{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final Brain Tumor SegResnet",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM9H0a2oE72EjjcULqBTEmy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kkingssss/Brain-Tumor-Segmentation/blob/main/final_Brain_Tumor_SegResnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Brain Tumor Segmentation with SegResNet**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pz5KqlgOXw6L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset and Json file can dowload here ! \n",
        "https://drive.google.com/drive/folders/1-MsS1-l2ENpYpWWfmQBiwT7aYMMpDy0D?usp=sharing"
      ],
      "metadata": {
        "id": "LJjGC-MhWFns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Setup environment**"
      ],
      "metadata": {
        "id": "hUe16rRyWFe_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LnKK5or3PRop"
      },
      "outputs": [],
      "source": [
        "!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel, tqdm]\"\n",
        "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Setup imports**"
      ],
      "metadata": {
        "id": "CROb_SKhYZ1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import tempfile\n",
        "import json\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import nibabel as nib #for read .nii file\n",
        "%pip install pytorch-ignite\n",
        "from monai.apps import DecathlonDataset\n",
        "from monai.config import print_config\n",
        "from monai.data import DataLoader, decollate_batch\n",
        "from monai.handlers.utils import from_engine\n",
        "from monai import transforms  \n",
        "from monai.losses import DiceLoss\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.networks.nets import SegResNet\n",
        "from monai.transforms import (\n",
        "    Activations,\n",
        "    Activationsd,\n",
        "    AsDiscrete,\n",
        "    AsDiscreted,\n",
        "    Compose,\n",
        "    Invertd,\n",
        "    LoadImaged,\n",
        "    MapTransform,\n",
        "    NormalizeIntensityd,\n",
        "    Orientationd,\n",
        "    RandFlipd,\n",
        "    RandScaleIntensityd,\n",
        "    RandShiftIntensityd,\n",
        "    RandSpatialCropd,\n",
        "    Spacingd,\n",
        "    EnsureChannelFirstd,\n",
        "    EnsureTyped,\n",
        "    EnsureType,\n",
        ")\n",
        "from monai.utils import set_determinism\n",
        "from monai.utils.enums import MetricReduction\n",
        "from monai.networks.nets import SwinUNETR\n",
        "from monai import data\n",
        "from monai.data import decollate_batch\n",
        "from functools import partial"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSfO97SiPZ0x",
        "outputId": "146caf86-1237-475c-85a0-d9e76db76220"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.9-py3-none-any.whl (259 kB)\n",
            "\u001b[K     |████████████████████████████████| 259 kB 9.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.11.0+cu113)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch-ignite) (3.0.9)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Import from Google drive**"
      ],
      "metadata": {
        "id": "IKPFXLBiYd0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLKJASd2_16Y",
        "outputId": "74aea6eb-5073-41a9-cf85-b9878483237f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Change Directory**"
      ],
      "metadata": {
        "id": "POA_ukI8YsM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/AI_builders"
      ],
      "metadata": {
        "id": "0t2CoI_h_29A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7204d41-7e63-43a2-bd4b-f09274c9d5de"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AI_builders\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Setup data directory**"
      ],
      "metadata": {
        "id": "UsAs6WHGYvu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
        "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
        "print(root_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCeDvLCKPatx",
        "outputId": "a64e0874-2fc7-4014-c0e4-9c9954131d64"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/tmpz7_0mzkp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Setup fold reader**"
      ],
      "metadata": {
        "id": "MeaWYLKXZCeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def datafold_read(datalist, basedir, fold=0, key=\"training\"):\n",
        "\n",
        "    with open(datalist) as f:\n",
        "        json_data = json.load(f)\n",
        "\n",
        "    json_data = json_data[key]\n",
        "\n",
        "    for d in json_data:\n",
        "        for k, v in d.items():\n",
        "            if isinstance(d[k], list):\n",
        "                d[k] = [os.path.join(basedir, iv) for iv in d[k]]\n",
        "            elif isinstance(d[k], str):\n",
        "                d[k] = os.path.join(basedir, d[k]) if len(d[k]) > 0 else d[k]\n",
        "\n",
        "    train = []\n",
        "    val = []\n",
        "    for d in json_data:\n",
        "        if \"fold\" in d and d[\"fold\"] == fold: val.append(d)\n",
        "        else: train.append(d)\n",
        "\n",
        "    return  train, val"
      ],
      "metadata": {
        "id": "gDp1lmDsBsEH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(model, epoch, filename=\"model.pt\", best_acc=0, dir_add=root_dir):\n",
        "    state_dict = model.state_dict()\n",
        "    save_dict = {\"epoch\": epoch, \"best_acc\": best_acc, \"state_dict\": state_dict}\n",
        "    filename = os.path.join(dir_add, filename)\n",
        "    torch.save(save_dict, filename)\n",
        "    print(\"Saving checkpoint\", filename)"
      ],
      "metadata": {
        "id": "n77KI2U3GhOz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Setup dataloader**\n"
      ],
      "metadata": {
        "id": "SAQk3RPMZ6Y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loader(batch_size, data_dir, json_list, fold, roi):\n",
        "    data_dir = data_dir\n",
        "    datalist_json = json_list\n",
        "    train_files, validation_files = datafold_read(datalist=datalist_json, basedir=data_dir, fold=fold)\n",
        "    \n",
        "    train_transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.LoadImaged(keys=[\"image\", \"label\"]),\n",
        "            transforms.ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
        "            transforms.CropForegroundd(\n",
        "                keys=[\"image\", \"label\"],\n",
        "                source_key=\"image\",\n",
        "                k_divisible=[roi[0], roi[1], roi[2]],\n",
        "            ),\n",
        "            transforms.RandSpatialCropd(\n",
        "                keys=[\"image\", \"label\"],\n",
        "                roi_size=[roi[0], roi[1], roi[2]],\n",
        "                random_size=False,\n",
        "            ),\n",
        "            transforms.RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
        "            transforms.RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
        "            transforms.RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
        "            transforms.NormalizeIntensityd( keys=\"image\", nonzero=True, channel_wise=True),\n",
        "            transforms.RandScaleIntensityd(keys=\"image\", factors=0.1, prob=1.0),\n",
        "            transforms.RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=1.0),\n",
        "            transforms.ToTensord(keys=[\"image\", \"label\"]),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    val_transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.LoadImaged(keys=[\"image\", \"label\"]),\n",
        "            transforms.ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
        "            transforms.NormalizeIntensityd( keys=\"image\", nonzero=True, channel_wise=True ),\n",
        "            transforms.ToTensord(keys=[\"image\", \"label\"]),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_ds = data.Dataset(data=train_files, transform=train_transform)\n",
        "\n",
        "    train_loader = data.DataLoader(train_ds,batch_size=batch_size,shuffle=True,num_workers=8,pin_memory=True)\n",
        "    val_ds = data.Dataset(data=validation_files, transform=val_transform)\n",
        "    val_loader = data.DataLoader(val_ds,batch_size=1,shuffle=False,num_workers=8, pin_memory=True)\n",
        "\n",
        "    return train_loader, val_loader"
      ],
      "metadata": {
        "id": "qXL12TDJAFDl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Set dataset root directory and hyper-parameters**\n"
      ],
      "metadata": {
        "id": "pSQkekKUaNsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir =  \"/content/drive/MyDrive/AI_builders\"\n",
        "json_list = \"/content/drive/MyDrive/AI_builders/brats21_folds.json\"\n",
        "roi = (128, 128, 128)\n",
        "batch_size = 1\n",
        "sw_batch_size = 2\n",
        "fold = 1\n",
        "infer_overlap = 0.5\n",
        "max_epochs = 50\n",
        "val_every = 10\n",
        "train_loader, val_loader = get_loader(batch_size, data_dir, json_list, fold, roi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLzH8gVpA8-P",
        "outputId": "1211f720-57e9-4e40-ddda-2c2536d3aebc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Check data shape and visualize**"
      ],
      "metadata": {
        "id": "MMlIiRfQaTl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_add = os.path.join(data_dir, \"TrainingData/BraTS2021_00002/BraTS2021_00002_flair.nii.gz\")\n",
        "label_add = os.path.join( data_dir, \"TrainingData/BraTS2021_00002/BraTS2021_00002_seg.nii.gz\")\n",
        "\n",
        "img = nib.load(img_add).get_fdata()\n",
        "label = nib.load(label_add).get_fdata()\n",
        "\n",
        "print(f\"image shape: {img.shape}, label shape: {label.shape}\")\n",
        "\n",
        "plt.figure(\"image\", (18, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"image\")\n",
        "plt.imshow(img[:, :, 78], cmap=\"gray\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"label\")\n",
        "plt.imshow(label[:, :, 78])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "7G6KGbKWBAJA",
        "outputId": "846317ed-14b8-4342-fa4a-690946ceec3b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image shape: (240, 240, 155), label shape: (240, 240, 155)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1296x432 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5IAAAF1CAYAAACar9UBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9eYxs2X3f9z213Xtr6+562wxn3nA4HJKiGJISSYiiYoWKKFkLJNCKEsFOHCiyZQlekMVwbDmAYyMwEgUxYCiQYUWBFcs2bEt2oEiJZTuxZEOBRIm0ZIMmY1Kk+EbicLY3r6e7q7r2qps/ur/nfev07TfTM9P9tu8HaHR11V3OOfe+mfut728JZVnCGGOMMcYYY4x5rdTu9gCMMcYYY4wxxtxfWEgaY4wxxhhjjDkTFpLGGGOMMcYYY86EhaQxxhhjjDHGmDNhIWmMMcYYY4wx5kxYSBpjjDHGGGOMORMWkuaBIYTw2RDCN93tcRhjjDHGkBDCMyGEb3kN25UhhKdf5zle977GvF4ad3sAxrxZlGX5nrs9BmOMMcYYYx4G7EgaY4wxxhhjjDkTFpLmgYGhIyGEvxRC+AchhL8TQhiGEP5NCOGdIYQ/H0J4KYTw5RDC75f9fiCE8G+Pt/1SCOGHk+P+2RDC8yGE50IIP6jhIyGELITwV0IIvxdCeDGE8BMhhOKi526MMcaYe5sQwteFED4RQtg7fq748RBCK9nsO4+fRV4OIfxPIYSa7P9Hjp9XXgkh/NMQwlsveArGbGAhaR5UvhvA3wawA+BfAfinOLrfHwPw3wH4X2TblwB8F4A+gB8A8FdDCB8AgBDCtwP40wC+BcDTAL4pOc+PAngngK85/vwxAP/teUzIGGOMMfc1KwD/FYDLAD4C4GMA/kSyzfcA+BCADwD4OIA/AgAhhI8D+G8A/AcArgD4fwH8vQsZtTGnEMqyvNtjMOZNIYTwDIAfBPD7APy7ZVl+6/H7342j/9hulWW5CiH0ABwA2CnLcq/iOP8HgH9eluWPhRB+CsCLZVn++ePPngbwBQDvAPA7AEYA3leW5e8cf/4RAH+3LMu3ne9sjTHGGHM/wOeTsiz/WfL+fwngo2VZfs/x3yWA7yjL8p8c//0nAHxvWZYfCyH8YwD/sCzLv3H8WQ1HzyDvLsvyd4/3fUdZll+8sImZhx47kuZB5UV5PQHwclmWK/kbALoAEEL4jhDCr4cQdkMIewC+E0ffFgLAWwB8WY6lr68AaAP4zeMwlT0A/+T4fWOMMcaYyHGazf8VQnghhHAA4L/H7ecNos8Zv4uj5xAAeCuAH5PnjV0AAUeRUMbcFSwkzUNNCCED8L8D+CsArpVluQ3gF3H0H2cAeB7A47LLdXn9Mo5E6XvKstw+/tkqy7J7AUM3xhhjzP3FXwfwORw5h30chaqGZBt9zngCwHPHr78M4IfleWO7LMuiLMtfO/dRG3MKFpLmYacFIANwE8AyhPAdAH6/fP6zAH4ghPDuEEIbwF/gB2VZrgH8rzjKqbwKACGEx0II33ZhozfGGGPM/QJTa0YhhK8C8McrtvmvQwg7IYTrAP4LAD9z/P5PAPjzIYT3AEAIYSuE8B9dxKCNOQ0LSfNQU5blEMB/jiPB+AqA/xjAL8jn/xjA/wzgnwP4IoBfP/5odvz7z/H94zCVfwbgXRcyeGOMMcbcT/wZHD1nDHH0RfTPVGzz8wB+E8C/BvCPAPwNACjL8ucA/I8A/v7x88ZnAHzHBYzZmFNxsR1jzkAI4d04+o93Vpbl8m6PxxhjjDHGmLuBHUljXoUQwvcc94vcwdG3gf+nRaQxxhhjjHmYsZA05tX5YRz1mvwdHPWAqsppMMYYY4wx5qHh3IRkCOHbQwifDyF8MYTwI+d1HmPOm7Isv/24GuugLMvvKcvy+bs9JmOMMa+On0WMMeb8OJccyRBCHcBvA/hWAM8C+BSAP1SW5f/3pp/MGGOMMSbBzyLGGHO+nJcj+XUAvliW5ZfKspwD+PsAPn5O5zLGGGOMSfGziDHGnCONczruYzhqnEqeBfBh3SCE8EMAfuj4zw+e0ziMMea+pSzLtFG1Mea186rPIsDm80gd9Q+20b+Y0RljzH3AFIeYl7PK55HzEpKvSlmWPwngJwEghOAeJMYYY4y5cPR5pB8G5YfDx+7yiIwx5t7hN8pfOvWz8wpt/QqA6/L348fvGWOMMcZcBH4WMcaYc+S8hOSnALwjhPC2EEILwB8E8AvndC5jjDHGmBQ/ixhjzDlyLqGtZVkuQwh/CsA/BVAH8FNlWX72PM5ljDHGGJPiZxFjjDlfzi1HsizLXwTwi+d1fGOMMcaYO+FnEWOMOT/OK7TVGGOMMcYYY8wDioWkMcYYY4wxxpgzYSFpjDHGGGOMMeZMWEgaY4wxxhhjjDkTFpLGGGOMMcYYY86EhaQxxhhjjDHGmDNhIWmMMcYYY4wx5kxYSBpjjDHGGGOMORMWksYYY4wxxhhjzoSFpDHGGGOMMcaYM2EhaYwxxhhjjDHmTFhIGmOMMcYYY4w5ExaSxhhjjDHGGGPOhIWkMcYYY4wxxpgzYSFpjDHGGGOMMeZMWEgaY4wxxhhjjDkTFpLGGGOMMcYYY86EhaQxxhhjjDHGmDNhIWmMMcYYY4wx5kxYSBpjjDHGGGOMORMWksYYY4wxxhhjzoSFpDHGGGOMMcaYM2EhaYwxxhhjjDHmTFhIGmOMMcYYY4w5ExaSxhhjjDHGGGPOhIWkMcYYY4wxxpgzYSFpjDHGGGOMMeZMWEgaY4wxxhhjjDkTFpLGGGOMMcYYY86EhaQxxhhjjDHGmDNhIWmMMcYYY4wx5kxYSBpjjDHGGGOMORMWksYYY4wxxhhjzoSFpDHGGGOMMcaYM2EhaYwxxhhjjDHmTFhIGmOMMcYYY4w5ExaSxhhjjDHGGGPOhIWkMcYYY4wxxpgzYSFpjDHGGGOMMeZMWEgaY4wxxhhjjDkTFpLGGGOMMcYYY86EhaQxxhhjjDHGmDNhIWmMMcYYY4wx5kxYSBpjjDHGGGOMORMWksYYY4wxxhhjzoSFpDHGGGOMMcaYM2EhaYwxxhhjjDHmTFhIGmOMMcYYY4w5ExaSxhhjjDHGGGPOhIWkMcYYY4wxxpgzYSFpjDHGGGOMMeZMWEgaY4wxxhhjjDkTFpLGGGOMMcYYY86EhaQxxhhjjDHGmDNhIWmMMcYYY4wx5kxYSBpjjDHGGGOMORMWksYYY4wxxhhjzoSFpDHGGGOMMcaYM2EhaYwxxhhjjDHmTDTeyM4hhGcADAGsACzLsvxQCGEA4GcAPAngGQDfV5blK29smMYYY4wx1fh5xBhjLp43w5H898uy/JqyLD90/PePAPilsizfAeCXjv82xhhjjDlP/DxijDEXyHmEtn4cwE8fv/5pAH/gHM5hjDHGGHMn/DxijDHnyBsVkiWA/zuE8JshhB86fu9aWZbPH79+AcC1qh1DCD8UQviXIYR/+QbHYIwxxpiHmzfleWSB2UWM1RhjHgjeUI4kgN9XluVXQghXAfw/IYTP6YdlWZYhhLJqx7IsfxLATwLAadsYY4wxxrwG3pTnkX4Y+HnEGGNeI2/IkSzL8ivHv18C8HMAvg7AiyGERwHg+PdLb3SQxhhjjDGn4ecRY4y5eF63kAwhdEIIPb4G8PsBfAbALwD4/uPNvh/Az7/RQRpjjDHGVOHnEWOMuTu8kdDWawB+LoTA4/zdsiz/SQjhUwB+NoTwRwH8LoDve+PDNObeI89ztFothBBQlmX8Of43gcVigel0WrlvURRoNpsoyxLr9Rrz+RyLxeIih2+MMQ8Kfh4xxpi7wOsWkmVZfgnA+yvevwXgY29kUMbcbWq1WhSEADYEItna2kK320UIAev1Ov6EEFCv1zEcDivFYVmW6Pf76HQ6WK1WWC6XGA6HWK/XG9ukhBAQQsBqtar83BhjHkb8PGKMMXeHN1psx5gHjkajgccff3zDbaTIq9frUVA2Gg3U63XU63XM53Msl0ssl0vU63U0Gg3keY7BYICyLFGrHUWRL5dLlGWJ1WqF1WqF9XqNer2Oy5cv45FHHkGr1cJ0Oo2itF6vRxHbaDTQ6XRw48YNvPKKe2obY4wxxpi7h4WkeejJsgyPPvooWq0WgCPnrygKZFkWReN6vY5ikGKyXq+jVquhVqthvV5HwVmv19FsNqMIXSwWmM/nmE6nGI1GUWzyGEVRoNFoxJ/pdIrFYoHlchkdS5630WjgiSeewLVr1zCZTPDss89itVrdnYUzxhhjjDEPLRaS5qFle3sbjUYDRVHgkUceQZ7n8TOKNgpJuoL8W0WkhrzWarUNIQkA8/kcw+EQIQTMZrPoUHK7breLZrOJRqOBWq2GRqMRhSR/6Ei2Wi3keY7lcon9/X0URYHpdBrFpjHGGGOMMReBhaR5KKnX63j66afR6/WQZRmKoohCks5jmhOpf4cQNkQkw1zpMqoInc/nMUR1Op3Gzxn+2uv1ojAFjhxSDX2liOU2y+US0+kUIQQMBgPs7u5iNBqd+5oZY4wxxhhDLCTNQ0e/38fTTz+NK1euoNPpIM9zZFmGZrMJADFElVVY+Zqf8T0tjsPQ13q9HsNRVXh2Oh00Gg10u12sVqsoCulKErqeFKrMwWT47GQyweHhIYDbrmgqeI0xxhhjjDlvLCTNQ8Wjjz6KS5cuYTAYoN1uI8uy6B6yEA4FoopH5iHyc62cSrewXq9v5FJS5DUaDTSbTdTr9eg28nNS5TzymI3G0T/T1WoVw1vb7TYuX76MTqeDwWCAg4MDfPGLX7yYRTTGGGOMMQ89FpLmgYeirNFo4NKlS7hy5Qq63S5arVYMSQUQxWH6U/XZYrGIr+kWUmBSmK5Wqw0xyRxI9o9Ud5OoOOXYtU8lADSbTXQ6HTSbTazXayyXS+zt7UUh2Ww2ked53Hc+n2M8HsdzhBDQarUwm83Of/GNMcYYY8wDiYWkeeDJsgxbW1vY3t7G9vY2Op1OFGLaziMNadVqqJqvuF6vsVgsNpxFikWGttJNBG63/NDzUJiq+6lisSzLuD/Py+NQKLLwzuHh4UZ46+XLl/HWt74VeZ6j2Wzi+eefx2c+85mN9bh27ZorvhpjjDHGmNeNhaR54Oh0Ouj1emi1WvGHopEFbyjG+D4dwzR0lU4j3+NvVl9VGJLKc1IMqjNJd1GPleY5rtfrjQqxKmw1dJbOaAgBly5dwvd+7/dib28Ph4eHGI/HGI1GUYy+853vjKK10Wig3+/jsccew40bN/D8889fxGUxxhhjjDEPEBaS5r6m3W5HkbVarWKRGgAoigJbW1totVqo1+tYLBYAjhzC+XyOWq0W3cMsy6I7WavVKkNOVWSmxXYUFttRl1GL6ADYEKgUnMyPTEWlnl/Hw7BW4HYvTIa77u3tYTqdotVqxXBaCl1Wi221Wrh69SpCCHjuuefexKtijDHGGGMedCwkzT0JezQCJ9twaPhnu92Owo1CkduztQaF5OHhIRaLBdbrNebz+Ual1bIsURRFPC9dQT1eVV4jRaKGwvIYaXisOo9avCfNh9S5A9gQrHoMClHOod1u4/DwELVaDYvFAvP5PBb6ofsK3HZOy7LE1tYW6vU69vb2EEKI+xljjDHGGHMnLCTNPUm328X29jZCCGg2m1FY0YWj4AkhbIgp4MidYzXTbrcbi980m01MJhMsFgtMJpMNMdnv93Hp0iUURRFDXdfrdQxN5bm1WqtWWiV0RYHNQjkANtxSon9ryw8Vo8BtEcuCPTyuuqfj8Rjj8RiHh4fRjbx27Rr6/T76/X5sHzKZTDAajbBYLGIo7oc//GFkWYYbN27g85///HlcUmOMMcYY8wBhIWnuGRqNBi5fvhzDTYGj8NTt7W0URYFGo4H5fI7RaITJZILxeBxzFVmEZr1eo9lsxv1YvXS9XiPLMgBHouzw8BCHh4ex3yNF43K5jG1BKPI0ZJbCjePTcNM0JFVFJl1FHlNbfLBIDwWivpe6oFmWxWMuFgs0Gg2sVissFgvMZjOMx2NMp1PM53P0ej0MBgNcunQJ/X4/rh3DfClEKZpXqxWuX7+Oy5cv41d/9VfP81IbY4wxxpj7HAtJc9doNBrodDpRULGtxXK5jHl93W4X/X4/9nukC9lsNtFqtaJoms1mmM1m8XOKPgo+pSpUdj6fY29vD8vlMrbwoJDjPjwuRSewGaKqMDQ2zbdUF5Gfa/6khr7SfdV8TIpM3ZYsl8uYM9lqtdDpdFAURcyTbDQasY8l50wROh6PsVgskGUZiqLAW97yFrz88ssOczXGGGOMMZVYSJoLIxU/WZbhypUrsfgLq6bSJWy1Wuj3++h0OhtiqF6voyiKKJzoLt66dSuGq2ohGwAbr7WvYwghFt+ZTqeYzWZYrVbodrsbhW9Soaf5mxyvvp8Wx+F4KEC1sI8en0KVgnYymURhzR9WoU1zJXm+RqOBoiiiAGfOJHDUY7LX6yHP8xgOOxwOsbu7i/V6jTzPkec53va2t2E8HkdBzP2NMcYYY4wBLCTNBdJut3H58mUAm0VqBoMBtra2YhgqgFgkhmGXDL3MsgztdjuKyhAC9vb2cOvWrdj2Qquran4jodtZFEXME6SrycI9eZ5jZ2dnw5mkk0jBCyCGorKID9+rQkVj2g6Ex+NYDg8PMRwOcevWrZjH2W63sVwu0e/3kec5sizbqFjL87darZhj2m630Wg0othljmWn0wGAKDRHo1F0H+fzOcbjMZ544gnkeY52u41f+ZVfObVKrTHGGGOMefiwkDTnSq1Ww7Vr1+LrNGew0Wig1+uh3+9Hgcj36cBNp9Po0PE4DPEsyxJ5nqPf7+PatWtRUE2nU+zu7m4UqKE45f6tVguHh4cbTuNyucRkMom9FbvdLvI832gfUq/XowNIl5HzYY5mKrqqiu5QpGqFWHVYDw8PASC26iiKYkNsa+EftjDpdrtxzhSJaf9KvRatVgtbW1uo1WqxUM/BwQGGw2HMHS2KAu973/ti2HBRFOh2u/jCF76Ar3zlK2/ezWKMMcYYY+4bLCTN64atNZjHp4JMK5AOBoONFhqz2SyGaxZFgXa7HcWSFrNRJ5CwEI8WomHri8FggOFwiMPDQ8zncwyHwxiqyVDQtDKq5hU2Gg1MJhPMZrNYzIfnUkHG+aXOogplnS/R8FgNVdV2H4vFIjqr8/k8VqDN8zwKyUajEdeCUJgy5Jfz0bVLnU/uozmqADCdTuOxKeC3t7ejkGy32+h2u7h27Vp0i19++eWN8RhjjDHGmAcbC0nzmklDNh977DFsb2/HVhJaiZSOYaPRQKvVQqvVAnAkfr7yla/EkNB+vx8FaVr1lKgYYxinFqXheer1Ovb392O+4/7+PoqiiPtSqGqeIkNSOX4KPRagoSvX6/ViaKi25KAzqSIyJW0RQnGna8W5zGYzDIdDTCYTrFYr7OzsYDAYoN1uo9VqxTBVhu7yujB3st1uR3GtbVPoRqojrPtRRLLHZqPRwGKxiOfieZjDOh6Pce3aNVy7dg3L5RKf+MQnMB6PT8w7LUJkjDHGGGMeDCwkzans7OxEkcNKqRomyZ6Ey+Uyhooyd48FcpjTWBRFLPqyv7+P6XQaq7aycquGh6r4oitG8UTHjVDI1et1XLlyJYpUFpEZjUZotVq4dOkSut1uFLVlWUZxtl6v0Wg0YpsMuoJ7e3sYDofR9WQo6mq12ggxVWdyuVxuhLFWtQjRfEnOkbmJ4/EYq9UKzWYztiLRMFit4sp14nEY4srX3JbtQSjw1ZUFEHNFe70ems0mbt68iZs3b8b56Tnm8zkmk0kc13q9xtd8zddsjHEymeCFF17AM88888ZvRGOMMcYYc89hIWlOwH6O7FlIkactNejOEbpaqfihI8l9ms0mtra2MJlMAOBE3iDbUZCyLKMzRjdS3T8NcQWAfr+P5XKJ2WyGvb09TCaT6LAVRYGiKKK4SudAF49FfOjOAUdCazKZnMg5TNG+j5wXj8W/0yqr8/k8uqjj8TiG/bbbbbTbbYQQ4ry1JYi6o4ThqnQltVARBeFpRYH0GrENS6vVwvb2Nlqt1kYLEo6HPTlVPDM/89q1a+h0Omg2m7hx4wb29/df4x1ojDHGGGPudSwkTaTT6cRWHI888kh8nwJPi8RoMRyGR1KI0eXTfETgdoVT9jfUAjpEi9hQkKkbyfcoaiiueC66ob1eL7qgWuGV+1IYqyunAnW1WqEoCjSbzbgPQ12bzWZ0/TgvhWOs6vWo8+Qc6UayDyYFnOYtcv21YE4aMqtrrFVxuXZp5do0ZzNtzbKzsxMLGekaUVRSsDMnVfNba7Uaut0utra20G63MRqNsF6vMRwO73gPGmOMMcaY+wMLSRN5+umnMRgMooukuYBsH5G6dszxY7iounUUSgx/BI6ESL/fx/7+Pg4PD7FYLDbCRDV8ledXEZQKntSRCyEgz3MMBoMTLioL+nA+KnY1ZJT7qYA6ODjA/v4+yrKMArMK7VuZhq+mfSWZn8nX0+kUh4eHmE6nG/tSFKbOItdY8yC5Ro1GI27LgkIqqlWkAoj5lHRwNRS40+lgNptttE0pyxLj8Rj7+/t45ZVXopAEbrcUoRvd7Xbx3ve+F4PBAJ/85Cdf071ojDHGGGPubSwkH2IuXboURVyn08FgMMCVK1fQ7/fRbDY3nEAVclWFZeg6qmOoPRwpeMqyjEIUAEajEcbjcWz9wbBNOm9pv0YdQ1pIRoVMlmVRCGoeIt0/HoeoU0nhxpxQumxZlsWqsRRWdOgAxLBcHWtVIR4KV27Pz9l6hC1J5vP5hmhkmG/qpqp41bXifCnK02qxKjI5Hua9ttvtmOeqlXNXqxXm83lcpyzLcPXqVXQ6nfgecyhZ/ZY5rdvb2/joRz+KX/3VXz2R52qMMcYYY+4vLCQfMp588snYjD6EgPF4jPV6vdHAPsuyDdGmoZIqavRHK4Jq+KW6fGkvRbYCmc/nMSQ2LUyThoie9prn0veZ85e+R7dVxZE6oBRqKmjZ9oL7zefzjVDeNC+SAk/DXBWuhzqj/K3VUXU91OXV3xSBaf4lw2R5HA0xBo7afEyn05ijOZvNMJvNsFqt8Oijj0YneTabbYxb58rKu+12Owrj3d3dKFQpTil6i6LAV33VV8V80Oeee+5sN7AxxhhjjLknsJB8CGA11Uajgaeffho7OzsoyxIHBwfY3d3FYrFAt9tFt9tFnucbIlKdSArKqnzF9XodhZuGxAK3BR730RBNiph2ux3Hq8V9+DewmYt4WrsNFbRV22q+pDqudBJVeHKMLP7D4kMUaWw9QtGoYbJV4azp3xSwFFnMT9Xxaa5j1XqmVWQ1nJVhw5obqWgoLXMdGQLL+4AtSbQokYY5M6yZ453NZrHqrIbu8v6o1+u4fv065vM59vf3cXBwEEN7tciSMcYYY4y5t7GQfAh48skn8cEPfhBvectbNkTFcDhEs9nEeDxGnufodrtRLGmIaVq4BTjpOhLtJcl9GcZIAba3t4eDgwOMRiPMZjMsFovK0EueT4Vh6mqm+YEcE8Wjjj8tNsOWGKwKq4WEOC8KMa1WCwB5nm+EkKrbmRYRSiu2qkDkeUMI0SmmANR10/Xmb56X5+BYFotFdCN5bs0H5fbD4RDj8TiKaI6bYb0q6PkZHVlWhmXRHc6HLViYo7parXDz5k0cHBzEtWZo8+XLl/HN3/zNGA6HuHHjhluFGGOMMcbcR1hIPuC8733vw/Xr19HtdqMoohjI8xy9Xm+j2AyFhLbcAFDZakJDLIHbIo9Cg9vQaaIDeXBwgMPDw5g/R+EE3BaA6n4Sfa0VYdNcSnUW1TGlaOK86CpSsBVFseHIavEanp8ilxVhAWwUstEwV4rgNKxXXdO0CE6v14thnwwLzfN8Yy4q6DRcdT6fR2dPcx/TaqoAoiNIV5U9Q1k0Ryv0sg0K14uCWkOA2Y6k1Wqh3+/H68/xjMdjTCYTTKfT2CJGxfgjjzyCPM/xuc997nXc5cYYY4wx5qKxkHxAYfXSS5cuYWdnJ1ba1NYR7PfHB33m62m4JEVCFZr7qD/aW3C5XEbxQFHJMaRhohQ7KgIpsrTKKfflWHVeWkCHx6BwZE6ghn+mzmFVFVg9Fn80jDetKHtaZVktCqTrpa4rq5xS+E6n0xg+q2tOJ5CCjeI/FZFpnqbmhfK8FIBFUWx8AcDjquuruZkMpU1DnPV8bPeSZRkODw9xcHCAVqu1cczlcok8z3H58mU8/fTT+PKXv7yRl2mMMcYYY+49LCQfQCgOOp0Otra2Yu7jdDrdqEqaZVns+ajigy4UBVcaXgrczmNMi+EAR2Jnb28v5t+xUI2GSjKENK0sqiJMi9SkRX2qnMcqJ1IrtbKwDMWPVnrlPlw//ta8RxWNVUJR1ybNkazKcdTwW65xs9lEp9OJ7UDG43F0PzlmvSY6D52vCryq9WJuJs/J/EwV5vw87bfJ/Ee+lwpUDZEFgHa7jXa7jf39fcxms+jCAogOaFEU6PV6uHLlSszddWVXY4wxxph7FwvJB5BOp4NOp7PhSqnwoRBRN/LmzZuxeTzDWCko+ECvuYPa3kNDM+mMvfTSSzE3rtvtYjAYRNHKfD62zVB3KhVudKxYDIaOIsNIsyyL+xVFgXq9HnMEWUyGf1Nc53kec0EpvqbTKcqyjGNUZ1GroXL9VNBy7FrJVFtsqABN8yW1qA6P3Wq10G63oyvH8FO9djyntg/RsFd+rn00U7fxypUrG44vBSWPSyeURXIoLDl/rjvzKTk+ba9Ct1N7j7ZarehK8vrSSc2yDB/+8Idx48YNfOYzn3nj/xiMMcYYY8y5YCH5gNBoNLC9vR0FgRZeqRI9fHBXIaV9C/k+RYM6d1pRFbgtJImGp/I4FD9anCbPcwwGA1y7dg3dbveEUOX5J5MJRqMR9vf3MR6Po1DJsizuR3GilUaHw2Es8rJer7G9vR3zQrvdbhRFbOWxXC7j2jF8lXNXccsxKlqshmucikd9P10jvs9iNK1WC71e79SCO3xP3T0dn7qRDAFOXWXmKAKIgpTH4bpQDKoYVSFJsaz5o7pmjUYDh4eHGI1GWC6XGAwG2N7ejlTodJAAACAASURBVGG07CNKpxIA+v0+3v72t6Pf7+MTn/jECcfXGGOMMcbcfSwk71NYsISCJ8sybG1tbQgdbaugAkdzBIHb7UE0VJLbMlRSwzBXqxWazeZGldU0r1FzCPmTCs5ms4mtrS30+/3oUKn4SgUlzz2fz+NnbJdBsaRhmGnYZZZlG+G8HDOFm+6voiztkcm5KFVFh+6Efq6iT0NG6djqNmnxIXUGqwSrhufq/mkuKsfNzxgOTLdRnU0K7HTuLPyj66VFgEII2Nraws7OTiwgxHEz/5W/syzDzs7Oa1pLY4wxxhhz8VhI3mdQwHQ6HTz++OMoyxJFUSDLMjSbTQCIImC5XGI8Hm+0eFBBMpvNUK/X0W63cfXq1Rgmyod5Ok3MpwNuCzwKMQ15JGnBGf1N11ErfHa73Y1jp0VvGAZbFEUUwCqCGcqrFVdVLLdaLazXa/T7/bgNz0EhxtBLHa++5vGAzaI7qQjTMVdRtSbqIqqrqdVvteJulbBKcza1oBF/NC+Soj0NhdVQXnUa6dSqkNRiS5r3qeG7FMfAkQO6vb2N7e3t2HuSQnUymcT2IMyrnc1mG8czxhhjjDH3DhaS9xGNRgMf+tCHYqhhs9lEr9dDv99HlmVRJEynUxwcHMRiLcPhENPpNFZupUhgGGWe5zFfrixLzGazKMKqwjMJRUVapZTbMux0MBig3W5H0UDhyxxHhlBWVfykiOz1erGS6UsvvRTbY2xvb2MwGKDT6WyEpGpOIIXM1tYW8jyP4Zcqzng+RUWkupCpk8c5qzhUgaZiSF1ZXi8V+MwH1dBQjoEFiVIRmx73NJGrApViUMUix8TfzC1dr9fodDpxjfQ8ur66r95LZVniypUr8X7lvdxoNNDv93Hp0iWMx2Ps7+/j2WefxSuvvBK/LPjABz6A3/7t38be3t6J+88YY4wxxtw9LCTvE/r9Pq5evYo8z2PxkmazGSuyZlm2UTSlKApcunQJwFF/RIoVhrpSTKYtK+j0acVMigKtqpqGkKrQoojKsiy6ndrAXovlsC0Iz6cuF3DS3SzLEr1eL/Y81FYSGv7K8ei6pI6s5voRCjt1NjVMVPtbpm4i9+c8qpzDKvdWSR1greqq4aRppVwdg+Zcco5cc76fur86Xop3LVqk4cP80S8a0iq+2msyhIButxvvBxXKdDo57q2trdiKhuN66qmnsLe3hy996Usn1tMYY4wxxtwdLCTvE7rdLq5fv452u70hJPkgruGKfEAfDAbRTdK2DvxpNBqxOqeGNGo7DnXMiArIqp6JDKNl9dFOp7PxGcetVVxTsaR5fXoOimTgyNVirqbum/ZIpEPIMajASueprqOKwtSRVedU3+O+/K3b6HqlOZL6WgWjVjataj2iY0wdVc6V/SZ5LP0szbusGj/da449daFTUc1xqyjnteIYVdDSRc7zHP1+f8Mxp7g0xhhjjDH3FhaS9wEhBPT7fTzxxBMxtywVOQwv5MN3o9HAlStXosBgtU06khQItVotVivV4jqp+6ViQwvbqPBar9eYz+cYjUbI8zyKPg2FzLLsRHEcLahDwULhS7S4DY9JQc15s8WHisosy+JxVaSlRXy4DhRc6l7y+BSoFOE6Bx5T1zUVeXrd1GFVB5bb87P0OqcOrVIlbNkPUvtC6mdpiCydYQ0P5jVdrVaxuBFDX1PSLwLYcoWfsX0L/6aQZ8GoRx55JI5vOp1iOp3GCsMuvGOMMcYYc+9gIXkf8G3f9m147LHH0O/3N/L7+BCuuW7qXPEzdXj0QV8/J1rMRiuvUohQXLDKKT+nuzmdTrG7u4t+v49er7fRz5Lbc1/Cz7XRvTpsGjZLEUUByc8ptJjTp+4gBRYdUd2e86dw5bbNZnNDPC4WCwyHw3j8oig2Wo+kTi7HnhYdSovHVOUy6nVJ8x6rBCSpcha5Jnp+PQfPzfuConO5XMYw6vV6jZdeeikef3t7O7ZMqapoy/Xn3HlvLBaL2BtTx8hiR8BR8aTt7e2475e//GVMp1P0+31867d+K375l395I+zaGGOMMcbcHSwk72GyLMP73/9+XLt2LYZzas6cFqdRUZSKAz7ss08ksFlVlKJCnceq6qBaATRtf8HCKqwQS9cKuC1w9Ng8Xpqvp+dOeyamvRzTSrJp3l9V/qHmRaro0dDXWq0WnV3NAaTYYR4q10CFsOYpcn6nhcDqGNTZTcNNq4r7EHVD0+OnRXzSLwdUkHE7FcEcN9djMpmgVqvFKrunQeGdurk8X1q0SHtPLpdLtNvteJzf+73fizmadOONMcYYY8zdx0LyHiXLMly6dAnvfe97URTFhmOW5hOqiAQ2i64oDEVM+znqcVMBqaLktAIvFEwUknT4qnLyKJr0d5WDmIZ7Vokjvq8FcbSyaZrvqOGspwk9LSykQpLOHAWkuqrqXHJtKcxTEZiKSL1WVTmOei2qttHrnK5ZGj6b5limx6eYS//mdZpMJvELCV3XVOCqo0pRqV96aDiwXlOuWbvdjteBzrCGZBtjjDHGmLuPheQ9ytvf/na85z3vQa/Xi/mLVQVj6CzRaVPBlz50a59EhqjyWHQrVWyo0GBRG54fuO10MsTx8PAQ+/v7WK/XUWjpuOlKacEWYNNRVHFHVHSm6Jqo63VaGKgWG0o/T3NBVYjmeY52ux3DewFgNpthNpthOp1iuVxuVCFNq96muY7qtpL0elUV10m3URHN9aOLyPWvyrNUN5hj1CJMIYToLHPtWU11a2sLrVbr1LHzfuK9yeJLnEv6Wr8M4Jo3Gg0URYFHH30UL774ImazGW7dumUhaYwxxhhzj2AheQ/y1V/91bh69WrsKajN4Om4AbfDSTVkE7hdVVXFpBY/0dYLGvaYVgtVQVflINE1WiwW2N3dxXA4xHq9xqVLlzacsyzL4jg5bgpKFTSay5gKOg1DJbpdGu6rY1bBBGAjF1OPle6jxWnSCrV6Hr0+3E6LBaXOYNpyhNukLu1pQjIVber+UaTzdxpGzDWmWNS56zHp3vI429vb8V5MW31wXdI81zTfNu2NWdX3kuGtPO9b3/pWTCYT3Lx5E7u7u/jIRz6CL37xi3jhhRdgjDHGGGPuHhaS9xDNZhNXrlzBYDCI4awahqluE8WKuk5pKCcFGAVD2n5Bq242Go0NF60qhJQ/qaO0XC5x69YtjEYjhBCwtbW1EdbabDZjkRUNhWWYowqr1BVMRaWeX8WlulpVAk5FshYn0vlWhQeT1EFV4a7inJ9XiTQNvyVVFVhT0a7HqRKSuh/HmfarrJqThvFyjhpqq6GtvV4v3pOsjFs1XhXKaajxaXNMx0hBTSeYzvl0Oj21Yq0xxhhjjLlYLCTvEZrNJra2tvDUU09he3sbzWYzOjda9RTAhhjkQ7uKM+33pwKUBXCYtzabzaIIUscoDaHVsFJ1DdUp3N3dxWKxQKfTQb/f35gb55EKIB4zbTWSkuZZKhrKyvlrLibPlYpiFXSp21gl5Pi6qlANcyb12OoGp+LstLBbHotfAqS5j2loqp5P3T7t8alfAPC83DcthpQ6v7qWmreoBYt03Do+XXe+pw6kXp903au+OAEQ25Dw30JVeLAxxhhjjLkYLCTvEb72a78WTz31FFqt1kbvxXq9jul0GkVAt9tFnucAbuctskekihT+aJgrX69WK8zn81gNs9FoIM/zjcIqQHW7CIYravhmKtoWiwWKotjIv9RQ0FREqrCiOOCYtRJtKuC4veYcqvghKooUDRNm2LA6i+rucXs9h4pBbWuRjoVz1pDeKjFJIZgKb4aHVglvwvuAlU1TF5Bj4ZcLabElnp/H0s+qrkEqaBXNP606FkNkCb/goFjWkGN1N+fzOXZ3d7G9vY2iKPDMM8+cOLcxxhhjjLkYLCTvEXZ2dvDYY4+dyDdLwzXVSUtdIe1dqG4kUQGU53nMZ2NBFM2ZZNhpmpvIfZrNZhQUy+USrVYrCpzZbIZ2ux3PrfmXqTOYkgqs1CFLw1ZPO05KGlLK91Jxpm6e5vNpyG1VPmUq7lSQaw4j31M3kPmKFOFpf9D5fB6vUbpWhEKSTraGP1e5e1xT/WJAv3BQKP7UBU3XIEU/V5dcc2D1PY6fopLjevnllzEejwEgfjmRhiUbY4wxxpiLx0LyLhNCwNvf/nYMBoON8Mg0bJDblmUZK2KmbhyAmMOm7TdSMQgcuZmtViuKvOVyiSzLopBYLBYnQiMpQtnuQqFLCiC2e9BQSAAnxJSugZI6eVX7VDl6VeGOd8opVGGojp2GiqZ5hHpu/Z2K2arwUC1Qo4JY50H3WUX+bDaLrmR6Lt23Xq+j1WpFQdZqtaJrrfeFClx1/FKhqb/Tcaoo5E8qUlUgpuHDGl7L89br9VjMZ7VaYTqdYnd3F5PJBOv1GlmWbYwpz3NMp1MYY4wxxpiLx0LyLlOr1fCxj30M3W43PszTfeJDvuYxrtfr2G4ifdjXh3Huo8V61GlkOOt0Oo1OGIWsiga+VtGlRVQoAtimhMeaz+cnHE0VlTw2x000r05FWOpiaj6nVg69E3rcdFt16FRMpgJQx63j0ff0WDrn1FlOx7xerzEajWLPxPl8jvl8Hu+FNMQ03b9WqyHPc7RaLbRaLWRZhizLorOqgj6tylvVnzJdO86TwrQqZJjjoijX0GB9rQ6pupIa8jqdTqMjyTxN3q8hBPT7/covNYwxxhhjzPljIXkPwJxIPpBTRNAV1IfrtFUHHR/NgQQ2nbz0h46h5kYeHh5iOBxGAUpRmIogCgV1HRuNBi5duoTZbBbFz2Qyie4St9X+jRyniqHU9UuFE9HwyCqBoyIprUSr59WquOqgnSZKq3ICVUxz3VUAc85VOYmaW8rw0dFoFENZl8vlRn/PdIy87qnzx2OvVqsYFqr5lwyB5Vo1Gg1kWRaro3LMqbjkedP7406hxVqISIWkHq8syyieKRr592AwwM7OTtx3PB7H3p10zvmeMcYYY4y5OCwk7yEomCgi2chdi6Ror8hUPFZVc02FjYay5nkewyHH43HMwaOLRddRxRxFnBZUUUeUrSHSXE7dJs3XO02IpKGUKVWtUarWQNtY6PlUyOj+Kpg0TDgVvamIVTdO32eepV5nwrzU2WyGw8PDGMbKNawKBVUxl54nzaVN8xnZMoahr/xNwcfP6ShzvCqiNdRY56uucXqdddzpNWUhndlshvF4HHM2G40Grl69GsdZq9VwcHCA4XCI4XCI5XKJ0WiEdruNVquF4XBYeR8ZY4wxxpg3HwvJewR12Sj01A3U12nVTWCzdQO3S4vU6LH5w+Owj2RauTM9Rpr3R6GrQlOdLQAbRWKqBNmrFU5Jcwq5n+Y1pkKzKnT11c6jxWYottLiO1Vo2KteH46N40wr0XI7tmJhyLIKbxVw6Vj0WvFYp7m4qejl9W61WnFtiqJAs9mMubK6drov7yMVi3pNqkiFpB6fY14sFhiNRnFc3W53o39lKt7pRuoXL7PZ7I4OqTHGGGOMeXOwkLzH0Mqdaf9IoiGM6v6khV2qcgspVFjMBTgSKBQPqVioCl/U43N7uo/Mc9MQSRVRKiRPEx46DgqyO+U/qsDVv3UOp4krbpO6n+qC6di5na5JOs6qHNPUWUzdOM2HTI9LYZ5+gaC5jjofXQ+6jemYGRpaFEXcpt1uo9vtotvtRlGqObH6ZUWa35jeHyruuYbaikbFp77PYzPsmuIWOPpCol6vo9vtxhzQWq2Gvb09jEYjZFmGF154AfP5/NR7xRhjjDHGvDlYSN4DqFOm7T6YO5YKJArA1Wq14R5p8Z0qB07FAXDUpoMP/c1mM+a9aQhsmp+nY9bQUf08dcV4TBUiGkKa5jrytwpPzp+/07mlc9dt6cJWFc3R46R5hBo2nOZNathnStoHUddd5wwA8/kce3t7G24kz6cOqa4Nj7VcLqPIpABLnWfOSc/JcavQ43y1hYiuozqJzM3UdddrpdccQBxn6qDSZdR1nc/nUdT2+31kWRa/XJlMJgghoNPpoN/vYzAYIM9zPP/88wCA4XCIJ554AsPhEC+++OKJ62KMMcYYY948LCTvAdIH/KoQVW7HB+80Ty09jooAACf24bG5reZSpsKL+1eFi6b5c3y/qtefihINjdQ5psWCUqdLX/PzNARY39OCN2kOnxbi0dDLtDCOumc8phb1Sa+dCqaqwj3693K5PFGFtyqXMB0D30+d1vSacJ35ZYEW2KGr12w2URQF+v1+LIyjc0qvjVIVgqvOKK8TXV/N9dR7i7m67XY7riGvW3otVDTneY5+vx/zQdNeocYYY4wx5nywkLxHqMpnqxKV+pCuLTgIHSF1qarOkTqEy+VyQ2yy0mq6n+6v59SQxdPyEVUAaJGbqsqfGpKa5h+qQFHhkArJKmGppG5jVf7maXNOj6Fin8dJx66/+Xna6kUdSJJeQxVg6bxSMaprqD0m8zyPIrLZbKLdbqPdbm84kVWhx6e5uboeep15n6bVWhXeDxwH8xxZeCgtVqQh181mE/1+H8CRw763txdDtV3J1RhjjDHm/LCQvMc4rYgOsJkLqEJKQxT5wH4nIafHSgUQXzPE8LQcuDsVY6FoSd1FDYetEqc8huZXVgllCijmknI+aT6kuqKap6muljp0acVXjkd/V60d3+P4OM+q9U9zGhlerOKQBXAY1qzXQB1HVlflefUcvBe4bbPZRKfTicV02G+S4axFUcQwWRW2PJ/mPFa50CrA03BktjahoKTbyPYwFJKtVgvNZhOr1QqTyQSHh4coigLdbjfuR2HKe58ualEUmM/nGI/H2NraQr/fx+c///nKe8wYY4wxxrxxLCTvATTEM31AT50hFZEqZlQgqRt1GqmgTEVX6jiq01VVTEa3ZV/CVPSpk5SGlaZuZlV4LAWIjlHHmq6HumAq0DkuzYOk60WBkrpgWuhGBdZpbq2uVxqSm1IURTzHbDaLFVV1vKnzWXVfML9RhX+e5+h2uxgMBuh0OrEibZqDuV6vMZ1ON64ZBV46Zv0ioarIkIb36v2lYbacrxY04rG5v/a2rPqCgEKc57169SpqtaMWIaPRCO9///vxpS99yW1BjDHGGGPOAQvJewA+3AO3BUu9Xt94YCZVuYNEBZ0WM+F+KfoZH/JTUVYlJFQ0cKz6nhZuSc9FqsTpaS6lzr0qJ7JqTiok9b30d5qPWDXWNExYRVwq5qr2r3IueSyGm3KsbH+hYcta1ZQFedLzqvjSdcnzHJ1OB91uF51O50TlWXUa1e1UcUg0vzHNbeXnKjDTteI50n11DPP5PN6LWgBK56ztU9Tl3NraiuuwWq0wnU7x6KOPoigKvPTSSzDGGPOAUatj9u0fQFk7vbI7AHRu7GP1WUepGPNm86pCMoTwUwC+C8BLZVn+O8fvDQD8DIAnATwD4PvKsnwlHD0N/hiA7wQwBvCflWX5W+cz9AcHFkEBbrfPUOctFZJV+Wtp3pm+pzmJ/JukD/n8zYIyFBZVFTcpIlXo8L1Wq3UiP1CL7KgwUGGTChMdp27D7Xg83a7KLWN4ppKKd3Uzq8SkOsZVLqiuXTp+3V6Pz7xAtkwJIWA4HGI+n28IXVZKZQ6jhubqa37O+XU6HXQ6HRRFgTzP45yr+kCm7q8KR732Gn5cda30fiGniV/dniGwDHtlHqeG/2pYMYUkx0tnd71eYzKZYDqd4pFHHkGr1bKQNOYBwM8jRglZhvrlS/jSNzWwbt75i+grv7mDwXM7WL3yygWNzpiHg9fiSP5NAD8O4G/Jez8C4JfKsvzREMKPHP/95wB8B4B3HP98GMBfP/5t7oC2TVAhuVgsNkTHnYqgpCIofZjng7eGxHLbNL8P2HSJ+JkKRW2TofmQ/DwNxaQopbukrUWA22KXvQJTMaiCTUVOGoZbJXRZMTQVnPpat9HwSx5TcyzT/dXJ499V51KXl8fVvogUjHr9dB6NRgPdbjeGCdfr9ehQ8rjMq6zX6xgMBtja2kKe5zG3UB1knU/VeqpTrOvTbDZPFAhSdH4qvrUKq56P7iuP12q14k9ViDXHxTY4vFbsjdnpdDAYDHBwcBB7cxpjHgj+Jvw8Yo5Zf+jd+ML35gDuLCIB4OYHgL13vBtv/Yu/dv4DM+Yh4lWFZFmWvxJCeDJ5++MAvun49U8D+Bc4+g/3xwH8rfLoyfnXQwjbIYRHy7J8/s0a8IPEzs4O3vWud2F3dzcWQqGbR7SqZxpiWhXyqsVLqqAoSp28tEBKKg5U2HCMzMlj0RYVKeocAbedRBWJ6ijxs3Q8HC+3SwWuOre6r7qM3EfzIE/LH9V9U1IhyPf0/VSgpWGtKqw5/slkglqthjzPMRgMsFgsYlGcEEIsqNNsNnH16tV4P1CcLRaLWHhob28v5ktubW1ha2srCk7t56gikT/pFwAsaqOhxKeFB6dz1Eq8PGcaGsvxTyaTjW0Z0lqv12P1YL2e/KKFTiWv63K5jIWEer0earUa5vM5er0evv7rvx6f+tSnKosgGWPuD/w8Yk5w54jWje2W7RLP/ZlvwBP/8Fksn/m9cx2WMQ8LrzdH8pr8x/gFANeOXz8G4Muy3bPH7534D3cI4YcA/NDrPP8DQaPRQL/fx3A4jMKiqjE8K7NqsZmqkNTUaazitHBYDVusElIaBknnjFU2daz6UK9OogpXnpcOmeZi0vFSB4zvM9wzDcdUp0vzCjnulFQE6byqQoQJXcDTcijT+VWRbqeCLYQQ1zTP87iPun/peFTIUlTVajV0Op2NUFYdq+ZUas4lq6jS7ZvP5zFnkWPV83Cs+gWEniMV92l4MbfXfFC9pzg+De/Wa6RhvDyefuHBY2dZhp2dnTteF2PMfcub+jySo31+IzV3lbJRYvxYiTJrvfrGxpjXxBsutlOWZRlCePW4gpP7/SSAnwSA17P//Y6KrsPDQ+R5Hh+gNQyUYYTpA3OVUFSBoCGYVbmGWuCHpGJSc9g07JNCjc6R9iZkcZTU+Uwf+glFCnA7dJGOlYoubqeimj8qhigo+dlpFVQ5fz13uk5VwoPjSHMddR9dez13lRiqup4UaRR0WuX24OAgriv7JKoD2Gq10O120ev1Ymio3hcapsr5MBy2KIq4LsvlEvP5HNPpNDqkdMfn8zmKooiiX8OPyWkFmvhZOmded36JotddXUS+r/mgura6rrz2KpTv5EYbY+5v3oznkX4YPHTPIw8bZd5EaLZQLuZ3eyjG3Pe8XiH5IkNEQgiPAmAli68AuC7bPX78nkn4xm/8Rjz++ONRkLGYioqw9EEY2OyXqKQP5qmQVDdThRiwKbBOyyVU4ZaGr/InFXE8Fp0oFQQaqpqeh0JV3+Px6V5RxGRZthH6S1Gk4oloMaGqueo4dA1TVIxUba8FcLi2nDtzITnver2+0eZib28Pk8kk5k6+8sorWCwWmE6nCCFgMpnEMTAkliKt0Wjg6tWr2NnZwc7ODgDE8E/9ckCda/ZeZB4hw5QPDw+jY8zxqRNdFEUsEDSZTE7cU6etqa4HxWOWZXH9tPCU5tJyrVT8Z1m24UTrNeDxGRa8Xq/x3d/93fjkJz+JZ555pvK6GmPuS/w8Ys7EF/7TLQz+zQex89OfuNtDMea+5/UKyV8A8P0AfvT498/L+38qhPD3cZTUvu98hGq2t7dx6dKlDbGh1ThTAUnSkEFC8ZVWB03DVzWsUgWk5sxpvqKGbaa5h3S2+DOfz6MwVuGiFUdV5Ol51KWqKvTDbVRUMOyXv1moh2j7lDTMksc4bT0pXlPHUkN11d1UAaWhtfoFAIANt033Wa1WmM/nODw8xGg0QqPRiC0stN2FOosaAp1lGYqiQK/XQ6PR2Cgwkxb34evFYoHxeIzhcIjJZBKdx1qthtlsFvMNi6KIbjDDe7Msi/cre1+mvTdJVf5o1RcfVSIwzd3UL0j0t64PhTfzQoGjQjynhXsbY+5r/DxizkRZBw6eClj/4Edw6ac+CaydO2/M6+W1tP/4ezhKZL8cQngWwF/E0X+wfzaE8EcB/C6A7zve/BdxVGr7izgqt/0D5zDm+5parYbr16+j2+1uCC4+NGuIJh/U9aE7dXeqqHLSNA+R+1YJSwoVvlZBqm4kj7larU6ErdK54nHVYeR86FDyeHzgBxCFZ5VjWFU9tF6vx/XT0F4KCRXpaSuLVHi/VjgPzbc87Vqk664uIuc0n8+xXC4xHo8xHo9Rq9WiINK1VVFGEcn2Hr1eL+ZF8j7SMNoqAc0QVopBhg4vl8vonmqIrDrTHLvep0QdQoY3a95qmter49QCQvxiQsNnVUzqFxIq9NMcXa6vxaQx9y9+HjFvFov+GvvvDLj8gXcjLFYIh1Osvnjjbg/LmPuO11K19Q+d8tHHKrYtAfzJNzqoB5k8z/Hxj388ikc+/Kr7yJxILbJyJ+cMuC2MNIeP7+u2qUtJUldNH/Y1TFMdyCp3iA/xVdulbiZFAl/zPBQOqQPKczDEkVU9Z7PZhvClO6bFYtSd4nE1VzBF8zP5N0nXNs13TAsLqShO3TngKPyUjtlsNsPBwUGcJwWROqQa/pvnObrdLvr9Pra3t2NRIh6PlV85bwouDROmKFXRD9zO46Xg1hDmVMSpEFR3UAWorpc60VwvdeYZckuHlS4rx6xOJHC7eq9+CcPKwgDiveD8SGPuX/w8Yt5M1s0SX/hPugCA3o0dXPvxC6zkahfUPCC84WI75rXzzne+E9/wDd+w4UDyoV5hXhjDNVO3J22TkYo1/k7DLVMRSWHBn7RIj7pNKoYoBLh/6vJo+GmV+KRw1Lmo26TVQ1MRyXOrgwrcLlDD3pucM905DfVM8zo11FRzPTUEU1+ryEwFNddKr5XOnX+rg0aRw/zO2WwWxZf26eTfaQ/PPM+jm6iusrqgdC+51nRBm80mBoMBAMR113YpFPgU4qk41HtI11Zfc1y8ThSneqzUlaTjrP8+NOeVXxjoKJ1JQgAAIABJREFU9VosFjGn8+rVq6jVanjhhRcwHo8xm80wHo83nG9jjDEGAEZPrDH+y193IeeqTwOe+Mu/YTFpHggsJC+QVquFfr8fq0fyoTZtmK5CMnVQ9EE6FXjqHAInHTM+vPNvOoIqJnkOFQ9V/R0pIFKnSVHnLg2vZI5dVaihClYVG3p+3ZbFirIsO5FTSFePgkQFZCpw0zGmc9GxqphMw45Th1KvB51GfsaxTqdTzOfzE+tJV40/LHzD1xSZHJPeF1VhyxSRXAstosO5p2G3ADacQHW8dV66Buk6aE6tXsMq11pzLUMIG70k9YsLLeDE4y+XyxjuC9z+tzWdTjGZTNxH0hhjzAnKOrAqLib1Yd0E9v7w1yGsj58Z1sDWP/gtV5E19yUWkhdEURRot9uxTx4fqpm7Bdx+INdG8PqgzG1I6nKljmMqHHUf7kfXKRWG6mbpufmjTeZPCw9NUTezqlor/9Yx64N/1bnUuaRY4ppqXp26oOoEp0L2tPlUCajTSAWpOqN6HF5finbmKXJfhq6qkCyKYkNIaksLFcqpuK/VajEfMq1ay3Ol41MBn7bgOO1Lg6o1TMNY6YzqtqlTrmKS/ybSYj7qnvKeXa1WUWCHENDtdnF4eAgAMczZGGPM/U3jsbdgNLg/+0GWjRIvf+3tv8MK2PnXTyJMbwvJ1e89i9IRNOY+wELygnjXu96Ft73tbWi32/GheTqdAsBG7p6KgrSHHnDSZUyrYaYP+KkIJKz0qQ/5KiQ1Z01bdagIVdcwFavp77Typu6reY9aDTUVbWnobVpNlgJXxSPnRnGuuYB0WylUtH1JSupY8jqlwjudm76nbqEKNDppbFXBeWRZhk6nE9eu2Wwiz/M4Bh5PRX+V8OZ89vb2oqja3t6ORXS0GI3OX11bCvM0v5Pn0RxerrHeA+qW3inHVAvnpGPg54pWAqb7yFBmCvE8zxFCcGirMcY8IDz7fU9i9MSDkfNe1oHP/7GBvAG86384xOrmzbs3KGNeIxaSF8hyucRkMkFRFABut7DI8/xE3h5wu7DMaS6KCigKDcKHdX1wpgCiaON5NRQ0DS2k+NLzaQXO9Nh8zcb16/U6OrGp8FGnkCGcVSKOx9QQTm29kbpfzOtLC+RwPdW95PHS8EpdwzRvMq18y/dTMa0ObJWDpwJIq4yGcBSu22630e12N9ZchZMWy+FPGk6sY5xOpxiPxwCATqeDVqsVx6JfGHA/naeuk65RmgOb3hup46zrw2uhFXd5P+jaMHeTY9Dz897UYkDqYDabzfjvoipU3BhjjLnXuPEn3wGs34HWEHjkr/7a3R6OMadiIXnOhBCQZVl0i+bzeRSSfOhmY3UtbJMWHyH6gK9FcvS1PiynxXDSgjUqgNKcR3UlU2HE8Fw9no5/NpthNpthsVjEB3p1WrktharmXr4aafEdjp3vUWylc1JXlMJbRWLVudMQ39MqvVa5wbpmVUJKz6HXSEVjKgbT/TWUNXV59Zzr9Rp5nseCPgA2QnvTkNg7oedLhSSv5Wn3YJVbzWNynHp/nIaGs6YFoYDNnM5XO5Yxxpj7g1qe4/Db3of51t0eyTkSgPnWcUXyImDyB46KALV/9xDlv/rs3RyZMSewkDxnQghot9sAEPPgtKpmrVaL1Ub5wEs3Ja0AmoqS1KlS5yYVBZqTx331wTsVIxQFaQgpf1qt1kZrimazuREeChwJFYpJ7U+oD/fqQKWCKi1uo45blYDivLRoELfNsgyHh4cbfSU5P80TVPRc2j5E8y2rHDq99qkw17lUXUuOn8dPQzurxJ6GzOraa4gpgOhAcx53CvM8TVDyXOlapUJd1+9Obm/6HqvoqsA/DVaqZVhuURQnCg9piHiVM2yMMeb+oNZuIzz2CJ7792ooaw/Hl4OrvMRXPnr0/7Wdz/Rx9bmrtz+czbDa279LIzPmCAvJC2C9XmM8HuPw8BDj8biy0TodvbQojIb9VYVOsvAKQ/jSQiYqSKbTaRRtVUIybRehLSpSkZkeJ21roS7fcrnE3t5ePEa73Y7zZxhnGnKqYZ4cH4VPGrKq68H3KMTV5Ww0GhgOh7FNhOY6pm6uhkmq2GRepVY+1THcyUnmWqbOJq8hx80CO2VZYjKZxL9TJ5rnozivytdMhSSAKLw4l1To6hcG6hTydxr6yi8yeGy2YNEvJKpEpopGHlvDT09bS723F4sFptMpptNpLGSlX1IwxJr/rl6L422MMebeY/LR9+DL31p/9Q0fUF55T4lX3vNU/HvrtwOu/MQn7uKIjLGQvBBCCDE/jT3tKA6azSYWiwVardbGgzXdFj2Gujp0AYui2GjfoUVN0vDCLMs2XEM+dM9mM9y6dQvNZhPb29vY3t6OBUr03Bo2qeKSpM4e/x4OhzE3L89ztNvtjZ6FaTVOFQL8u8qpTB3XqnxBFXrNZjNW86TY0fxPFTA6DgpNXhP+0GFNwya1YExV/qW6ZKl4BLBREZdzS3MH9Zwcu65RuiaNRgOLxQKTySQWeep0OhvnSMOd07zE9Lh6bVRcHx4ebrirrDSbfmmh81H3V38r/PeRilp+UVOWJa5cuYIsy5BlGRaLBUajUfzsmWeewWw2O3FcY4wx9za3/thHMHo8HPXKeFhJvlMdvRVY/ulvwFv+2m+i9P/bzF3CQvIcYcN4CrzZbIbhcIi9vb3oyqmjpyKsqlgMsNlCgwJEwwwpcphnRveNjeuJChO6lcvlEt1udyN/EDjZh5LHVgGQwjGmTqm6j+qsqUDi8dPWJ1XhkPxcnTjN3dNcORb14fx1W3UzVYjzR0VquiYK1y4NM9V8RK41x83rSEeO60JBmbqjel+cFuaqc+F2PD4rsFZ9OVE1r9McQd2Hx57P55hMJhtz45rrGFVUpmJSz6nz57XWkFV+Pp/PMZ/P0ev14hc0s9ksRgLs7e1hMpmcer8aY4y5t6i/4ynMH9sGAAyfAJbdh1hEVrDKS4zfUmL+0feiNl+jMZyh/E3nUJqLxULyHGH7Brox0+kUr7zyCmq1Wmy9UavVUBQFOp0O8jyPLRk0Jy99wFbxked5FEGaL0YxyXBWChyFApf7Eoa2npajlooZPthzbOrS0ZHiGDRklmKhquKmitWUKrGT5uNRqKoYpbBNhYg6qRpWq0VfGDrKeVCI8zcdTs6X15C5r9oblLmavEfolK7Xa0yn0xMim+iaqxOoIcypc6trq2I2vQYqvvVLi6oiNemXH3R4GWI6Go2i69lqtdDv9+PxKOx5nKrc2PQ6cy68Bgx51TzXxWKB8XiM7e3tKCRHoxGGwyF2d3fx4osvnji+McaYe5Nau43dr7uKmx/iO/4SsIqyDvzudxw9yrefz/H45zpH789m7kNpLgQLyXPk8PAQ8/kcTzzxBMqyjA/aBwcHyLIsiqpLly7FXEEAG+GT6QO2upF0+vThn+Gq3I55YxScFKFazKfdbuP69etoNpvo9XpRbKUClmKElT+rQhVTd7Fer6PdbqPX60UBkhaQ0d6RWtmVx1ZBodVp9b2qnE8VtBTzDKmt1WqYzWYbYabqls5msw2hoy4f145jXS6XGI1GAG4LJ7py/JxFhxhuyZ6R7XYbOzs7J8Qs15zhrjqv9F5QQZ6G9XJ9J5MJZrPZxpcW7LvIOaXzrRKRHKd+IVCv1+O9PR6PMRqN4nrkeb5xH6f3ir7H41Mgaw4w/11U5YJmWYaiKPDCCy/gxo0bKIoCWZZhNBrhs5/9LPb29k7MwxhjzD1KCHjmz34NFj07kGdh/MgaX/hL7wMAPP4vlsj+0afu8ojMw4CF5AVAgciH+263izzPkWUZWq1WbA6/Wq0wHo8xnU6jkwVsFkHhb4qONARRxWhZlmg2m/E83Fcf1IEj8dNut6M4VaGUCka6WqnIoAhRUav73qkCp4o0FZUqOnTuGvKZhmTqMdXposCikFQhQtFJgcxjayEkbsdjaXGger0eHUa6nvP5/MSYKSy1Kul4PI5hx/V6HbPZbOPYOi8tTMPP0lzKKnjNVqtVzB9kDqy6lNqXUosRcS30R11JXRMNuW61Wuh2u7GH6KtVYeV10y88NCxaBb6Gc/Mep5Dl/fHSSy9hOBw6nNUYY+4TGm+9jue+6zoWnRKla6OdjQCUjaP/3730tU30Bh/B9t92MR5zvlhIXgBaCAc4cqHoCuV5jn6/Hx/ametFIalOm4YhaosIvq+Ch4KOIpKFYigS9OG8VqtFIVMlGtP3qtyqqjw6fT/9PA1r1eOT08Id04qi6frovulvFSEqRtKwUv2toZQUVdyH14E5juqiaT4rP+Oac39ea+3DqTmb/J3OLS2klOY8pmun808FIXNpWYhGnW7uq+5nKmJVfKqQzPMcW1tb8UsMrSar1/O0eycN8VUnMxXaGl7LfXd3dyuPa4wx5t6j8ba3YvSeazh42k7kG2V2aY11K2Dng+9B+Lc3sD4ueGjMm42F5Dmjzgpw9FDe6XSwvb2NdruNoiiQ5znm8zlmsxkmk0lsV6A5cHx4VnGZPtir6KMwqeotmYaHshiPOlQMydRjakXYVGSq0NL37iQSgM2wVv6t4qkqtJdzpsOrQjKtNKrFe4Aj95XbMDeR+Ym7u7txfbvd7kZF3NRN07lpgSSGiabijjmnFJg6TuZXchxVzp+ugxZSCiHELwvUbVURyB9tN7NYLGLIKAtBjcfjOC46lrwXqpzg9J6kiGw0GsiyDO12OwrJtGCRjlOvm96rKjzpJuv9z2vJHEnmCNuBNMaY+4vQaODFb3kLXvlq//f7zWLRK/GFP9zDu/7aNeB3ngH8/0ZzDlhInjMhBBRFsVFNcjAYxIdgFl9hOOt8Pj8RVqr5gAA2QlD1AV8dLT6Ia+4bBQHDLzXHjeGHwO0Qx3QcmvuYho2mlURVKCppHiVR549/87cKSxVJ6Wt1aSkueC5WKtUwTa5BWd7u18m8QW2Tos5k6rBqERi+nkwmca1brVY8JoUW11tDOHlOijAKMs2Z5PkpmIbDIdbrNbrdLnq9XtxP7xfOQ4UXvzBQIcZ7cTabxXtQ80k5Hv3CIr0OXNPt7e2Yl1sUxQk3XdeUx9ZWKCS9p9jChuPNsizmt06n0+jmv5YQWmOMMfcGodnCM3/hg1i2LXTOgy/84CO4+lvX0P3ZX7/bQzEPIBaS5wyFZLfbRbvdRp7n6PV6AI5EFh9+2RIiLbCjD+nq4qSODtF9KfrU0eKDu4qoqlBDzZHTVhkkFZK6b4q6SFXj1FDJKgcyDeNkiwzdRo+Vhm3qWFNHl3NsNpvodDpoNptReFWNpWqMOvcQQqycCxy5nhpSTEHG9U/DhFVAp2vG+bDFxng8jnNjjicdbvZRZFEfdaHVyeY9wOqxrLo6m82iY97tdjcq/qobnl5vCjw6vel6qZut7XF4r6ZFgrR6MeHnk8kEk8kEL730EnZ3d2NxpfRLCmOMMfcm9affhpd/3yNYtkuU9Vff3pyddVZi7+kayj/49ej9zG/YmTRvKhaS50xZlhiPx7h27Ro6nQ6KokBRFCdcP7aIqHJ7KIz4wH1ayGhaXbRKwGkeG4VMlTuYnkdDDTVckn9zPx13VX5iuja6X5r7R5eM0EmjoEpDYFPBrI5Xui6p09loNGLBIa1mque50zXW9aPwSd1iOnZZlkVnkZVcq9ZH3+P86BqOx+ONyrDMD9zePuq51Wg0Yrg0w191rdWlBjbzeEej0cYciqLYuOa6Lpq/mLrX/KKE2wFH9yhDaBuNBrrd7kZuLkU315O5m1p9l8dZLpfY39/HrVu3sLe3t9Ez1BhjzL1N47G3YPRVV3Dr/f5v9nkzvbLGohew/VtPoXz2eedMmjcNC8lzZjab4Td+4zdw/fr16NDQsWIIobpD7EuoFVspRtiWQ904fbjXthl8uNfwWBVWdMTUxVE0PFVFqZ6T26mrWRWKq65UKvgo4jQ0V8VbmiunIbpVTm3qvLHQC9eGx6cbpgV02u123JcVXHk+FbqpWEkFIHsb8lhpsZlms4nFYoHJZIKXX355o3IrgOi4avgz57derzGZTGKLDRXF/KKBxW4oODWEuUpw85zqANL1JBpGymOwiBNdXN5LDI/lNv1+P4r0+XyOmzdvYrFYoNls4tFHH8Xly5ejq6rCM4Sj3qv7+/tYLBZYrVbodrtxvJPJBDdv3sStW7dwcHBwIm/XGGPMvcuz/+GTGD3pwjoXxSov8fk/fgXv/N+awKc/d7eHYx4QLCQvCIYbAoguFIWNPuSre0PoHtKN4Ws+MKvQUneH4oOuznK53KjGqaJI3VElPYeGiFY1tdfzpsfgfio0KSTTfbRYjo6JQqHKbVXBpcKP86QQ4mcsMKTjT8etrp0KXZ2nOrt6nBBuF4hJi9bwC4PRaITDw8ONtUmdXD2XCuhUvLPaqlalpWjd3d2NcyfaCxJAzDOkAF6tVlGw8ksOzkMrs7IoEdeb4bFlWcYxZVm24TxTsO7v7298scHqwbzH1+s1Op1OdEgZCsvzbW1t4fLly7h16xaef/75uJaNRgP9fh/7+/sxvNcYY8zdZfVNH8BXPnr8pWnHTuTd4Evft4Od9309tv6OcybNG8dC8oL49Kc/jbe//e146qmnNoqzaHERChJ9DzjZ7kPdRWCzKImKUG5Dt2g6nZ7IodTXKiy1eAxw2+FUp1RRAadCTj8nqeuYhs+mOY3pHLmPzo/7Umioo8nPVEhWhatWzaHq3KnrxfVSgck1olCmgFd3N8sybG1tRWe6SiSm59Y8S94vaf6lFrRhqC7Fnc4rz/MTx9JCTACiy5jn+cYcVexxe56Xx6NY5r0DIBbjGY/HWCwWGB+H1/T7ffR6PXQ6nQ1XmQWT9L6jOG21Wuj1emi322i1WjEklwK2Xq9jOByeuM7GGGMunsW3fBC7784w37YLeTdZdkosOo7cMW8OFpIXxKc//WmEEPDUU08BOFlMhQ7LarXaaOOQ5qOl+YYa+qliMz0H8+jSwiekKu9Rm9Wn4YKp2OK51KWkwEnPo3mOaVVS/tbXaZGfFIodCuZUSOq+Kiyrwnl1TiqGq87L+aVhoqkjzNBPjpXVWZvNJvr9/5+9N4/T7K7rfD/n2fd6qnpLp9PZOs2aTgAlAqJkBh0QGWFErzvD1Rl5CYMyolfuXK/OjOO4IC6DXhXEccYZVOQyglwEXBFIIAmSkJi9O+l0J1Vd67Of5VnO/aPy+dXn/OpUdXfS1VXV/fu8XvWqes5zlt/5ndOvPu/z+S4NhGFoii3ZIKnH4jG0aq9W4iXY6YsGjimKIgNtXF/nleuyqA7dcs6VOtmj0QjFYtEU9lEXkdezWq2ueykAwFQtrlQq6PV6WF5exvLyMrLZLKamplCtVhPhygASL1YmkwmKxaJpL8LqswAwOztrwn21qrGTk5OT0zYqk0Vu/16celkR4Z6tgchJZQwUrH2PPWS6T+fVFydAeZOK3sMMMv3Lp9rPJO8he2A/xmfmt3soTrtcDiQvshQcFUS0GImCpOalUQyNDcMwkf8GJJ1CgonnrVaOZR6eOlm6X60iqjlz/E7z69KgS5vH27mTBEqCpIKMhozqj4axpskuxKPnDCDRl5EhptyGcKJupYaIMhwyLXRX807tfEO9ptyOua08F54/Qz61BUyaW6rHZ/jnaDRCGIaJcGi6i/zR+4bwxWtJAKS7xwJQvLc4HoJqvV43kDkcDlEsFlEqlcw9pdVoOdfMeez1euacCoUCqtUqKpUKisUiut2uaZei10UdZ4VRfYEyHA5NDirdTLZbyWQyxkV1cnJycto+5Q4ewIPvuhrA1jmRP/bKv8Q7px9PLPtiMMb3feztAICX3nQcH77+rzfc/n929+BnPvmdWza+nabO9RP03nUEN/xMB5Mg2O7hOO1iOZC8iHr44YexvLyM17/+9QlnjDmCDAekw2LnLhIqfd9HFEXmgb5cLq9rz2AXpWGPwWKxmNr2g+4gj0tHSqXum4Yf2i4Zz4Owq/tSUCIMaFEbO0yUxyVMEDQIHgoYPK4N6wwvtcHTrkKr3yno2s6kzpWdp5m2jMV3NHSULwniODY5huVy2TiT9rlT3J4gqK1ZOPccu84DQZHjoZvI60agVdDlse3qqswvZfgoq9BqvqVe63K5bGCX+2d+6szMDACYfXAMdqVXXiN16ens8nwY5spCPrVaDUeOHMHKygqeeOIJODk5OTldPM3/m1dgWMVqWw9vayAyzsV437f8N3xdcQlANfHdTYUxPvht7wcAXJPrAKhtuJ/XV0/jim/7AP7VZ34ImeAyeAHpIludLpAcSF5EsecdgESrAjsf0S5sAyRDS+kURlFkANIGO0orevLBnw/jacVo7IIyKnUfuS91oggXrM4ZBAEmk4nJAUxzlQiTPG87vNaGNJ0XOzSVy/QcFI51HQ0JtiuZquNKmCKk6vZp14ZzbsMf98E50zFkMhkD+jouO5eUx1LXkdefxW9sgCS0ssIql9ON1MqyOg86Dr6s4LnpvaRFoGyAtp1y+76kk+j7fqKYj86dhteq26shwtxvvV7HgQMHDPzyxUkYhuvuEycnJyenrVF2ehrhS65H/1CMcWnrCurE00PceN2T+KZyF0Wvuu77SqaAW8v8/2RjiASAqUwZt5aG+JobT+Arjx8GFotbMOKdpTgTI7j1GCr3nMJodm67h+O0S+VAchtEt84GhlwuZ0JKNb9Oq3ACyQqe6igRFvi9hppqzpwWcqFDxLFoG4e0HEcFCYIjfzPUsVAowPd9ZDIZjEYjUxBHpdBsQ1xa/uK5yi4aZAOzgjNDIHUMmsOpTrEN2not9EWAXhuen+3a0k3jPunOZbNZ4+LqHFG6b7vQTaFQQK1WMy1DeK3YUiSbzZrWGQzf1ftC96svGwCYMFaeHyFUQ243ul6EWK7DueexarUa2u02ACScWL1O9jaTycSE4GqBoWazaUK38/k8BoMB5ufnDaTr/p2cnJycLqwy1SqQySC+5iAef30ewBZCZCHG0cNn8PGjnwKQX/f9yniAlvVCPOsBV+c2Bsqsl8FHjvwV/jfv1bizewSZ8NJ2JuMs8MRrsrg2OoTCSsuFuDo9IzmQvMiaTCY4deqUcVQILXwwD8PQhAM2Gg0cPHjQPLgDa/0Qc7kcqtWq6dFHiNNwTrvdAx/GdSxaqAZYK1yjIKn5jnSSqtUqyuWyKXrC9iaEjsFggFarBc/zMBgMzH55DrYYaso5SZOGg9rgYi/T1ioaNkuA43d2eKt+VjdQgUadN60mymUabsrKo8yDrVQqyGQyCILAOLEEWgIewTuKogQscg5sl7lUKqFSqaBeryd6cnJ/dOZ4HjpnKsIpgVbDcW3Y3KgQkX0d7KI/Cuye56FWq5kWJd1uF/v370+ERqsTzJcWvu8jCAJ0u13jrpbLZVPEhy9U5ufnEzmet99++4b3lpOTk5PTM5eXL+D4/3UTJoWL09LjF7/5j/Gm6gqAdNj72r97O674eCGxzN+bwZ0//VvIepsD4h9d95f4u4N/hx/++L++UMPd0Tr5rXlUb34Jrvi127Z7KE67UA4kL6Kmp6dx8OBBnDlzxoAVwYbuVxRFKBQKaDabieIo/H48HpucSM/zUKlUTCEdLrNDR223D0Ai51JdNjuMUrcnmBAkWTSFMEs3slqtot/vI5PJmAb0PL7muPHc9HgKteqmUgRAPZ80oKEDpr0PdR40bFbDa/mZTiqPTcAljHO5LksLw7XBiRVc2UdUgZe/6bpx/wx5VXhjKCvdaDpxdgEgfVmg86gvBjjX6qLm83lUq9XEGAmpek4K1vayNBfcDmHlCxHf91PdXhvUuW/2pdTcXDqVnLdCoYCZmZlEcSknJycnp2evTKWCube8yHBc7K1WRo0vkolX8MapQDiOJzj6kbeh+YCHzMiq83COQSlZL4OvLfbws9/ykXMezzDO4ef/5g3wot33/0ycwUW7bk6XnhxIXkRVq1VceeWV6Ha7ibDPwWCQyL+jg6R5bOo0lkolAwZp61A8Rlp+oD7Ma2VWzYNUQCDgqANWq9XWgSQrgNJ149/2Pu1ladL1OQ4NReX58LcClDqRQDL/cqNcTRvAOEe2E5oGazaYbgSVvC5pvS55ngRHO9STIbYEKIatauEbe5/clse1Q24VDqmNKttu5ALrdbHnwr5OGgrMcfE8CK3quHIOOFZg7eVDsVhcV+FYX8xks1nThqTT6WBqagqdTifx0sDJycnJ6fyUPbAfw6NXonvk4oHjuejhYR/vmftn2H8nkO+vr/OQiYC3Pfn1yHoxbqmfwFsaG7e+mMqU8ebG4jkfexxP8F+PLODJJ2eQ6ey+R+tRCfC+9kbgnocRD6PtHo7TLtLuu9t3qTKZDGq1Gg4ePIi9e/cm8rwWFhZMC4RisYhDhw5h7969aDabpq8eQY5hrwQOhRIFAtt9sx/29aFf1+Nx7AqnmhdZKpVQq9UwNTWFer1uQJIwy5w/uqUKOOqs2k6eumYbVSC1w1UVKjWXzj7XtPO0YUf/JmBrnmhaWGiay6f7UDgnHGpVUnvfhCB7LIRILdpTLpcTOYJpgK15sJxTzj9dPHt+7XYz3B8hj706bYdbX1BonqZd1EhzTsfjMWq1GorFYiKsmi68hv3SWSRU8uUF55Uh1BxDsVhErVZDHMcolUq47rrr8Nhjj2FpaSn9H6mTk5OT06bycjn4L74GT7xm+3ouxtkYmZRWIn/Ueike/MUbkX86N9OLY8Ty/3upPcb9v3ATJjngL159E97ydEXXC6Gsl8Hnb/ooXld8HR689/Dq8ce7x50M907wyPfW8NzHahgvLW/3cJx2kRxIXiT9wA/8AK688koTkkeQ7Pf7yOVyWFxcRBRFaDQauOqqq7B3717UarV14X1xHJsQVjtvjlIHSQvBUOqMaYgmt9UcQh4nl8sZiCyXy2g2m9i3bx/q9TrK5bLJ/SPk5XI5BEGAWq2iIZRPAAAgAElEQVSWqKxJkOSxbIjj8fS4Kvt80kBZXSy7lYaeM0N1+Tery9o5pjqXOr82uNvhopxXhUVtb6GtUhRqCU0AEu1ROE69hhpCCmAd8NpOql4HhXUtAkTHTh1r7oPfpQGwHQbLOdQXE3wBwnuarTq0hynnVdfVY/Pc2QJHj63hrrz+fGFj/ztwcnJycjo/PfWjt8C/IsZWFtLZTJPKGHe+7tcxnSljo/xISiFSP7/y330J7957G4DKBR/fR47+GcIbVp87XvKXP4pM2z1mO13acnf4Fmr//v248sorcejQIRw4cADFYjEBE8BqWOLU1BQAIAxD0wtPq6/yb3V31PmyHSUFybQQS32YVjjifu2HbQIXw20rlUqiqTy3UyeQ49aWI4RnO7RUZYfWav9HQoZCmw06mmPJojVpx1JY1X6FWmVVcy51fHos7kvnVmFU51BfCNiuZBpQ28fT87Cvkd4fOm4tnKR5igrsPF/Nl+XcpjmxCr420Nvj1+thjwlYA23Ohb5o4FwpxOpcqfvIMXBffAHBNjSuBYiTk5PTM9Qtx7DygtVqp8HeGJP89kBk9bo2fvDo7dibXd/q45/84xvw1B1XYn+KU0nRoTyQ72A6e+EhElhtOVLBapGfn3jZp/EHJ16O5UdmtuRYW6H5b38u9t3ZxuTu+7d7KE67RA4kt1CNRgPXXnstnve855k8MIUpPszTeRyPxyZcT50n20lTaQ6hDZEaOpqW46bb28VMFDoIknQjmR+p7ipDJW1IsnPw6BDax7QL5ei4NGRSpW6kDTsaTsnj2X9z/4QOrWCrzqKuT+k6GzldaSBvn5d9XdPCbO3t9bw22rd9/vzeDoPW3Nu0FxB6L+k6DPtNA2tbhEX7PuXYtL0Nw145djqSCp9ch5WP9fz039VwOMRgMECv14Pv+xvOqZOTk5NTUplSCd7VhwAACy+sYfmm7Y3m8PaHeM3VD+Kd048nlo/jCT7QPozZ26/E/q9sDJHAeodyq/X25iksHq7jDzu3ID5TuqjHfkbygJUXxKg9VUXx7u0ejNNukQPJLZTdfJ6uShAE5iGZbT7K5TLG47Fx/LRSp4Y62tChD8Z8uNbjKVwQlNLyBQlT6kjxeMzHI0A2Gg1MTU2hXC4jjmMMBoNE9UwFFs3hU1dJw13tRvTq0ik4acglQxZtSLHDTjX8V8GDuXXqSios5fP5BITZ+YeaG2gDJf/mcdOKGPFv9jfk+urepTmW9m/75QLX53zZLwrsnFoFWQ2ftWFU4ZJzqC8ObNlzZefwqnR7u4pv2ssEhV116HX8uVwO/X4f8/PzmJ+fx8rKyrp/L05OTk5O6fKuPoSHfmTf05+2PyXgQ694P24pru8XuTTx8d//4z/HvjD5/5DmR9q5kmNcvP8Hfnbf/fier78T3/K/3rUTptHJ6YLLgeQWSh05IAlpbAHheZ6pPsnwUTu8T8MJFVaY46YhndqvUXMBGbqY5hzZeWsADMgq7DabTdTrddOvj7lv2lfQfsDn8aIoMuGFOieclyiKEMexKdZDMdyS4Mj9DYdD9Ho900eQBX4Unu3Q3yAIEEWRWaagqOAYxzHCMFwXhkxpfqDCu84nf6e5rfY1ZPiu7sfOhdS/bbDUdfRaaNVZGzgV0Eajkck3TIMtBTp7THoNNwuP1n8LaQ6y5lcyv5HH03tc/y3ocWz3l9/5vm8cyUpla0KZnJycnC4ldb/rZVg65mGnk89bT78cd/3ei1AJ17/MVHC0ncgP/+o/w2/fGuLEN/3+WY/x/N95G2q3LOLOl3z4GY/zSK6Mz/yLX8FrPv8OxPPFZ7yfi6WnXplD+egrcMWvu76STmeXA8ktFN0ogqEdckmAYgsPhpDarqM+LJ/rcfW3HldDH9OAS4+juZGsztpoNFCv11EsFg28qhNJ90nDbAl+6h6qdF1tY2KfL6GVY2R4JddT15DjT/usIZaj0cjAHGGazjD3r6HIOld6frYzmRYOu9G10r6RCmM8ju0M2uei23H+uQ8NUdUwUGCtp+NwOITv+/A8z7zQsMdoQ5qGJVO2I8u/7e/te1EddN4jqrS5V9dU50VDb3O5HGq1Gur1Ovr9/qbXwcnJyclpVaOyh1F1Z0Pkax/8Vhy/62pcsbB5OGuaSisT1O4u4cba9+HLX/cHKHrrnU7qim94EvOdGp77uTebZd947XF84PAXzvl4WS+DI/ka3nLsdnzsiZt2fM7kuBRjWHPRO07nJgeSWyiGsSpE6oOyPlBrL8g0kLQrt6a5lPpgruvaeW4bOVSEK12HjmS1WkWtVjM/uVzOuHt0RtPGrGBBx0kdJR0/t1UA5Hb2OO1zSCt8w/Xt7xWmCVIESTqTURSZ/RPAbHeP56GVWOmq2uegY9kMdm2nTb+zr43t7nGubQdUq57a247HY0RRhF6vZ3JzCZIKiWkhtGkQaV9LrmuHo9rhy+o26jzyvLlPvpjh9npPUTynXC6HqakpBEGATqdjXG8nJycnp3TlrjiA8Q4yzeIMgKkhSt4YwBrwnfy7a3DFvePUbRjKaoe06uepx8YYzdbxiRv34FXl2XUFfHqTALcFdXzqBR/BS+98M2b+R83s42+/4Rg+84Y7zLr7sz28qHj2SfvpvQ+ilg3wG/Pf5Kq5Ol0ycnfyFurhhx/GmTNncOTIEdNeAVh9KC+VSuYhOJvNolgsolAoJCBAc+gUyoA1wLJDKjVEVWFJ3UA+gKdBlz68040sl8solUoGtgqFAvL5vAn/VPglLAyHQxOq2Wg0UCqVMBgM0O12EYYhKpVKIiSVOZocv+6TY1fnk3mMhBXOhQ3inAN1DDWPkK4j981rQZDksYIgSMyVun52yDD7LOpxbCfTdtMUvjQ01XbsABjXmn0WOe96jyig8nprgZw0N08r7Oq9lfbiQa83j63gyDGwUrHv+4iiyIyhVCoZJ952iZlHOxqN1oXxaj/TbDZrQp65Led/OByiUqlgamoKURRheXkZnU7nrA6xk5OT0+UqL5fDI++8HuPCznnh5s2EOP7q/wrg3IvVEBY3av9B5YIYv/5T34NPvfu+dQ7jx/qH8Dvv/g7gPcnw19jzcPDzMX7u8z9olp25JYOH/+Vvn9PY3jn9OL7/m38Dt/yvH99VfSadnDaSA8ktVhzH6Ha7pjE6H7gJjXxYZo9GdVe0bYY+9NvFSWynLC3Hzc4J1Ob0Cpfcdy6XMxBZLBYxHo/h+z4KhUKi5yShz3b+2LtvMpmYXpOe56Hf75swSsIQkAzVVEdVgULhzPM81Go1c36EHw2v1fOxYdoO+wzD0ECK5mnyuGEYmj6TOjbNTeW+tDLtRg6pfa6cT/2OY+UxJpMJSqWSyaPlOdnrc192SGha+CehjmDPcGsCqn0P8RxtuLNdZs4bx8njRVGUyEe1t+f41G3nefHa0+mfTCamfynvUf13o+5soVBAuVxe15fUycnJycnSDuabh4d9vOm3fhLNU09HdFmu42baaN0v/8FNOFa7ObEsGwJ1jPGT7/vXKPRiYJO2IjP3xTj2a28zn/tXTXDiO3/nnMa0UxVNxXjy3a/ANf/tBEazc9s9HKcdLPdUtcWaTCbwfT9RGVT74WlBEUKMghrhR4FEQ/0oGx7Tvle4UCjj/jWckw6guj88NvdnO0k2qKjTxQd4AkoURebh3w7N1fBL/ZvFWjjuSqWyLsxX4dB29za6PoRVtjDh3Ch0EPxtp84eq56/OqEbAUxaxVP7eipIEnJ5nyj4p0Gj7i9tfJxXvsigk6yy7z+9R7g/fZmg10lfGNBJLRQKBobTpPeRfcxsNgvf903hJLal4b4VgAn4vDe0rY6Tk5OT0+5TEGfRfHRs6gDZYLgZWG60bnVuY0hsPJH+7KDKD+LVMZkdZzdeGUDJy+LGm0/i3uNX7dgQ1zgXwz8QA4WN80ednAAHkluuOI7R6/XMg2w+nzcwwlBRPmzn83lUKpVEgZowDM0Dt+d5JsxVgS7tN4/NZRr6R5Dk8QlOCq2EHz70E14ICQp0ANa5fzw+HSXuk+OnY0lXjWKYKZAMA9X2J9rbUkMhFSLUNbPB1oYtLfaj86OQp05sWtinumycCwIgXyDYPRI3ku3EMQQ3jmNzPTKZjHHlNHzWdrAVIPXFhbrJhFN1aznXCoI6Fnu8drsau2iUgmOxWEy8xFDZIbf8rPdQFEXo9/vo9/um8JM67pr76fu+CcHeCNqdnJycnC4NnU+vyLR1z8fhfKaqZUr4+NFP4ZX+t+PJYC8yoXvB6bR75UByizWZTNButzEej1Gr1VCtVhGGock/VGgqFAqo1WrmYZnVQvkgT4AhVNghhvxtAyT/JiwwD5AukTpchCACQaFQQKVSQbPZNP0kuS17MY7H4wTUFK2kc4IF4SwMQ+N8aUuPNPdRi6zY5wRsDmS2C6lhsXSGCXi248b8O6pUKhlQCoIgkb+n7VrUtdR2HmcLqdQ8SA2b5biLxSI8b7VVDOefc68hrjpmdVE5Xg2XpXi/+b5v1mdVXl47XlM9N81ltXtlav4qgMR9psV81JG2YZjL1CEOggC9Xs/k2rbbbQyHQxOWy3DdTCaDKIqwuLiIXq+HwWCA2267bR0EOzk5OTk5UVsNkarPHvsIPnjNVfilT33bRTumk9OFlgPJLZbneahWq6jX66hUKiZXkLCU1hxeoY8QwBA97Tdoh5PaeXca7qjhrAwHzOVyiSI6/X7f5AoCSUeKMEM3Sc9PK2wq/PEc2YZhenoa+/btQ6fTSYQZ6nnY8wAk80B5PLputkO7kexQYjs8eCM41fOn62j3jdQxci4IYbYrau9fHTktfMNjs+gR3Wy+fGCRoiAI4Pu+uS/oyvIeUtjc7Fhcz3ZleQ6EboKutgixHVF1Pe3j6UsD+x623Uk9Hu8jQmGv18NkMkG/3zcvBYDky4Ner4elpSUsLS3hiSee2DC82cnJyclp5+mGm07j317zl5uuczEcxPPRk28c4l0v/eQ5rZv1Mshuknvp5LQb5EByC1UsFtFoNFCtVlGtVk2hFGAtr0yhyQ4rpOtHAByNRibUlaCiskMZbUClA5kGJpoTqU4oAANrGuKoUKTQREBQAKOTWa/XMT09bXpPEkDsMFF7Xza0aauItO/TZIdt2iGadPhsuNFxcR06fWnhsnoOel3SxmiPR105Fe8TVvBVaGKIMF8AaFgt96XHt4FuIxfUvidZaIiuqLb00LxeAig/K7hTdgscvZdtR90eixbU4f2q39PJHw6H6Ha7iKIIg8EArVbrLHeIk5OTk9NO0nOnzuC1ldB8/swgj18/9brEOptB5LOBzM22Tf3OA+ZuyeC7b7oLb2+eOufjHCnMo3nDMlZOzMBzTOm0C+VAcgvVaDRw6NAh1Ot1NJvNRB4aH6ZtwAGSRVwKhUIijLJQKCCKIgOWNnTYeW08JkGxUCgkeibauWsMKWXY4mQyQRAECIIA1Wp1HQDwR9s46Fh4LLZi2Lt3r+k/qVVj1QFTENP2JXbeI+dKXVCtzMr1uI49PoUfSkNBFcw5vjiOTZEg5ngqdKdBpD2Ws0El96PhvoT3Xq9nrv9kMkGr1UIQBKYXZrlcNjmEk8kE1WrVOMl0uPVc+cMqtQDMfaXhqgznZTVfbUuj+aQ2SCpA2hDLZTa425VxNRyZIN9oNFCpVFCv1xN5uwTIVqsF3/fNfpycnJycdrd++qE3ovSB6XOuKns+kGl/PpfvvDjGOO8hzniY5IDPfM97cF2+dq6nAwC4tTzBbS/5n3je6bfDC9z/VU67Tw4kt1AMvVTQ0PYYGjKqIaw2+BCUuC6dNG0zQWnxHIaw6me6ScztozNJmKADyof74XAI3/cT+XPsk6igpXlvdIQ0HNfzVttMTE9Pm1YaXE7Y1MqePKfRaIQgCMy6dsgrj6nhkjZ8pRV10Wuh56L7s2FV4cdeV4FJ8yFtIOO26gbqeup82uG2QRCg3W4nzqHT6Rho4/Vl30Tf9zE9PY2pqalE1WAej9dKrx/vSRu8CaIATD/IjQo+pRUvssVx8J6itDqtFoPiyxe2/Mjn89i7d69x+Hmd+/0+xuMxVlZWEASByTl2cnJyctr9ulBhrGfrMXku38Weh2ve+TDee/jPAQAHc+cHkU5Ol4IcSG6RDh8+bCp98gHYDimkq8WH6eFwaFpwqAtj55HZ7SnUNWNRGzpHdCC13Qdl5+qxTQcb3bPvH50e/ihoaP6ggiZ/FBRyuRyq1SoajQYGg4E5dwBm3IQdgiHnhUCu63Hceh52UR6FCDsEk9DK/dnbKJTy2qlbSWmbD+6P4nHSHDp+VgdZj69ATJCmM0hwGgwGZl+j0QgrKysIw9AcJ4oidLtdjEYj1Go1lEolc0/w/iKsa+9MG76YS6tOLK+pzh+BW8Nr016KpIX72vejzgkAUwGXL1Ts+5n3vd5HTz31FHq9HpycnJycLm9tRT5ls+BvCJBH/uZ/xz89+jA+cPgLm+4jhyx+7Bs/g/c/8EqEpxyMOu0uOZDcIvFhHUCiLYUd2qfN2tloXUFNt0tr35GWV8ncMeY/pq0LIAG3ClSEAh2X5t6NRqN1TeX5QK/AZANDJrNa0ZX9HzWnT8HYBkkCrZ6/FnjhMgAJiOPyjRwpBXKFSHufXJYGP3aorT0mHatdZdeePzu8Wc+RYDUajTAYDEy4sxbXGY1GpkIwQ3zp/AZBAACJvFuOV0NZ7fxU7lvniNfCznFNu694zmnzat87vEf0fDkmQjyvl54Dr6WCPMffarUSsO3k5OTklK54EqPypAf/ADCqnr32wMXWDc1F3PO8fZh58OyF09KgcavyKTdS47YyPl+8HjgLSGa9DN45/Tj+vHkTHncg6bTL5EByi3T8+HEcOHAAV111lWmNAaxV4gTWgGk8HiMMQwMD+tBOp5CfNSdPww31YZ8gWS6XE7CkBWr0+IQVu4CJ5ifyGMBayK46TlQakNh5m5VKxeTYEYworRwKwKwTRZHpB8hzUjCzwdIGNx0/IUdbV9i5mQo/mq9ou4V6/hq2qmCj66tsUOP1sYGZ50fXl9V1+ZnjjuPVnqX6QoFuI0Op6UgWi8UEBGqoNV8S6AsGhTR1NG0I1vvJdhJ5b9rhwGmOsoZjc3264cz51LlOc6ZdSKuTk5PTeWgyxoH33YaVt7wcSzdv92DW60PX/S2++ta/wNt+4sfgjTeHv816RJ4LNOo6m60/jj2M4wmyXsZaPgE8wPN2HpA7OV1IOZDcQhWLRVSrVfT7fYxGIxOOpzlhhAeGIwZBkABHFlDZKNRV3RvNKePfdqES+7ga0ql5lYPBIAEWhA+2ndCwVEIdx6Xhp9yvQlG1WkW5XDZASpeL0GpXGFW3k/NjAzawPjePsMpwTI6dzeoJ4zyOzoMCFLfR+bClAEi44fWxwYrrpOVu0kVMC2vN5/Oo1+tot9sIwzABzzp2XttSqQQAxlXudrsm3HoymZhwVYJyFEXr8jPTXOJKpbLuXrTPzRbvT3VCOc402Oe9EASBuQfY01QrB3P+hsMhWq0WnnjiCSwvL6Pf7+P48eOu5YeTk5PTOcrL5fDET92CYWPnws/z83n8xnvehze//53n5EyqCINpUJjmXhIgN4POr/zWi3D0pTfhxLf/rln24d4Ufvk934u3/tuP4Q21hwA4l9Hp0pUDyS0UoYy5heqmKdjRheQDuF1wh2GMQNJFtKt62vAIrDlrdmVMdUPV3dPKrnbhGm7HMer3dqVNjoUFfLQADXMGCZKlUgme5yEMw3WOJM+L8Mg8UsKygrJdlZTgpy0z6HBxvbTwWD22njdBjS8DbCjS7bi+tsFIczHTigDZ10MdylqthmKxiCAIEtdInVnb1QRW4S4MQ/OCgNdMq/baDiPvmzTY08/6UkPHwJcCmosKrPU31bBa26FkSDPd/EKhgJmZGeNEch39d9HpdLC8vIxOp2MKAjk5OTk5nbtG9RiTws4FybyXxdcUs5g8/T73bNVXn43OJRS22Jlg6v4sbph5i/lu3CrgqsUJfukLr8MTX7sH//nAVy/IeJycdqIcSG6hCFL9ft/kldGV0YdzPkRzmd1nT8FA3Tqur+F9CgVpIayUFkTRYjEESR2jPrhzPYKZHpPH5bJCoWCcQG19QoDgfJTL5cQ56d90AMfjMQqFAnzfNy6jXQzHhhst/BJFUQLgdH7ssFMbjPhZwTGtjYadn6mVZLm9DZ1pOZ0KcpqvCgCVSsVU2rWLB/F66IsGvQdGo5FpicHxjUYjA/oaRqovCPgiQ6+fzostdcDpGqo7bVex1TnU8OvhcIher2cqtQJIOKqaZ8yiQp1OB71eD2EYpo7NycnJyenS0WYhrBdKZ8u3rM2OUfvT4rrtml/J4+8P3wA4kHS6hOVAcguVz+dRqVRMrz/CkLpimoeoFUsBJKBLpbBAp5OwoXCq22nlWO5bf3O/dFEJbVQURfB938AA20ZoD0HNNSwUCuZhPwxDE9arBYgUGrktoU+L7TAkleMjXKa11dBCK5wD7avYbDZRqVRQqVRMKCeh13bIdD8K6xy/Qqy+GLAhjsAMIOEiajsOhTJWR1Xo5NiKxSKazSYmk4lxF20nlbDGvFuFXOZLDgYDtFotlEol0+Nzz549Zl8ETHWtNXeWY9KwYJXe2wRJfcmh56zXnv9uuG6v10tcV/vfAQBzLouLiwCAfr+P2dlZODk5OTldXrrQBXOezT5/7V2/g1vL61M9nJwuJTmQ3EKVSiU0Gg0EQQDf99Futw2kadEcAhP7M2poKMMEbdeMy5lbGMdxoqcei5PYIMJ92X0FgWTRl0KhYFyd8XiMwWCATqdjGt+Px2MzRkJDuVxOtJBgC5J6vQ4AJq+SAKfFW0qlksnp6/V6xrGkG5bP51Gr1dBoNBI5gwrVwBpEqcM1Go0QhiF830elUkkcS3NKFQAVINMKw2hIJcOS+R3hyXYfeW30Gmh+I/fH68JCQwrFtVrNgCQL69jivPb7/XW5hAzzJdyWSiWTL1qpVBIOs+1op4XM8m/bhdQ5s4sHaQsT/jshqHqeZ/59MISXf6ujy387cRzD930DknaBJScnJycnpzRtRaXWZ6JhPMaxL7wF4VIZ6/9Hd3La2XIguYUqFAqo1WoIwxC9Xg/9fh+9Xg8zMzMJ95FukbbC0Jyys4UQEjIUPOy+hep8aiioDZK288dx+b6PXq9nQDKOY5RKJeTz+UT+pxZUUYeT7ilz1xhKqSGvAOD7fsJJIyRzfcIzodsGMbvCKoGzXC4bUNYKolq1VWHIzkW1YVIdXe6D6+sY7MIzdnEaAiX3y+ujOYoUx0Knm44h96v7tsN49V7g+bEIURiGCIIAg8HAXC+7kA/vA71XNO9Tz08r+upx7XV4rrzndS75oqRcLht3VOcYWAsVpsM6HA7R6XTQ7/dT/704OTk5Oe0efWH2OvxSsYWf2vPIBd/3s4HIs+VlBs0Mlm4NcTjXwbkU2plgsgqRgcNIp90nB5JbKOb/NZtN9Ho9+L6PbreLPXv2mIdggoSGnircqfOVJj7w04Gk26SOJ7AGkrpPPqyrM8rlDC+kg0V3i/l03JYu6Hg8TkAjkAx1zWazphppGIamCiwBj/DT7/fh+34iZJYgWSwWjbvG89T5SYNJXoM4jhFFEcrlciLM1C5OpDmCCpEKmDZ8q4Oo7rFCnr1f3T7t2ByTunn8XCgUUC6X0Wg00Ol0NsyftR08zpdd6EdzDFn4SNtpqLvKH+5bczxt55LHS8vXtH/0vHm+bBXDc7GLGzHEmv1Xh8Mh5ufnXX6kk5OT0yWg1qMzeH/rlfipV68HyVEtRtBcA69CP0ZmGJ93a4+zfW+3DPGsZ7E0qAz2eTjxzb+Pc4HIMB7i9CgEdlh9I28CZH0PGLvQXKfN5UByCxVFEYIgQKlUwoEDB9Dv97G8vIxKpYJms4lqtWocRIKT5jwCWJcLCGAd8NEBYiVPfZjXHD5+pqOooEHAIbAUi0XjADLPMI7XWntoKw2OiY6o5hJSDIFlGCt7ATKckqDHlikalspcT1YwJThpniYAs54u4/lWKpV1rqIWrVGgsauBar6mDVe6Pzsv1b4XNKRYnTcNz2WOJsevuZj5fB5RFKFUKqFarWL//v3GiQOQcKEJ33rP8IWB9mpUZ1idWZ5TWg4nPxNsN3K1dV9RFCXuZ33hwPte55f7qdfriRcuOucESTr+vEednJycnC5tPfh9v4WJ0Nfz/uTtuPJz55bPeLZ19Hu7ZchmRXfOZd+2/qh7CD/3qW9HZof911VYyeDwz9+Okfs/1eksciC5hQqCwISy7tu3D57nYXl5GQsLC5iamjKtF+iuMX+QIYd80LcdLjs0UkMXuS8CjbqdlB1qqKGwBChWWtVwVM2to7PIfRWLRQN9BBh11Qh0dDGLxaLJVfS81T6SYRiiUqkkwFcBQ4GLDieXna3YjT1Xdo6inQ9pO5zchvvX66HzqqGpXBdAYnzq4qXlONpwpnDF7z3PM273cDg0eaBpeZ2ESEIjgZHXuFAoYGpqCrVaDfV63bRMsXMcNeTWlkKnHWrM7wjJug6Xc10Nl6ULbR+DcxZFEVqtFlqtFtrtNubm5gxUOzk5OTldusp6GWjN819+/YfwS899DYq/N7NtY3omGseZHedGGjmIdDoHOZDcQjF0kg/91WoV5XIZ/X4f7XYbAEyBEW1gv1FhF7tFhQ0KfCgnRNBFS4OKtDBDYA0aWPyEoZ9pIKsVSDUHU3PfFAzoxtHtZI4iq6bSofQ8z8CRQp6OV501uqaEFIKJApDmTSrw2M6jumI65/a2dlimDeppgJi2jYbN2u4m92NXcOX85vN5NBoNE95Jd1oLFWk4K+eNeaJ0hlm5tVqtmmJJ5yMb3DU/1YZfvQ91W507nX8NadVqvtxXp9MxLT+CIDjvsTs5OTk57VxNghx+feVa/MvG/ZjOVjZc7021DnD00/g/vuF7ceegzUQAACAASURBVMUXcc5hrluhXA9488lvxK9e9RfYm61uuN7H+xV8eumFF3FkTk4XXmfN7PU87/c9z5v3PO8+WfbvPc970vO8u5/+eZ189396nveo53kPeZ73mq0a+G5QtVo1LRXy+TympqZw5ZVXYjAY4PHHH8fjjz9ugFIrtaaFsdqfNwopJFQpUNp5a/rgb0MNH+rpBhH6+DBPQGG4K91KuqgEQAKlhu4SGEulEsrlcgKiGdLaaDTQbDbRaDRMQRnmUrLiLaG8VquhXC6bcfKHYZo2zNhzpcsVJO1qqZQ6jbouXTB1jjdqt6IuK7cNw9DMowKghhzrvrRdTLPZRLPZxNTUFOr1Omq1Gmq1WqI6LeerXq+j0WgY57Fer6NaraJaraJSqZjKqGm5ujpv+lnP1wZw+16l00yXO4oiMxc2VHP/DKPWEGSOYzgcotVqodPpYDAYpP8jdHJyumTknke2Xt5wNT9upyjTy+J9n3ktHhnlz7rum2odPPhdv4WomgxDZV6jnd+4mc62rr1PXb82O8Zjv/x8fNY/iJXxwPyM4+TE/vsH/jm+fOfRcx7TxZI3BjLpWTpOTut0Lo7kHwD4TQD/3Vr+a3Ec/4ou8DzvBQC+G8ALAVwJ4K88z3tOHMdjXIaamZnB9ddfj5MnTyKTyZgH/nvvvRenT59Gtbr6pmpqaiqR58eHcg0t1LBCO+zRdtWAZBiiumN0cqIoSuReMtRR3U/mL2azWXS73QQE6NgKhUICLumWcd82IBNY1LVkH0dgFZRYSZQ9N3luQRCY8F8COnPlOAcaXqrVR9XRIpQQYujEcW68p/NEtegPsFYplBBEEFIoZrEXeww6Z1oUya6Gqp/tlwWcM3WdNWfVdrHt7W041OI7Wg3XPmfbDbfHy+uobWW4TPdlw7vtDvM3/9ZrzR/f9zEYDLC8vIzZ2VnMzs5iYWEBTk5Ol7z+AO55ZMsUj0a47j/9A5a+7yVYPnbphDVulN94Lts8m32/92e+F78ii9/6sx/FWxrz5zyG7dKVn5ug8sl/2LERt047S2cFyTiO/97zvGvPcX9vAPDHcRyHAB7zPO9RALcAuP0Zj3AXazweG/Dp9/sGWJrNJnzfR7FYTOTqATB/q8OnhWNsKUh6nmdCPNU9UnDiNoQ+hjnSMVQnKZ/Pm/VZ2ROAcczoqgGrTeC5fhAEprqrVlsF1oeb2sBCoGO4ZbFYNC6nhqxOJpN1gMPx2RCtYbuESq1mm9bGQsNQN4Ifzq26hnZ4qm7H9XVONSxXq6hy3bT8Th07l2sBH4Yl231CtSAQj29/r/mym82DFgvifcf1dT1eJ+ZnsmCSOsAKoerMZzIZA+UMxc1kVvtQttttzM7O4sSJE2i3267IjpPTZSD3PLL1isNwRzmS1Fu/+gP43iN34idnjm+6Xt7L4qa33ovP//Ux7L9r607kXEAzGyb/X4ri3ZFNlhnFiIfRdg/DaZfo2dzV/8bzvDcDuAvAu+I4XgFwCMAXZZ3TTy9bJ8/zfhjADz+L4+94zc/P45FHHkEulzO97TKZDKampjAYDBL5anYen4aQpoVnAkmHaSPnxw5FVHcviiKTB0mo0ePz4T+OY+P40U1jdVmCQBAE6Pf7JoyV4ajlcjm1MI2OR89DG9OzQEwYhgZ81cFjT0uFcK3cqj8K0WmgrWNKm2tua4er2q0xNDxTz80GNt3faDRKAK8W5tnoWqrjx+vveV4C2Fj0yH6BwAJMvM4bQZjmv24WHszjpoXDcl2Oi2Oy83YV/BWUgyBAHMdm2zAMTY7xysoKlpeXzQsEJyeny1YX7HmkhI3z8C4XlRfHKJ/JwT+wc4iyc6KJ26evB84CkgDwwas/j1d+zX6sdK7A9MPpBjRDUbcjh5K6YWYRX25XgMXi2Vd2ctqheqYg+dsAfg6rtaZ+DsB7Afzg+ewgjuP3A3g/AHied0naCV/84hdx//33481vfnMC1KanpxGGoQnBtNs0ED6YQ6cOGx/YdX3+JiAASWeILmeaY8b908lSsNCiLAo3PBeCJMNxR6MRfN8HANPnkGPTc+BxKT1/zYljyGsYhiaklnNgh7gSOtXNU/cvbRxa4EjdPi0wpABFaNYqo5TmhSpQpbl5wJoza4cya4VaBXCOJQ1YbdDkHNitSHhP2aG0CvRpLx64T7twkkIfiwLZLww0/JbOZNoc6PXhsjAM0Wq1kM/nTfXWhYUFLCwsYGlpCe12O/UFhZOT02WlC/o80vBmLsnnkfNR6RN34OqHj+ChH9m33UNZp3E8QdY7a3kPfP6mj+LD10/hfe/+7vVfPn2F7f6PuiytP6Sdc2n3l9TfadvZ+vD1f40P7rkC//lTbzzr+VwUxYAXY+dWkXXakXpGIBnH8Rn+7XneBwB84umPTwI4LKte9fSyy1ZxHCMMw0QuGXvoMUSP4asEA+YLKkgCWAc2movG4ivaIgNYg0F1fRQ0CGeEAobUlkqlhIukff+AtWIzdnEfhiL6vo8gCDAYDEzRHG5Hh9HzVqvZzszMJMZJkCPEFgoFA3ClUglhGCacKbp5hE57/oEkRPK82HrEBvW0YjNpRYrSrnVafqN9nTgeXtNMJmOu9WAwQKlUMmHCWnXVvrYa9qxS2FVY1iI+XKbnvVFoL6Wuof7NbXl+DEW250tzc+0CTnbobxAEWF5extLSEprNprlvTp48ifn5eSwtLWFubi4x305OTpef3PPI5aO7v3o9nnvqh/DQrR88J5h8Q3URz/vV31i3/Ht+98cx82Dy/47z6Q/5bPpM7nQ99zdnMX5qzrGk0znrGYGk53kH4zieffrjvwDACmofB/Ahz/N+FavJ7UcB3PGsR7mLFYYhbr/9dtx8882oVCoGJIFVEOj3+wjD0IAWQ0O1/6OGt9qFUNLCMjVMUr/THDx1n/jw7/u+yU8D1pxCBQaOk9VGORY6jHywZzGaMAzh+z7K5bKBmW63a4ryVKtV4zhpmC3hgnBJeGFeKfdFKOQc2dVSda5Y0ZXHK5fLCfhWV5EwZOdx6r43Akp+x9/q7NkOI3/bVUt133qNtUCRAt1m4bgKrXoOmi9KB5hjtYHYdnptkKRTzuJD3E/aeemLEW6vriTvoyiKTMg0CyW1Wi0MBgPj6Ds5OV3ecs8jW6SFZRz+yxk89Y05jIs7Ayu8oYfJSgHfeXy1AO/LZ05smjNZ9PK4qbC+2uvNr38Aj75y77rl44mHwodmkAvO73zP5mZG9Qzi71rE15ePAyib5f9h4QX4xKkbz+tYW62400VsvZB3ctpMZwVJz/P+CMCtAPZ6nncawM8CuNXzvBdh1QB/HMBbASCO43/0PO/DAO4HMALw9vgyr5AWRRHuu+8+HD161Dwcs1diHMemAiUAA4/MEdSCNAQ1O+zSBhkNbwWSoa98gCeM8ju7ByOdIsKFulpcxgd57RnJSqQUw1E113M0GqHVasH3fVNttV6vG9eyXC4n+lESJAk9dLM0h3M8HptcSW5HeCHUZDIZk7NJoKxUKmY7jlFDdHV/Cl22y8m/bajXMGL+1rxGdYJZlEbDcbU4EGUXCUorwKTr2WPS37x26iry2BryakOtOuMKk7yntAiTVphNKxzEsdovLwj2w+EQvV4PnuchDEP0ej0MBoNEaLSTk9PlIfc8cvE0XllB8ZN3IvN1r9gxIAmswuQ9Xz4CAHjs+j34p9UH8DXF8+t//KHr/jZ1+TAe4+YvvQP1J2IUuueeNrGZCxlOZdA+Ajz04j8FIXIcT3B3NMKfPPIShKdq5zX2rVJm6KHQ8gD3gtbpPHUuVVu/J2XxBzdZ/+cB/PyzGdSlqCAI0Ov1TMhfrVZDFEWYnZ3Fo48+igMHDqBer6NcLpviIsBaSwaGyE4mE9OWgw/6ChOEPq3IqY6U5t8ROuM4XtdmgaDCfditQViJlfu2q7Fq2GsQBAYkCUcMo+33+5ifnzeQNzMzk3AduW+CFZB0AumSEly0EBDDgzn+SqWCqakpEzrKXpY6zwq9dMr4w/lKgyR+5vecG62SqpDN+SeY63nxurKqrs6rVqpVkFTH0w6B1rnUa87v1AHnGBh6ap+jnRepUghkyDTvRc4fHWHODe85upqFQiEBiQz3JUR2u120220EQQAnJ6fLS+55xEnVOdHEd556B776xt9ALVN61vvLe1nc/7b/B9d96l/hqj9fnzbyTNT91h4e+vo/TCxbmfj4zj//cXjjnRP2Wj7j4eB7b4PDSKfz1e6oRXwJ6HOf+xyuvfZaHDt2DABQqVQMvD322GPmgb5UKpmHdi2Sw4dxhnsCWLee7XQp4ABIAIANKFzPdp7ScuoUdPnwr3mADGkF1gqpBEFgIEeriTIXju0+2C6E+ZsEVs0vJCxqER7mXVIcM8NlC4WCgRg6mdq+Qqu/AjDOpYKkFhai60lo0jHaTqLtEGtIKqVgmZZLyTFynnlf6LzrvaFSV1Fh1ga7wWBgIHp6etpU7CXQpoXRagirjo+OM+8rLTalY9J90YFst9totVpYWVlBr9czLyKiKMLy8vK6IkJOTk5OTlujI79zAovffB0WX7xzXEmVN/Rw09+8DZ4X4+orlvG3L/zYdg/J6Bt+5na8ZeZ2AFWz7H0r1+DX7nr1joLIw381RuWuEw4inZ6RHEheJPV6PczOzqJYLOLYsWMmlLBUKqHb7ZqwUDp1Gs4JrD14E5o8z1vnEmoLEduV4sO+HZ5Jd9B2+whqrLRJWNTj0U1jsRgFLA271SIvWqlTQYzH7Xa7KBaLJmeyXC6vA2k9Fqt7Eir1fAEYaCQw0X2ze1Cm5f7ZeYcKUXZ+pH7WEE4eR+dbXWOGMqdVH9WxKPBuliOrv+3rYIfa6v5VDAnmfGquqioNiHnOhEqt0sox0J3kurwvRqMRer0eFhcXDUz2ej0D6gDMPeDk5OTktPUazc4hP7gGwM4BH1ve0mpo68nxXvzo9EvN8isKHfy7vQ+d9/6+6YUP4K/9G3Hor85nEMDp14+RKazh2A/N3IYj+WTo6uKoBm/5/EJxt0LF5QyaD6/+v1p9YAGjM/PbPCKn3SoHkhdRS0tL6Ha7OHz4sHH0arVawr1RkLSlgMcHeO7HzmmzP3N7LrdzKfUYhD66ffl83oSLauN7BRy6hDwHO1RSIYbOkwIOYbLT6RhXMp/PIwzDBNhoqCgBOAgC+L6f6CfIfdPl4/7scfP4GxXOsQFTt9EqpSwyo+dp50BqsRm7oI+dj6gQqsCnLp+eg75EsF9CcH2Oyy56w+3t0FSGp9IpV4jmchskuS/2suR15Zj03raLSjEfcmFhwUAkw8F5PCcnJyeni6tsECM3yGBUjncyT8JbyeP/+9zXmM/xngjff+uXzec8gIO5s+ckfuDwF/D/Tt+LX/iH71vdzo+RDWMEzY0rxcZZ4LPf9F5cndh/8ljz4z6Wou3PicwGHmpPxKj/yWqbVRfj4/Rs5EDyIiuKIvzZn/0ZXvva1+LgwYNoNBpot9uJh2vCBbA+LHE8HieqpQJIgIPtNqW5Tvys8GMXZ7ErlTJ0VN09jo+OpBaTodNE91BdOgVJDd/VAj48BivcatEhhjayUigLFtGVJFBp+xA6qtyXum1aKIhzrLmpBCA6oIR5/s3jpxWVIbwyPFbnlG6qOqAKg7q9undA0oFWKWAq+OkcKjDzXHO5HGZmZsx1WFhYQK/XQy6XQ6PRQK1WS4Tqpr1Q0PuBTjAr6ur5ES55DfV8Cfy8p7htFEVYWFjY/B+Xk5OTk9MFV+kTd+CGr1yJB9919XYP5bzkLRXwTz76E+bzpDbCY6/7vXPa9k21Dr7tP/4mAOAld/wACp+awhd/5jc33SbvbQ6Jr/zCj2A8Wzmn42+ljvxxC5N7HtjuYThdInIguU360pe+hIMHD+Lo0aOJXLThcGgqkWpIpzpXdHWCIDBwwX6T6rZpNU51IDW8lXDB7RRI02CEf9sumgIoYU9DUG1nlMs0HFaPw1xGjp/HUpDkeMMwRBRF8H0/4bISetWNtF06dcO00qvCroZe0qVlzqcCYloFVYbraqEldRoJTeraqpPJOVBHjyJsqRREud/NQkEVnjUMl3OnrT10/myQ1HOi1EW0YVlDVLm8WCyiVCol3GleRxfO6uTk5LSNSkm/2BWS/zq8QRYvuO37163yizd/FN9WHaxbnvdW///6wM1/iDufc735fL56YtTDt9z5VoyWyttm6E495OGKv18CAMQnXTtVpwsnB5LbpJWVFUwmqz0lZ2ZmjHsXRRGq1dXEbAU9hQw+iNPd0zYZGr4JrIEF92GHu3KfqrTcPADr9qtjVMdUQVJdMAVJPTcdC4v0ECTtEE/Np+RYeBw7VJMQqT0q0yqd2oBrtxDRcFy6kQy5VRBPEx3TdrttXFCG2rINiX1NtKoux0zY5XkrlKUdcyOA1BBYXmsFZW7PUFaOgefJz3p/2M6kXVxIz0NDb/UFArctFAqoVqsoFosm9LVYLKbOrZOTk5PTxVEchJi+30PnCDAu7c4Xe97YS2238fv7vgGP7nkksWxvroM3NxYBAC8rZfGy0snzPt4H21egPa7gybCJ4In6RYfITOhh6tHVv6cfCTC+/+GLPAKny0EOJLdR7XYbd999N1796lcDgAl1ZJ9J2w3kMm3fwDw2daDUJeL2+oBvQwuARB9Au2AK90d3CkAiNFSBiiCplUwV1GwAtVtRKLgpnCik0AHVsEhWIKWy2SwqlQqq1aqBSDsMU/MLuW8Fdz0vdSPDMEQQBOuuT1qBHmAVjvv9vukXynBdbf1BaS6kOoQMoeX2acVvdF5ZRVVFiOR9we95T/m+b8ZTq9XQaDQArLmWXJfbp7mSfLmhx9S54brcn7rhLOqkPS3pjKYBs5OTk5PTxdF4ZQV7fu92BO9+BfxdCpIb6d5/uA734rrkwn0hvv3W305dP+9lUfTy65b3JmttqcaI8Z9ufz0y7Yv8mB2v9oQEgELbw57fu+3iHt/pspMDyR0gfThfWloNPajVasZRIxwCSFSwZO4YAYgP3HwwZ0ggH/Btx8sOs9SHdQVH5roRxjgOhcEgCBAEQWr+ZlquHo/BdfS3ulVaYEXBj7ChsKThuJlMBuVyGfV63bS30H3YAEu4ITRq+KVWhmUYrZ3DqmNkeCbndc+ePRiPx8hkMmi1WsjlcqhWq6hWq+tcVACJc6MLOxgMsLy8jGw2i5mZGQNcOq/2eNQpVYC2r4s6uwrlzIPlCwiCL2GRLygIvTymhi4TaG1Q1LnW8bHvKPNlS6USTp8+jX6/DycnJycnp4uihSJu+rMfS/3q6POfxKef/4nEsmE8xrG/eAe8UP5PH25PIOtz/stJjBeXgEmMSwv5nXaiHEhusyaTCe655x4cO3YMBw8exGAwQKlUWhfaCaw5R4RAAIkQTFYt1WI3QDIk1c51031RCp2ECg1N5DrqQvq+jyAIElU67VxLhRwb7GzgtMNO+bcWcmH4o+ZnqgOqRYI0b5TfaT6o5qJquxKGG2uLEYKVOnV6DgR47qNWq2EwGMD3/UShIOYe8jrYoKxFdlh9Vl8C2NI51P3YrqC9vl5Linm4nDPej/yOc6r3ph3mnJbzqWG5PK46591uF91uF0EQJO5PlyPp5OTktP06/BcrGFcKmJSyePz1BcQbFzLd9fI2AMGHT16Bl0dvSiyLYw+en9m2/pD7vgw0jvvw4hjj+UXEw+jsGzk5XQA5kNwBOnPmDPbu3Yt8Po9qtWrAxXYUgSQk8kFcH7TphOkDvlby1Fw3O19OXTb7eHYopbqGGvapoae2A6a/1c20YVllf1Zny+5tSeij6G5p6CXPg+PktlqV1S50xNxIuwKthsFqmKjCXlqRIq3Ky/1oKw0bIpmzWKlUEuBl5yJyfrhvhU8dG4+5USiuvQ73pS8j7PBUle302rAfRVEiPJbfjUYjtNtttNttA5J2ASUnJycnp+3T5J4H4AHIVyqoHXsRBgfjXZsz+UyVaecw3963bvnFRsjcwENpfvWo0/eumEqsl9fVcNpuOZDcIfrHf/xHzM7O4lWvehVGo5F5gC4WiyZnktBHwGSIoeZOsnorAYQN7+1iKIQMVnO1C9CoNP+S62guIwGOMGa7a/Z2PCZDRglhHLO9vY6NTmS5XEapVDKOWxzHxjG0czY1B49hrlqplPPI3ok2SNrFdzgWLSxULpcTOY0EJcLR8vKyKbjj+z583zehy9yfXZiG86AONV8UqPtnF0PSMWhVWHUs0xxgLZxD2TmX6roy/HQ4HKJYLCbAWp1MDX1lCHShUDDnRShl25GFhQWTD3rq1Kln+S/LycnJyelCazIY4MB/uQ1n3vEK9K6NL2lnckcpBrynH9NqTwB7f3c1B9JVEXDaLjmQ3EFaWVnBJz/5SXiehxe96EW48cYbMRwO17lomquYzWYTIZ0aJsiWFgxDtAvOjMfjREEdLYZDWGWfQd0vK4jyh21LNO9QYWQj54r71tBLbqthlwqSWrBF8xo1p5EASHdSw3M1t1MhnKHBBGMFUu5Xx8T5JRhp/p/O13g8RqvVwsrKCnq9XmJO2epFAU6h33b0WKRHnWUtkMQCRYTOfD6fuFZ0GDXclaAcxzEqlUoiL9fOg+X9UiwWTT4jc0Y13Jcus74gYC/NIAgwPz9vXgYQwJln2263jevKyrEurNXJyclpZ+rg79+D4Uufi8feUDj7yk7PWtnQww2/8hAwHiOOhg4gnbZdDiR3kOiqAcCJEycwHA7x4he/OFEFk60RtD+k9mzUAix2aw2CjhbfodNkP6wTZNSRUheO7h2hSyuwam6kvU91y4rFIjzPM7mOCh4qu1iPzpdWWrWrrrLXo+b20X3TPD8NrVQI1TlUiOWYdD+6XbfbNWBNqCqXy2YsU1NTqFQqCYhkzqSGemqYLLAWAqtzq3OiUMlqp4Q8jodzwUI6OsdaqZdK6wPKa8l9pLnO3Cf3y/kKwxArKyvm3i2VSiiVSsbdHg6HptCPC2l1cnJy2tma9PsoPvQUrv70YQDAws15+Fc4vNkKVU9nsO8rIcbLK4B7weq0Q+RAcodqfn4e/X4fhw4dQqFQSDx4A0gACJ0mPrDb1UftAjcEjtFolGitYBdlSYNJbYGhIKmhn3Zepoar0lklRNHJ03xKrQCq49b9qTOqoagKTkEQmHPkfrge96+gpvvR6rPqRHJ8nFsCpDqXLBhDiKxUKqhUKub6KUhqMR3CpB5L5812RIH1xYi4DSvt0nW1100Lc9WXE1pF1S7iwxcBbEOioGmH29ogHIYhWq2WcU8Zuk0YHY1GyOVy5r5ycnJyctrZGs3OoTA7BwBo1r4O42IW0bSDyQshbwwUl1b/D20+OkLub768zSNyckrKgeQOVr/fx8c//nHccsstmJ6eRqlUMpCj4ZaU5pvxe7uK6XA4TORb8sGdrRboSDE0kmDDbcMwNBVI7XxCdSUJg+pWEVa0tQeBR51EzZW0c/sIVoRGwiLdQI6LfwOreXnMS6QLSceOoaSEGLqMg8HAQFQ+n08APM9FYZ3wGoYhlpaWsLCwYCD2+uuvR6PRMIVmGo1G4lrZ+YppeYz8bIObDZh67egYMq+U567hrXYxHHWMC4WCud943/A+4pwUCgWEYZjqgKsY1trtdtFqtQwklkolBEGwrirs/Pw8Tpw48Qz/5Tg5OTk5bYeqH/kSGs+9AQ+9de/awu0pZLozxP8Sz3cOnt4u38ngql9wvSCddq4cSO4CMfxzamoKANBqtYwjWCqVUK1WzW+7eA7DYu0wTLptDHe04U/BkA4YYazf75u8O82L5N8aDmnnRxK8tDjPRhVm1SFNq0RLOCE49vt99Ho906qD+yYMt1otMzfVatXAXVroq+Yf8m91B4FVQGNeIQvHeJ6H/fv3o1qtmjltNpsml5XVSDlnLFJDEE6rSKuAxuur10ZzSRUkuQ8WbdJqsXZILeFc98P5tu8PDXXm2LU9jII11+v3+2i325ibm0MYhgbQef68rtlsFv1+34R4Ozk5OTntLk1OPIHnvXcAAFh89TVYfPHlG4a578vA9D0tPPyDzXOHyRh47gdX4LW6wHiM0dm3cHLaNjmQ3AV66qmnkM/nsWfPHpNnxqbt2WzWFHfhb81btEMjFfA0TJSFUxQS6B4y9LTf76Pf7xunTwu1aDEewoTmFdpQqWMslUqJ0FatIAqstSAhVLFSKoFRocYO31QoJehpXqRWoOU2WiiGx9f54jnkcjnjVBaLReMyTk9Po1armW1ZnIZg6/t+okWHFsOhS6rXJa3Nh124SMe+kWx3WosYaWVWnR877JXb6ksDgqQeW6vyjsdjdDoddDodDAYDMy90NXkuw+EQTz31FHzfR6/X2/A8nJycnJx2ruJhhNGTTwEAZr7aBDCFxRfFl40zmet72HvP0y9tR0D3eVObru9NgH13AZmRpKo8fhrjfn9Lx+nkdCHkQHIX6NSpUygWizh06JBxlhQuGHbIB32CSSaTMeGH2j4CWJ8fyId+7ZtI+KGLR5AcDAamGIqdF6lVPjfK7VOQ5HEJq2m5e1rFdTweG1e01+thMpmYYj1a+dTzPFPxluG61Wo1UZVWcy4BJABKwQlIAid/tECOHptFhHgO6v56nmdCbLnfIAgMSKoDqg6ynpctO8SV11dDjulG8hpxvHrN0np5ct86F2kvBBhGS9Dni45+v4/RaIRut4tOp2Oumc6/Vsp14axOTk5Ol44md9+PvXMH0L7h+tXPBWBcvAQdyngVIL0YKM97qP3pl5BtTqH1mufjzMvWr5vvSdrK2EPzY3dj8vSLVsC183DaPXIguUv06KOP4vTp0/iO7/gOU8Alm82iUqlgMBiYvEVgtYn7cDhErVYzTlm5XIbneeh2uwDWCqYQGpgLR2hgEZ8wDI1j2G63MRgMTB9AdfIIKcBaaCz3ZReEITyEYQjf9xEEAaamplCr1RK5iFqkh2P09FlQvgAAGF1JREFUfR9LS0tYXl7G/Pw8CoUC9u7di6mpKRNqSnjyfT+RN8icPx2HurMKliz4otJz5BgBJGBUoVHXo6tJOOz3+6Z1yGAwSEC/hgfzeqnjaQMtj79R/0e7HYotnQMtrkM4ZFgzzymXy6FcLptzZqXawWBgHGsCJduosA2KA0UnJyeny0ujuTO45mfOAACi174UT7wme5Ytdp+8CXD9L9+HydP/ZwPAYz/6QkTN9UiYDT1c+3NfRjxc+z/ZgaPTbpUDyV2kMAzx6U9/GjfddBP27t1rwgIJQCxgQnBiy4ler4dut5sAvUKhsK5IC0GDgECHcjAYwPM8DAYDk5upFTVZ3VM/azEXINkug6DJfTM3kLDHkE5gFVqYi+n7Pubn59FqtdDr9YwzSmcMQMLFY3EZdUiBJBDSTSQ48/zpkilYazinisfR5Twm8xNtoOv3++h2u+j1eibXNZPJYDgcwvf9RPVWLTCk+ad2KKvtFPKeYL6ihhqzGI9W+uW+OZcakkzwzWQymJqaMnmTPMbS0pIBfK5H5XI5zM/PGyh2cnJycro8Vb7zOJ772Iz53HveDJ68NbPJFjtflSczOPzn8xj3B4nl1/+PpxDnUx6zJxOMh+kvdp2cdpscSO4ixXGMhYUFtFot465pLz9CEwut0DWiixiGoWlFUSwWzXZAslejhpEqIBIsbZCxK3VqviHHpEVjFHAoO6eODhkr1fq+j5WVFZw+fRq9Xs+E3mqhGM3Z03FSOh6FLoan2vmS9rb2+XF7u02I7cKyGuxwODTXgoWLfN83MEso7vf7BvQImCyao+1G7HFxbIRCzivn2i7Kw+Pa86Kwquel14xhsb7vGyDW+4y5n0EQIJfLod1uuwI6Tk5OTpe5xkvLwNKy+VybXI+ZPQfWrdd6HjDJ744Q2EkeGO2tIXPcQyzW4ujE49s2JieniyUHkrtQ7XYb2WwWQRAY2NIwVVZwLZfLpsDJysoKBoMB9uzZg1wuh0ajsQ4I7bxG5u0RHrQvpd22AkBiP2nfU3Ecm6qtdCG5f1ZdBdbCW6MoMhU/jx8/jiiKTEgrQYsuHN1EuqZ0zuwCPlokiNsDSLiSKsKWOpvcr0KXhuRSbAsSBEHCiez3+4iiyBTnYVgu4atarWJmZsZAG/eTdjz7h+sQqDnX2t5FwVJ7RtoFedjv0fM8BEGAVquFTqdjrlmr1UK320UURQm4j6IICwsLz+wmd3JycnK65DV+5ARmHrFSHjwPvf/75RhVAHjApLBzgTIz9BBNxXj8W8s4cncR8cjVWHW6vORAchfq+PHjJteMUDMzM4NXvOIViQd5wspwODQtJarVKgBgeXkZnU4nARe+7xsIZainFoUhrGouHrBW1ZTLCXQcH50sumDqqNF1o4PF3pDcL3MV2YOw1+uhVCqhUqmg2WwaR5bAxPlQsNawUgU8QpgWpdFQXy1Ko4DNMFeCNt1RQjSPz+16vZ7JL+33++h0Ouh2u/B9H3Eco1wuo1qtmkJKQRCYcFiGICvEq2vKa6PtSrRokVbvZZsSXm9eWzrYGt6r1ziXy2FmZgaDwQBLS0t46KGHTA5lJpPBYDDAqVOn1uVgbtRT0snJycnJaUPFMa75hbsAANmrDuLBdxzcsRVfr/9oH96XHwQATFy4qtNlKAeSu1A2SACrvSXvuOOOda0arrnmGjQaDVQqFZTLZZNX2e/3sbi4iGKxiGKxiEKhYBxOtrWwwyfpXKkjx+91OcMwuQ1z8TY7H3VDi8ViIuxVeyNWKhVMT09jz5492LdvnwE+7Y3J9XU5nU2tsGrPpxas0Uql6uzxnLWXo+apEiDZM5LzzAJIBGXmmBLsNKSULq0CNuE8zeHVOVRgVrDlddX2InQQtYKvAjS3I5DSVQ2CAHEco1gsIo5jzM3NIYoiB45OTk5OThdELEQzmT2DG/64se77U99cR7j34peoueqvJyjN++Zz9pHTLt/R6bKWA8lLRMPhELOzs+uW052s1WoGksbjMaIowmg0MrBCkCRc2D0XbSfPFt0wSkNm6fwp7KXthwBDENaQVEJQtVpFs9lEs9lEvV43eZuERXVNtTAOv2exHx5fYXEjSOO4tQ9j2jItzEPoWllZweLiYgIEGdYLrFVj1eI1bCFSKpUSRYrsnMU0qTupMMhxEaRtZ1NDXNXNpbTCLoGYbmff9bpycnJyctoCTYIAuOPedcub170Mg256kZ7e4Rhx7hm82IyB2qkMvPHGq9TuPoXR6SfN501WdXK6LORA8hLXo48+ikwmg/3796PX6yWqmDabTczMzJg2IVEUmVYig8EA9XrdOJbq4NF106I0CoiEEA0TZeirthhRZ1PdRLuSKOGmUqmg0Wig0WigWq2iUCiY/XF8BCUVexQyVHQjlzQNzhjea1e0VUAFkm5tLpeD7/smFHRubi4Bw0EQYDQaGYe1UqmYEFbCcLlcNo6f7fQp/OrxtXgOl2mVVv3eLiSUFhKsc2L3gVxeXnYOpJOTk5PTtqj+J19EPe0Lz0PwH162ml95nvImHg598D6Mn64BkCaXAenklJQDyctAx48fx8mTJwEAN998M2ZmZpDP5zEzM4M9e/agXq8jl8thYWEB3W4X3W4X/X4/ARfAWoVSLUyjeXuEGS3kYoeI6nIFQO5D8yv5ezgcGlc1jmNUKpVEuw3uh4DIbbkvLcSj4acM8Uxz+ug4EkIJomlgp/ukm8ocSrY2oQtMJziTyaBYLKLZbGLfvn0GcDnfdIk1RFirq9qOK51MBWnCLfNgNeSZeZd63my1wr6RQRCYUNm5uTmsrKyg0+lgfn7eQaSTk5OT085THOO699y3YdTO2bQZRDo5Oa2XA8nLQMydA4DHHnsMs7OzyGazpmgNq6a2Wi0T3kpwK5VKBqLYVoP5cgQRLeZSKBRQqVQSfSRtqFTHktvTJaMTSWdMK8QyBFQrmNq9HikbsuiKblZJlj8KkzxfDWW1233Ybp9WkR2NRubYWqCH7T1YaIeOJIDEnOlx08ZNEFdoVFDWedbz0yJIGgrLY2puJyu1zs3NOSfSycnJyWlHa+J6Fjs5XTQ5kLzMdD7tGK655hoDJgQPFosZDAbrCtkwDJZ5jCyao4Vv0lqDKPBpTiU/a6sLACbHkPtkPqddpVXbm7D6q8pu9aFuo70Pre7KwkCaT7hZESI6kva5sKhRsVg0EMxztF1fyj6GAizhVEFS81I1nxNAIteRvR/Zy7PX62Fubs5Umw2CAPPz8xgMkg2XnZycnJycnJycLk85kHTaULfddhtuuOEGHDt2DMAaeIRhiH6/n4Cc++67LwFqr3rVq1CpVExuI7AGP9qCgiGfDI0tl8soFAoGkLTHo+d5pmooAJTLZQORGlKqP3TaGMaq+ZN2bieXaX6mwqgWDbK3AWCcUs/zUCgUUKvV0Gw2jQM5Go1QLpfR6/VQKBRMQR0N71W4pSNqF/ThseI4NtVs2euxWCwm3ElCN8essBwEgekHyZYvrDTbarVwzz33YHl5rXG0k5OTk5OTk5OTE+VA0mlTnTx5EouLi3jOc55jwHE0GuGRRx5JQJjt9t1xxx2o1+toNpuYnp42eZP5fB779u1LhK3S3QRW3cZSqZRw1vjdaDTC8vIyfN+H53moVquoVqsGErmOQpc6hrYTakNbWkip5hsSRG2os3tRAkChUEC9XjfurR0uSwAkCNvaLHxUcynZziOXy5k2Lro/AjZDmTl+3/fR7/exsLCAwWCAVquFBx54wPS2HI/H8H1/oyE4OTk5OTk5OTld5nIg6bSphsMhOp0OTp8+nQjxPBtk+L5vHDpWi+XPwsKCAZzJZIKDBw+afMJ8Po9CoZAoDqNO4MrKCoIgMMu0QAywBnWEPi1Ms1FrC2qj6qhabEiX829CsW7PfEg9J0Ix5yOtaqxdDZefbTjmeXCeCJPMi+Qc2GG3BFm28Wi1WlhYWMDCwoJpU+Lk5OTk5OTk5OR0NjmQdDqrJpMJnnrqqfPeLgxDhGGIlZWVDdfxPA+lUsm02NAqo4Qo5g9OJhOsrKxgOBwayNTKr9w+DRTphtqVZLlfu5qsrsPfdEbVebQdTobkMgR3MBggn8+jVquZQkHtdtvkTGroLPenx+Qyu68mz1srsmqILIFRFccxhsOhKZ7DENYzZ86c0/V0cnJycnJycnJyohxIOm2r4jjGF7/4RQCr4aBXXHGFcevG4zEef/xxs24mk8FVV10FAMYV/cpXvpLIWXzjG9+IqampdX0VFbx0GaWVYwGkAudwOASAdbmTLCak7VJYsKbdbmN6etpUwB2Px1haWjJ5nmwtQsi1W6Xwbxtc6dRqP8wwDLGwsADf9+H7vgFMAuRwODThrHfdddcFuoJOTk5OTk5OTk6XoxxIOu0YDYdDzM3NbRh6OplMMDc3B2DNpbML33z2s59FLpdDuVzGq171qkTVWf3bLmzDv3V/XJfOIcNBh8OhCS8lzCmg+r6PlZUVdLtd0zNSYU7/brVaqNVqpsgQAONcal6mDb8EZeZETiYTBEGApaUlLC8vo9vtolwuo1wuY2VlBY8++qjJcSUQOzk5OTk5OTk5OT1TOZB02jFiG5HNdLbvGUZbLBbxyCOPIJfLoV6vY8+ePaa9BcGLhXmiKDKA2mg00Gg0EiGzmUzGtMiIogiTycT0yiREspgQsFYNtdfrGZDk8cIwNGGncRyj1+uZlhpaVTat7QkA49RqT0vur9frodvtGkdycXER+Xwe3W4Xi4uL53s5nJycnJycnJycnDaUA0mnS1JhGJqQ2cOHD+PGG280+Zd0GFmhtN1um1DPI0eO4MiRI+tyNdk/k3mHuVwOhULBOIPcL0Nu2X+RTiddQO6DP4PBAN1u14DmeDxGuVw2bqdKCwVxe+Zi8qfdbhvYPX78+EWZaycnJycnJycnp8tPDiSdLnmdOnUKc3NzeOELX5go3HPvvfeaXEfqxIkTeOyxx8zngwcP4ujRowbUmLs4HA7R7XZN70a6l6PRCN1u1zinmUwGy8vLyGazBhZ7vR7CMMRkMkGv18PS0hLa7bYJk202m6hUKuaHoa0cN93RXq+HxcVFrKysoNfrYTKZ4OTJk2d1bZ2cnJycnJycnJyerRxIOl0WGo1GOHHiRKKYjfacpOw2HktLS4iiCHv+//buKMTSs7wD+P/p7saQbhuNlkWSUCXsTXoTQ2gDlmIptCY3a2/EXmgQIb2IoOBN6o299KYWhDZgMSSCrQRUzEVoK4vQK1NTCcZNkF1axYQx2bLENQk7ZrdPL8434zm7GbNvO7PfZM7vB8P55j1zZp7v5Ztznj/n/b7zznfm4sWL2+cubl3M5siRI7n++uu3z2u8dOnS9hLYZLFE9dVXX91ehtrd28tbt2o4c+bMykd1HD58OLfccktuu+22lau0bv2+zc3N7XMsT506lddee21lme6v+wxKAADYDYIka6G7c/78+eHHXbhwIZubmzl8+HAuXryYQ4cObX9cyebm5vZ5l4cOHcqFCxe2Pz8zyfY7iVtLVpc/h3Nru6ry8ssvbz9mS1Xluuuuyw033LBykZ2q2l7W+vrrr+fs2bMungMAwDUnSMKb6O5sbGwkSY4ePZobb7xx+x3ArYB36dKlnDt3LmfPnt2Vv7mxsbH9NwEAYL8RJGHAK6+8ktOnT6+MbYXJy99VBACAg0qQhEECIwAA6+433vxHAAAA4FcESQAAAIYIkgAAAAwRJAEAABgiSAIAADBEkAQAAGCIIAkAAMAQQRIAAIAhgiQAAABDBEkAAACGCJIAAAAMESQBAAAYIkgCAAAwRJAEAABgiCAJAADAEEESAACAIW8aJKvq1qr6TlU9W1WnqupT0/hNVfXtqjo93b5jGq+q+mJVnamqH1TVnXu9EwDAwaYfAdhfruYdyYtJPtPdtye5O8kDVXV7kgeTnOzu40lOTt8nyT1Jjk9f9yd5aNerBgDWjX4EYB950yDZ3Rvd/f1p+xdJnktyc5ITSR6dfuzRJB+atk8k+UovfDfJ26vq3bteOQCwNvQjAPvL0DmSVfWeJO9L8mSSY929Md31syTHpu2bk/x06WHPT2OX/677q+qpqnpqsGYAYI3tVT/yejb3rGaAg+aqg2RVHU3y9SSf7u7zy/d1dyfpkT/c3V/q7ru6+66RxwEA62sv+5EjedsuVgpwsF1VkKyqI1k8aX+1u78xDb+4tURkun1pGn8hya1LD79lGgMA+D/TjwDsH1dz1dZK8uUkz3X3F5buejzJfdP2fUm+tTT+selqaXcn+fnSkhMAgGH6EYD95fBV/Mz7k3w0yTNV9fQ09tkkn0/yWFV9IslPknx4uu+JJPcmOZPktSQf39WKAYB1pB8B2EdqcTrBzEVUzV8EwD7T3TV3DbBOfrtu6j+oP5m7DIB948k+mfN97g37kaGrtgIAAIAgCQAAwBBBEgAAgCGCJAAAAEMESQAAAIYIkgAAAAwRJAEAABgiSAIAADBEkAQAAGCIIAkAAMAQQRIAAIAhgiQAAABDBEkAAACGCJIAAAAMESQBAAAYIkgCAAAwRJAEAABgiCAJAADAEEESAACAIYIkAAAAQwRJAAAAhgiSAAAADBEkAQAAGCJIAgAAMESQBAAAYIggCQAAwBBBEgAAgCGCJAAAAEMESQAAAIYIkgAAAAwRJAEAABgiSAIAADBEkAQAAGCIIAkAAMAQQRIAAIAhgiQAAABDBEkAAACGCJIAAAAMESQBAAAYIkgCAAAwRJAEAABgiCAJAADAEEESAACAIYIkAAAAQwRJAAAAhgiSAAAADBEkAQAAGCJIAgAAMKS6e+4aUlVnk7ya5L/nrmUfeVfMxzLzscp8rDqI8/G73f07cxcB60Q/8oYO4vPr/4f5WGU+Vh3E+dixH9kXQTJJquqp7r5r7jr2C/OxynysMh+rzAewWzyfrDIfq8zHKvOxat3mw9JWAAAAhgiSAAAADNlPQfJLcxewz5iPVeZjlflYZT6A3eL5ZJX5WGU+VpmPVWs1H/vmHEkAAADeGvbTO5IAAAC8BcweJKvqg1X1o6o6U1UPzl3PHKrqx1X1TFU9XVVPTWM3VdW3q+r0dPuOuevcK1X1cFW9VFU/XBp7w/2vhS9Ox8sPqurO+SrfGzvMx19X1QvTMfJ0Vd27dN9fTfPxo6r6s3mq3jtVdWtVfaeqnq2qU1X1qWl8bY8RYPfpR/Qj+pFV+pFV+pErzRokq+pQkr9Lck+S25P8RVXdPmdNM/rj7r5j6ZLBDyY52d3Hk5ycvj+oHknywcvGdtr/e5Icn77uT/LQNarxWnokV85HkvztdIzc0d1PJMn0//KRJL83Pebvp/+rg+Riks909+1J7k7ywLTf63yMALtIP7JCP7JqnV9rHol+ZJl+5DJzvyP5+0nOdPd/dvcvk3wtyYmZa9ovTiR5dNp+NMmHZqxlT3X3vyU5d9nwTvt/IslXeuG7Sd5eVe++NpVeGzvMx05OJPlad292938lOZPF/9WB0d0b3f39afsXSZ5LcnPW+BgBdp1+ZGf6kTV9rdGPrNKPXGnuIHlzkp8uff/8NLZuOsm/VtV/VNX909ix7t6Ytn+W5Ng8pc1mp/1f52Pmk9PSiIeXlhat1XxU1XuSvC/Jk3GMALvH88aCfuRKXmuupB/RjySZP0iy8IfdfWcWb4E/UFV/tHxnLy6tu7aX1133/Z88lOS2JHck2UjyN/OWc+1V1dEkX0/y6e4+v3yfYwRgV+hHfo113/+JfkQ/sm3uIPlCkluXvr9lGlsr3f3CdPtSkm9msRTgxa23v6fbl+arcBY77f9aHjPd/WJ3X+ru/0nyD/nVcpG1mI+qOpLFk/ZXu/sb07BjBNgtnjeiH9mB15ol+hH9yLK5g+T3khyvqvdW1XVZnKT7+Mw1XVNV9ZtV9Vtb20n+NMkPs5iH+6Yfuy/Jt+apcDY77f/jST42XQnr7iQ/X1pOcGBdtqb+z7M4RpLFfHykqt5WVe/N4oTuf7/W9e2lqqokX07yXHd/YekuxwiwW/Qj+pGdeK1Zoh/Rjyw7POcf7+6LVfXJJP+S5FCSh7v71Jw1zeBYkm8ujs0cTvKP3f3PVfW9JI9V1SeS/CTJh2escU9V1T8l+UCSd1XV80k+l+TzeeP9fyLJvVmcxP1ako9f84L32A7z8YGquiOL5RI/TvKXSdLdp6rqsSTPZnE1sQe6+9Icde+h9yf5aJJnqurpaeyzWeNjBNhd+pEk+hH9yGX0I1fQj1ymFkt5AQAA4OrMvbQVAACAtxhBEgAAgCGCJAAAAEMESQAAAIYIkgAAAAwRJAEAABgiSAIAADBEkAQAAGDI/wLqk5uTGZ3lxgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Create Model, Loss, Optimizer**"
      ],
      "metadata": {
        "id": "gHKz2v35bAdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_epochs = 20\n",
        "val_interval = 1\n",
        "VAL_AMP = True\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "model = SegResNet(\n",
        "    blocks_down=[1, 2, 2, 4],\n",
        "    blocks_up=[1, 1, 1],\n",
        "    init_filters=16,\n",
        "    in_channels=4,\n",
        "    out_channels=3,\n",
        "    dropout_prob=0.2,\n",
        ").to(device)\n",
        "\n",
        "loss_function = DiceLoss(smooth_nr=0, smooth_dr=1e-5, squared_pred=True, to_onehot_y=False, sigmoid=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-4, weight_decay=1e-5)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)\n",
        "\n",
        "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
        "dice_metric_batch = DiceMetric(include_background=True, reduction=\"mean_batch\")\n",
        "\n",
        "post_trans = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
        "def inference(input):\n",
        "\n",
        "    def _compute(input):\n",
        "        return sliding_window_inference(\n",
        "            inputs=input,\n",
        "            roi_size=(240, 240, 160),\n",
        "            sw_batch_size=1,\n",
        "            predictor=model,\n",
        "            overlap=0.5,\n",
        "        )\n",
        "\n",
        "    if VAL_AMP:\n",
        "        with torch.cuda.amp.autocast():return _compute(input)\n",
        "    else: return _compute(input)\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "bFqf3shmPzl9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**training process**"
      ],
      "metadata": {
        "id": "C4Q4NmBtbYta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_metric = -1\n",
        "best_metric_epoch = -1\n",
        "best_metrics_epochs_and_time = [[], [], []]\n",
        "epoch_loss_values = []\n",
        "metric_values = []\n",
        "metric_values_tc = []\n",
        "metric_values_wt = []\n",
        "metric_values_et = []\n",
        "max_epochs = 20\n",
        "val_interval = 1\n",
        "total_start = time.time()\n",
        "for epoch in range(max_epochs):\n",
        "    epoch_start = time.time()\n",
        "    print(\"-\" * 10)\n",
        "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "    for batch_data in train_loader:\n",
        "        step_start = time.time()\n",
        "        step += 1\n",
        "        inputs, labels = (\n",
        "            batch_data[\"image\"].to(device),\n",
        "            batch_data[\"label\"].to(device),\n",
        "        )\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs, labels)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        epoch_loss += loss.item()\n",
        "        print(\n",
        "            f\"{step}/{len(train_loader) // train_loader.batch_size}\"\n",
        "            f\", train_loss: {loss.item():.4f}\"\n",
        "            f\", step time: {(time.time() - step_start):.4f}\"\n",
        "        )\n",
        "    lr_scheduler.step()\n",
        "    epoch_loss /= step\n",
        "    epoch_loss_values.append(epoch_loss)\n",
        "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    if (epoch + 1) % val_interval == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for val_data in val_loader:\n",
        "                val_inputs, val_labels = (\n",
        "                    val_data[\"image\"].to(device),\n",
        "                    val_data[\"label\"].to(device),\n",
        "                )\n",
        "                val_outputs = inference(val_inputs)\n",
        "                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
        "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
        "                dice_metric_batch(y_pred=val_outputs, y=val_labels)\n",
        "\n",
        "            metric = dice_metric.aggregate().item()\n",
        "            metric_values.append(metric)\n",
        "            metric_batch = dice_metric_batch.aggregate()\n",
        "            metric_tc = metric_batch[0].item()\n",
        "            metric_values_tc.append(metric_tc)\n",
        "            metric_wt = metric_batch[1].item()\n",
        "            metric_values_wt.append(metric_wt)\n",
        "            metric_et = metric_batch[2].item()\n",
        "            metric_values_et.append(metric_et)\n",
        "            dice_metric.reset()\n",
        "            dice_metric_batch.reset()\n",
        "\n",
        "            if metric > best_metric:\n",
        "\n",
        "                best_metric = metric\n",
        "                best_metric_epoch = epoch + 1\n",
        "                best_metrics_epochs_and_time[0].append(best_metric)\n",
        "                best_metrics_epochs_and_time[1].append(best_metric_epoch)\n",
        "                best_metrics_epochs_and_time[2].append(time.time() - total_start)\n",
        "                torch.save(\n",
        "                    model.state_dict(),\n",
        "                    os.path.join(root_dir, \"best_metric_model.pth\"),\n",
        "                )\n",
        "                print(\"saved new best metric model\")\n",
        "            print(\n",
        "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
        "                f\" tc: {metric_tc:.4f} wt: {metric_wt:.4f} et: {metric_et:.4f}\"\n",
        "                f\"\\nbest mean dice: {best_metric:.4f}\"\n",
        "                f\" at epoch: {best_metric_epoch}\"\n",
        "            )\n",
        "    print(f\"time consuming of epoch {epoch + 1} is: {(time.time() - epoch_start):.4f}\")\n",
        "total_time = time.time() - total_start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiPS2tvyP3WR",
        "outputId": "926c1e83-cfa6-4f28-dc47-8aa131ecc046"
      },
      "execution_count": 15,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------\n",
            "epoch 1/20\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mเอาต์พุตของการสตรีมมีการตัดเหลือเพียง 5000 บรรทัดสุดท้าย\u001b[0m\n",
            "36/1001, train_loss: 1.0000, step time: 0.6230\n",
            "37/1001, train_loss: 0.0787, step time: 0.6484\n",
            "38/1001, train_loss: 0.3626, step time: 0.6540\n",
            "39/1001, train_loss: 0.0500, step time: 0.6728\n",
            "40/1001, train_loss: 0.7155, step time: 0.6913\n",
            "41/1001, train_loss: 0.0472, step time: 0.6640\n",
            "42/1001, train_loss: 0.2271, step time: 0.6607\n",
            "43/1001, train_loss: 0.0530, step time: 0.6661\n",
            "44/1001, train_loss: 0.0764, step time: 0.6804\n",
            "45/1001, train_loss: 0.1641, step time: 0.6519\n",
            "46/1001, train_loss: 0.0563, step time: 0.6524\n",
            "47/1001, train_loss: 1.0000, step time: 0.6380\n",
            "48/1001, train_loss: 0.1186, step time: 0.6516\n",
            "49/1001, train_loss: 0.9664, step time: 0.6502\n",
            "50/1001, train_loss: 0.3631, step time: 0.6529\n",
            "51/1001, train_loss: 0.0340, step time: 0.6485\n",
            "52/1001, train_loss: 0.0549, step time: 0.6447\n",
            "53/1001, train_loss: 0.1300, step time: 0.6512\n",
            "54/1001, train_loss: 0.4108, step time: 0.6479\n",
            "55/1001, train_loss: 0.1556, step time: 0.6803\n",
            "56/1001, train_loss: 0.0760, step time: 0.6556\n",
            "57/1001, train_loss: 0.0352, step time: 0.6502\n",
            "58/1001, train_loss: 0.0745, step time: 0.6745\n",
            "59/1001, train_loss: 0.5449, step time: 0.6534\n",
            "60/1001, train_loss: 0.1192, step time: 0.6674\n",
            "61/1001, train_loss: 0.9702, step time: 0.6551\n",
            "62/1001, train_loss: 0.0428, step time: 0.6554\n",
            "63/1001, train_loss: 0.9100, step time: 0.6501\n",
            "64/1001, train_loss: 0.1187, step time: 0.6540\n",
            "65/1001, train_loss: 0.5170, step time: 0.6561\n",
            "66/1001, train_loss: 0.3035, step time: 0.6514\n",
            "67/1001, train_loss: 0.0325, step time: 0.6747\n",
            "68/1001, train_loss: 0.0471, step time: 0.6533\n",
            "69/1001, train_loss: 0.2518, step time: 0.6585\n",
            "70/1001, train_loss: 0.4594, step time: 0.6477\n",
            "71/1001, train_loss: 0.0937, step time: 0.6494\n",
            "72/1001, train_loss: 0.2510, step time: 0.6507\n",
            "73/1001, train_loss: 0.1733, step time: 0.6510\n",
            "74/1001, train_loss: 0.0474, step time: 0.6463\n",
            "75/1001, train_loss: 0.1340, step time: 0.6486\n",
            "76/1001, train_loss: 1.0000, step time: 0.6257\n",
            "77/1001, train_loss: 0.4541, step time: 0.6535\n",
            "78/1001, train_loss: 0.0683, step time: 0.6485\n",
            "79/1001, train_loss: 0.3148, step time: 0.6518\n",
            "80/1001, train_loss: 1.0000, step time: 0.6425\n",
            "81/1001, train_loss: 0.0376, step time: 0.6504\n",
            "82/1001, train_loss: 0.0406, step time: 0.6502\n",
            "83/1001, train_loss: 0.0690, step time: 0.6616\n",
            "84/1001, train_loss: 0.0239, step time: 0.6450\n",
            "85/1001, train_loss: 0.0752, step time: 0.6490\n",
            "86/1001, train_loss: 0.0898, step time: 0.6505\n",
            "87/1001, train_loss: 0.1498, step time: 0.6758\n",
            "88/1001, train_loss: 0.0734, step time: 0.6756\n",
            "89/1001, train_loss: 0.0844, step time: 0.6547\n",
            "90/1001, train_loss: 0.0907, step time: 0.6491\n",
            "91/1001, train_loss: 0.0875, step time: 0.6539\n",
            "92/1001, train_loss: 0.0865, step time: 0.6561\n",
            "93/1001, train_loss: 0.0781, step time: 0.6503\n",
            "94/1001, train_loss: 0.0476, step time: 0.6490\n",
            "95/1001, train_loss: 0.6629, step time: 0.6759\n",
            "96/1001, train_loss: 0.0955, step time: 0.6515\n",
            "97/1001, train_loss: 0.0515, step time: 0.6440\n",
            "98/1001, train_loss: 0.0363, step time: 0.6493\n",
            "99/1001, train_loss: 0.2896, step time: 0.6593\n",
            "100/1001, train_loss: 0.0869, step time: 0.6497\n",
            "101/1001, train_loss: 0.1221, step time: 0.6494\n",
            "102/1001, train_loss: 0.1868, step time: 0.6519\n",
            "103/1001, train_loss: 0.9981, step time: 0.6494\n",
            "104/1001, train_loss: 0.0635, step time: 0.6515\n",
            "105/1001, train_loss: 0.9993, step time: 0.6364\n",
            "106/1001, train_loss: 0.0928, step time: 0.6540\n",
            "107/1001, train_loss: 0.1218, step time: 0.6507\n",
            "108/1001, train_loss: 0.2766, step time: 0.6525\n",
            "109/1001, train_loss: 0.6939, step time: 0.6370\n",
            "110/1001, train_loss: 0.0791, step time: 0.6766\n",
            "111/1001, train_loss: 0.0914, step time: 0.6474\n",
            "112/1001, train_loss: 0.0686, step time: 0.6617\n",
            "113/1001, train_loss: 0.1677, step time: 0.6677\n",
            "114/1001, train_loss: 0.1984, step time: 0.6706\n",
            "115/1001, train_loss: 0.2704, step time: 0.6524\n",
            "116/1001, train_loss: 0.7190, step time: 0.6623\n",
            "117/1001, train_loss: 1.0000, step time: 0.6225\n",
            "118/1001, train_loss: 0.0264, step time: 0.6458\n",
            "119/1001, train_loss: 0.0832, step time: 0.6493\n",
            "120/1001, train_loss: 0.0528, step time: 0.6467\n",
            "121/1001, train_loss: 1.0000, step time: 0.6226\n",
            "122/1001, train_loss: 0.0834, step time: 0.6630\n",
            "123/1001, train_loss: 0.0780, step time: 0.6476\n",
            "124/1001, train_loss: 0.1722, step time: 0.6535\n",
            "125/1001, train_loss: 0.0582, step time: 0.6653\n",
            "126/1001, train_loss: 0.1414, step time: 0.6764\n",
            "127/1001, train_loss: 0.0299, step time: 0.6671\n",
            "128/1001, train_loss: 0.1275, step time: 0.6506\n",
            "129/1001, train_loss: 0.0429, step time: 0.6489\n",
            "130/1001, train_loss: 0.1086, step time: 0.6864\n",
            "131/1001, train_loss: 0.1469, step time: 0.6499\n",
            "132/1001, train_loss: 0.0550, step time: 0.6462\n",
            "133/1001, train_loss: 0.0330, step time: 0.6496\n",
            "134/1001, train_loss: 0.3014, step time: 0.6522\n",
            "135/1001, train_loss: 0.0658, step time: 0.6752\n",
            "136/1001, train_loss: 0.1503, step time: 0.6553\n",
            "137/1001, train_loss: 0.0545, step time: 0.6449\n",
            "138/1001, train_loss: 0.6039, step time: 0.6673\n",
            "139/1001, train_loss: 0.1340, step time: 0.6670\n",
            "140/1001, train_loss: 0.1918, step time: 0.6551\n",
            "141/1001, train_loss: 0.0242, step time: 0.6492\n",
            "142/1001, train_loss: 0.9999, step time: 0.6333\n",
            "143/1001, train_loss: 0.0512, step time: 0.6470\n",
            "144/1001, train_loss: 0.0599, step time: 0.6462\n",
            "145/1001, train_loss: 0.1763, step time: 0.6495\n",
            "146/1001, train_loss: 0.1297, step time: 0.6495\n",
            "147/1001, train_loss: 0.0448, step time: 0.6482\n",
            "148/1001, train_loss: 0.0426, step time: 0.6471\n",
            "149/1001, train_loss: 1.0000, step time: 0.6237\n",
            "150/1001, train_loss: 0.0883, step time: 0.6497\n",
            "151/1001, train_loss: 0.0318, step time: 0.6432\n",
            "152/1001, train_loss: 0.0494, step time: 0.6471\n",
            "153/1001, train_loss: 0.1217, step time: 0.6501\n",
            "154/1001, train_loss: 0.9904, step time: 0.6485\n",
            "155/1001, train_loss: 0.3113, step time: 0.6589\n",
            "156/1001, train_loss: 0.2514, step time: 0.6711\n",
            "157/1001, train_loss: 0.0594, step time: 0.6497\n",
            "158/1001, train_loss: 0.6266, step time: 0.6575\n",
            "159/1001, train_loss: 0.0438, step time: 0.6620\n",
            "160/1001, train_loss: 0.1310, step time: 0.6503\n",
            "161/1001, train_loss: 0.6926, step time: 0.6523\n",
            "162/1001, train_loss: 0.5787, step time: 0.6702\n",
            "163/1001, train_loss: 0.0790, step time: 0.6666\n",
            "164/1001, train_loss: 0.9129, step time: 0.6795\n",
            "165/1001, train_loss: 0.1300, step time: 0.6488\n",
            "166/1001, train_loss: 0.0788, step time: 0.6520\n",
            "167/1001, train_loss: 0.0548, step time: 0.6462\n",
            "168/1001, train_loss: 0.1384, step time: 0.6549\n",
            "169/1001, train_loss: 0.0842, step time: 0.6474\n",
            "170/1001, train_loss: 1.0000, step time: 0.6244\n",
            "171/1001, train_loss: 0.0211, step time: 0.6463\n",
            "172/1001, train_loss: 0.0640, step time: 0.6538\n",
            "173/1001, train_loss: 0.0443, step time: 0.6492\n",
            "174/1001, train_loss: 0.0826, step time: 0.6500\n",
            "175/1001, train_loss: 0.2886, step time: 0.6576\n",
            "176/1001, train_loss: 0.1267, step time: 0.6483\n",
            "177/1001, train_loss: 0.0336, step time: 0.6665\n",
            "178/1001, train_loss: 0.0658, step time: 0.6561\n",
            "179/1001, train_loss: 0.0409, step time: 0.6467\n",
            "180/1001, train_loss: 0.7710, step time: 0.6495\n",
            "181/1001, train_loss: 0.0622, step time: 0.6449\n",
            "182/1001, train_loss: 0.0328, step time: 0.6452\n",
            "183/1001, train_loss: 0.0419, step time: 0.6458\n",
            "184/1001, train_loss: 0.0871, step time: 0.6498\n",
            "185/1001, train_loss: 0.0445, step time: 0.6563\n",
            "186/1001, train_loss: 0.1400, step time: 0.6495\n",
            "187/1001, train_loss: 0.0356, step time: 0.6772\n",
            "188/1001, train_loss: 0.4870, step time: 0.6530\n",
            "189/1001, train_loss: 1.0000, step time: 0.6365\n",
            "190/1001, train_loss: 0.0627, step time: 0.6521\n",
            "191/1001, train_loss: 0.6671, step time: 0.6614\n",
            "192/1001, train_loss: 0.6834, step time: 0.6386\n",
            "193/1001, train_loss: 0.1437, step time: 0.6498\n",
            "194/1001, train_loss: 0.0505, step time: 0.6447\n",
            "195/1001, train_loss: 0.7499, step time: 0.6502\n",
            "196/1001, train_loss: 0.0620, step time: 0.6602\n",
            "197/1001, train_loss: 0.0365, step time: 0.6543\n",
            "198/1001, train_loss: 0.0575, step time: 0.6490\n",
            "199/1001, train_loss: 0.0837, step time: 0.6493\n",
            "200/1001, train_loss: 1.0000, step time: 0.6318\n",
            "201/1001, train_loss: 0.2619, step time: 0.6521\n",
            "202/1001, train_loss: 0.1920, step time: 0.6532\n",
            "203/1001, train_loss: 0.0408, step time: 0.6475\n",
            "204/1001, train_loss: 0.4249, step time: 0.6775\n",
            "205/1001, train_loss: 0.9878, step time: 0.6497\n",
            "206/1001, train_loss: 0.0645, step time: 0.6488\n",
            "207/1001, train_loss: 0.0312, step time: 0.6536\n",
            "208/1001, train_loss: 0.2860, step time: 0.6643\n",
            "209/1001, train_loss: 0.0896, step time: 0.6630\n",
            "210/1001, train_loss: 0.0568, step time: 0.6634\n",
            "211/1001, train_loss: 0.9983, step time: 0.6419\n",
            "212/1001, train_loss: 0.8168, step time: 0.6661\n",
            "213/1001, train_loss: 0.1690, step time: 0.6507\n",
            "214/1001, train_loss: 1.0000, step time: 0.6239\n",
            "215/1001, train_loss: 0.1285, step time: 0.6521\n",
            "216/1001, train_loss: 0.0487, step time: 0.6471\n",
            "217/1001, train_loss: 0.0984, step time: 0.6528\n",
            "218/1001, train_loss: 0.2539, step time: 0.6514\n",
            "219/1001, train_loss: 0.6874, step time: 0.6788\n",
            "220/1001, train_loss: 0.0562, step time: 0.6489\n",
            "221/1001, train_loss: 0.0422, step time: 0.6487\n",
            "222/1001, train_loss: 0.1501, step time: 0.6519\n",
            "223/1001, train_loss: 0.6792, step time: 0.6476\n",
            "224/1001, train_loss: 0.0770, step time: 0.6599\n",
            "225/1001, train_loss: 0.0719, step time: 0.6512\n",
            "226/1001, train_loss: 0.6972, step time: 0.6736\n",
            "227/1001, train_loss: 0.1008, step time: 0.6694\n",
            "228/1001, train_loss: 0.1416, step time: 0.6577\n",
            "229/1001, train_loss: 0.0337, step time: 0.6480\n",
            "230/1001, train_loss: 0.1628, step time: 0.6775\n",
            "231/1001, train_loss: 0.0880, step time: 0.6530\n",
            "232/1001, train_loss: 0.0381, step time: 0.6619\n",
            "233/1001, train_loss: 0.0827, step time: 0.6503\n",
            "234/1001, train_loss: 0.0454, step time: 0.6489\n",
            "235/1001, train_loss: 0.1967, step time: 0.6563\n",
            "236/1001, train_loss: 0.1292, step time: 0.6462\n",
            "237/1001, train_loss: 0.0488, step time: 0.6519\n",
            "238/1001, train_loss: 0.3969, step time: 0.6501\n",
            "239/1001, train_loss: 1.0000, step time: 0.6229\n",
            "240/1001, train_loss: 0.1505, step time: 0.6705\n",
            "241/1001, train_loss: 0.1175, step time: 0.6630\n",
            "242/1001, train_loss: 0.9783, step time: 0.6936\n",
            "243/1001, train_loss: 1.0000, step time: 0.6387\n",
            "244/1001, train_loss: 0.0689, step time: 0.6477\n",
            "245/1001, train_loss: 0.0523, step time: 0.6481\n",
            "246/1001, train_loss: 0.0815, step time: 0.6461\n",
            "247/1001, train_loss: 0.0354, step time: 0.6617\n",
            "248/1001, train_loss: 0.0672, step time: 0.6522\n",
            "249/1001, train_loss: 0.1992, step time: 0.6581\n",
            "250/1001, train_loss: 0.0627, step time: 0.6611\n",
            "251/1001, train_loss: 0.0693, step time: 0.6539\n",
            "252/1001, train_loss: 0.0672, step time: 0.6469\n",
            "253/1001, train_loss: 0.1043, step time: 0.6714\n",
            "254/1001, train_loss: 0.6974, step time: 0.6492\n",
            "255/1001, train_loss: 0.5691, step time: 0.6566\n",
            "256/1001, train_loss: 0.7633, step time: 0.6465\n",
            "257/1001, train_loss: 0.0910, step time: 0.6460\n",
            "258/1001, train_loss: 0.9999, step time: 0.6246\n",
            "259/1001, train_loss: 0.0572, step time: 0.6566\n",
            "260/1001, train_loss: 0.1041, step time: 0.6457\n",
            "261/1001, train_loss: 0.0869, step time: 0.6558\n",
            "262/1001, train_loss: 0.4466, step time: 0.6526\n",
            "263/1001, train_loss: 0.4611, step time: 0.6507\n",
            "264/1001, train_loss: 1.0000, step time: 0.6378\n",
            "265/1001, train_loss: 0.6922, step time: 0.6512\n",
            "266/1001, train_loss: 0.0747, step time: 0.6945\n",
            "267/1001, train_loss: 0.0381, step time: 0.6472\n",
            "268/1001, train_loss: 0.0485, step time: 0.6568\n",
            "269/1001, train_loss: 0.0602, step time: 0.6477\n",
            "270/1001, train_loss: 0.1835, step time: 0.6498\n",
            "271/1001, train_loss: 0.3897, step time: 0.6538\n",
            "272/1001, train_loss: 1.0000, step time: 0.6497\n",
            "273/1001, train_loss: 0.4093, step time: 0.6542\n",
            "274/1001, train_loss: 0.0600, step time: 0.6462\n",
            "275/1001, train_loss: 0.7785, step time: 0.6567\n",
            "276/1001, train_loss: 0.9946, step time: 0.6729\n",
            "277/1001, train_loss: 0.0398, step time: 0.6560\n",
            "278/1001, train_loss: 1.0000, step time: 0.6245\n",
            "279/1001, train_loss: 0.0908, step time: 0.6724\n",
            "280/1001, train_loss: 0.1012, step time: 0.6588\n",
            "281/1001, train_loss: 1.0000, step time: 0.6234\n",
            "282/1001, train_loss: 0.1338, step time: 0.6503\n",
            "283/1001, train_loss: 0.0424, step time: 0.6644\n",
            "284/1001, train_loss: 0.2345, step time: 0.6541\n",
            "285/1001, train_loss: 0.0994, step time: 0.6461\n",
            "286/1001, train_loss: 0.0867, step time: 0.6519\n",
            "287/1001, train_loss: 0.8176, step time: 0.6508\n",
            "288/1001, train_loss: 0.0580, step time: 0.6776\n",
            "289/1001, train_loss: 0.8872, step time: 0.6550\n",
            "290/1001, train_loss: 0.0741, step time: 0.6505\n",
            "291/1001, train_loss: 0.0638, step time: 0.6452\n",
            "292/1001, train_loss: 0.0439, step time: 0.6470\n",
            "293/1001, train_loss: 0.0590, step time: 0.6485\n",
            "294/1001, train_loss: 0.0574, step time: 0.6540\n",
            "295/1001, train_loss: 0.0490, step time: 0.6694\n",
            "296/1001, train_loss: 0.0523, step time: 0.6511\n",
            "297/1001, train_loss: 0.8516, step time: 0.6674\n",
            "298/1001, train_loss: 0.1678, step time: 0.6755\n",
            "299/1001, train_loss: 0.1215, step time: 0.6717\n",
            "300/1001, train_loss: 0.9556, step time: 0.6492\n",
            "301/1001, train_loss: 0.1163, step time: 0.6550\n",
            "302/1001, train_loss: 0.2863, step time: 0.6578\n",
            "303/1001, train_loss: 0.1959, step time: 0.6579\n",
            "304/1001, train_loss: 0.1157, step time: 0.6522\n",
            "305/1001, train_loss: 0.9020, step time: 0.6530\n",
            "306/1001, train_loss: 1.0000, step time: 0.6236\n",
            "307/1001, train_loss: 1.0000, step time: 0.6248\n",
            "308/1001, train_loss: 1.0000, step time: 0.6286\n",
            "309/1001, train_loss: 0.6859, step time: 0.6772\n",
            "310/1001, train_loss: 0.1264, step time: 0.6547\n",
            "311/1001, train_loss: 1.0000, step time: 0.6237\n",
            "312/1001, train_loss: 0.1349, step time: 0.6552\n",
            "313/1001, train_loss: 0.1132, step time: 0.6518\n",
            "314/1001, train_loss: 0.1745, step time: 0.6530\n",
            "315/1001, train_loss: 0.0800, step time: 0.6498\n",
            "316/1001, train_loss: 0.0619, step time: 0.6522\n",
            "317/1001, train_loss: 0.5158, step time: 0.6537\n",
            "318/1001, train_loss: 0.1049, step time: 0.6556\n",
            "319/1001, train_loss: 0.0330, step time: 0.6488\n",
            "320/1001, train_loss: 0.7054, step time: 0.6564\n",
            "321/1001, train_loss: 0.2342, step time: 0.6603\n",
            "322/1001, train_loss: 1.0000, step time: 0.6227\n",
            "323/1001, train_loss: 0.2454, step time: 0.6527\n",
            "324/1001, train_loss: 0.0899, step time: 0.6516\n",
            "325/1001, train_loss: 0.0945, step time: 0.6518\n",
            "326/1001, train_loss: 0.0749, step time: 0.6742\n",
            "327/1001, train_loss: 0.7027, step time: 0.6523\n",
            "328/1001, train_loss: 0.9790, step time: 0.6483\n",
            "329/1001, train_loss: 0.0858, step time: 0.6497\n",
            "330/1001, train_loss: 0.0781, step time: 0.6501\n",
            "331/1001, train_loss: 0.0860, step time: 0.6507\n",
            "332/1001, train_loss: 0.0525, step time: 0.6468\n",
            "333/1001, train_loss: 0.0499, step time: 0.6488\n",
            "334/1001, train_loss: 0.0892, step time: 0.6509\n",
            "335/1001, train_loss: 0.0468, step time: 0.6483\n",
            "336/1001, train_loss: 0.1780, step time: 0.6519\n",
            "337/1001, train_loss: 0.5346, step time: 0.6533\n",
            "338/1001, train_loss: 0.1015, step time: 0.6473\n",
            "339/1001, train_loss: 0.8311, step time: 0.6519\n",
            "340/1001, train_loss: 0.0517, step time: 0.6471\n",
            "341/1001, train_loss: 0.7031, step time: 0.6496\n",
            "342/1001, train_loss: 0.0679, step time: 0.6485\n",
            "343/1001, train_loss: 0.0508, step time: 0.6480\n",
            "344/1001, train_loss: 0.5811, step time: 0.6507\n",
            "345/1001, train_loss: 0.4712, step time: 0.6518\n",
            "346/1001, train_loss: 0.2371, step time: 0.6529\n",
            "347/1001, train_loss: 0.0727, step time: 0.6485\n",
            "348/1001, train_loss: 0.8500, step time: 0.6520\n",
            "349/1001, train_loss: 0.0594, step time: 0.6730\n",
            "350/1001, train_loss: 0.0882, step time: 0.6557\n",
            "351/1001, train_loss: 1.0000, step time: 0.6235\n",
            "352/1001, train_loss: 0.0697, step time: 0.6739\n",
            "353/1001, train_loss: 0.3635, step time: 0.6741\n",
            "354/1001, train_loss: 0.0246, step time: 0.6663\n",
            "355/1001, train_loss: 0.5906, step time: 0.6675\n",
            "356/1001, train_loss: 0.7191, step time: 0.6630\n",
            "357/1001, train_loss: 0.1043, step time: 0.6603\n",
            "358/1001, train_loss: 0.0762, step time: 0.6565\n",
            "359/1001, train_loss: 0.0675, step time: 0.6509\n",
            "360/1001, train_loss: 0.4814, step time: 0.6523\n",
            "361/1001, train_loss: 0.0398, step time: 0.6660\n",
            "362/1001, train_loss: 0.0953, step time: 0.6680\n",
            "363/1001, train_loss: 0.0785, step time: 0.6761\n",
            "364/1001, train_loss: 0.1084, step time: 0.6561\n",
            "365/1001, train_loss: 0.9074, step time: 0.6542\n",
            "366/1001, train_loss: 0.7649, step time: 0.6609\n",
            "367/1001, train_loss: 0.9988, step time: 0.6441\n",
            "368/1001, train_loss: 1.0000, step time: 0.6243\n",
            "369/1001, train_loss: 0.1506, step time: 0.6511\n",
            "370/1001, train_loss: 0.0516, step time: 0.6625\n",
            "371/1001, train_loss: 0.0903, step time: 0.6667\n",
            "372/1001, train_loss: 0.0761, step time: 0.6599\n",
            "373/1001, train_loss: 0.0662, step time: 0.6582\n",
            "374/1001, train_loss: 0.2619, step time: 0.6548\n",
            "375/1001, train_loss: 0.2208, step time: 0.6526\n",
            "376/1001, train_loss: 0.0815, step time: 0.6526\n",
            "377/1001, train_loss: 0.0323, step time: 0.6521\n",
            "378/1001, train_loss: 0.9999, step time: 0.6291\n",
            "379/1001, train_loss: 0.0622, step time: 0.6493\n",
            "380/1001, train_loss: 0.0482, step time: 0.6532\n",
            "381/1001, train_loss: 0.1335, step time: 0.6497\n",
            "382/1001, train_loss: 0.9950, step time: 0.6646\n",
            "383/1001, train_loss: 0.1342, step time: 0.6512\n",
            "384/1001, train_loss: 0.1429, step time: 0.6510\n",
            "385/1001, train_loss: 0.1032, step time: 0.6503\n",
            "386/1001, train_loss: 0.0400, step time: 0.6503\n",
            "387/1001, train_loss: 0.8086, step time: 0.6583\n",
            "388/1001, train_loss: 0.0998, step time: 0.6614\n",
            "389/1001, train_loss: 0.0713, step time: 0.6505\n",
            "390/1001, train_loss: 0.1450, step time: 0.6556\n",
            "391/1001, train_loss: 0.0403, step time: 0.6571\n",
            "392/1001, train_loss: 0.0805, step time: 0.6764\n",
            "393/1001, train_loss: 0.1189, step time: 0.6657\n",
            "394/1001, train_loss: 0.0905, step time: 0.6787\n",
            "395/1001, train_loss: 0.0510, step time: 0.6482\n",
            "396/1001, train_loss: 0.0770, step time: 0.6510\n",
            "397/1001, train_loss: 0.0431, step time: 0.6754\n",
            "398/1001, train_loss: 0.1263, step time: 0.6513\n",
            "399/1001, train_loss: 0.0832, step time: 0.6474\n",
            "400/1001, train_loss: 0.0419, step time: 0.6476\n",
            "401/1001, train_loss: 0.1822, step time: 0.6517\n",
            "402/1001, train_loss: 0.6355, step time: 0.6513\n",
            "403/1001, train_loss: 1.0000, step time: 0.6242\n",
            "404/1001, train_loss: 0.0882, step time: 0.6507\n",
            "405/1001, train_loss: 0.0736, step time: 0.6492\n",
            "406/1001, train_loss: 1.0000, step time: 0.6239\n",
            "407/1001, train_loss: 0.7001, step time: 0.6553\n",
            "408/1001, train_loss: 0.0781, step time: 0.6475\n",
            "409/1001, train_loss: 0.0724, step time: 0.6530\n",
            "410/1001, train_loss: 0.1395, step time: 0.6518\n",
            "411/1001, train_loss: 1.0000, step time: 0.6741\n",
            "412/1001, train_loss: 0.0929, step time: 0.6523\n",
            "413/1001, train_loss: 0.3314, step time: 0.6602\n",
            "414/1001, train_loss: 0.0362, step time: 0.6450\n",
            "415/1001, train_loss: 0.0666, step time: 0.6456\n",
            "416/1001, train_loss: 0.1882, step time: 0.6498\n",
            "417/1001, train_loss: 0.1634, step time: 0.6504\n",
            "418/1001, train_loss: 0.2730, step time: 0.6534\n",
            "419/1001, train_loss: 0.0436, step time: 0.6729\n",
            "420/1001, train_loss: 0.9986, step time: 0.6636\n",
            "421/1001, train_loss: 0.1089, step time: 0.6517\n",
            "422/1001, train_loss: 0.8981, step time: 0.6535\n",
            "423/1001, train_loss: 0.0871, step time: 0.6496\n",
            "424/1001, train_loss: 0.0580, step time: 0.6549\n",
            "425/1001, train_loss: 0.6899, step time: 0.6485\n",
            "426/1001, train_loss: 0.0731, step time: 0.6478\n",
            "427/1001, train_loss: 0.0729, step time: 0.6517\n",
            "428/1001, train_loss: 0.0307, step time: 0.6511\n",
            "429/1001, train_loss: 0.1188, step time: 0.6676\n",
            "430/1001, train_loss: 0.0475, step time: 0.6500\n",
            "431/1001, train_loss: 0.6773, step time: 0.6526\n",
            "432/1001, train_loss: 0.0713, step time: 0.6737\n",
            "433/1001, train_loss: 0.7023, step time: 0.6780\n",
            "434/1001, train_loss: 0.1249, step time: 0.6699\n",
            "435/1001, train_loss: 0.0823, step time: 0.6529\n",
            "436/1001, train_loss: 0.7233, step time: 0.6504\n",
            "437/1001, train_loss: 0.2065, step time: 0.6514\n",
            "438/1001, train_loss: 0.0560, step time: 0.6496\n",
            "439/1001, train_loss: 0.0386, step time: 0.6693\n",
            "440/1001, train_loss: 0.0779, step time: 0.6709\n",
            "441/1001, train_loss: 0.0476, step time: 0.6474\n",
            "442/1001, train_loss: 0.0573, step time: 0.6531\n",
            "443/1001, train_loss: 0.0476, step time: 0.6454\n",
            "444/1001, train_loss: 0.0675, step time: 0.6507\n",
            "445/1001, train_loss: 0.0534, step time: 0.6748\n",
            "446/1001, train_loss: 0.0600, step time: 0.6631\n",
            "447/1001, train_loss: 0.0548, step time: 0.6554\n",
            "448/1001, train_loss: 0.6803, step time: 0.6701\n",
            "449/1001, train_loss: 0.0535, step time: 0.6530\n",
            "450/1001, train_loss: 1.0000, step time: 0.6230\n",
            "451/1001, train_loss: 0.0742, step time: 0.6716\n",
            "452/1001, train_loss: 0.6493, step time: 0.6535\n",
            "453/1001, train_loss: 0.0557, step time: 0.6683\n",
            "454/1001, train_loss: 1.0000, step time: 0.6282\n",
            "455/1001, train_loss: 0.6972, step time: 0.6529\n",
            "456/1001, train_loss: 0.2093, step time: 0.6488\n",
            "457/1001, train_loss: 0.1563, step time: 0.6612\n",
            "458/1001, train_loss: 0.0399, step time: 0.6506\n",
            "459/1001, train_loss: 0.1350, step time: 0.6541\n",
            "460/1001, train_loss: 0.0486, step time: 0.6661\n",
            "461/1001, train_loss: 0.4921, step time: 0.6525\n",
            "462/1001, train_loss: 0.1465, step time: 0.6565\n",
            "463/1001, train_loss: 0.1893, step time: 0.6553\n",
            "464/1001, train_loss: 0.0540, step time: 0.6488\n",
            "465/1001, train_loss: 0.6818, step time: 0.6685\n",
            "466/1001, train_loss: 0.1443, step time: 0.6707\n",
            "467/1001, train_loss: 0.2458, step time: 0.6541\n",
            "468/1001, train_loss: 0.0785, step time: 0.6483\n",
            "469/1001, train_loss: 0.0858, step time: 0.6579\n",
            "470/1001, train_loss: 0.9128, step time: 0.6766\n",
            "471/1001, train_loss: 0.1602, step time: 0.6791\n",
            "472/1001, train_loss: 0.0435, step time: 0.6553\n",
            "473/1001, train_loss: 0.0679, step time: 0.6502\n",
            "474/1001, train_loss: 0.0902, step time: 0.6772\n",
            "475/1001, train_loss: 0.0991, step time: 0.6552\n",
            "476/1001, train_loss: 0.0549, step time: 0.6517\n",
            "477/1001, train_loss: 0.0408, step time: 0.6787\n",
            "478/1001, train_loss: 0.0545, step time: 0.6505\n",
            "479/1001, train_loss: 0.0471, step time: 0.6635\n",
            "480/1001, train_loss: 0.1999, step time: 0.6528\n",
            "481/1001, train_loss: 0.8002, step time: 0.6548\n",
            "482/1001, train_loss: 0.0377, step time: 0.6530\n",
            "483/1001, train_loss: 0.0479, step time: 0.6473\n",
            "484/1001, train_loss: 0.7277, step time: 0.6670\n",
            "485/1001, train_loss: 0.1244, step time: 0.6499\n",
            "486/1001, train_loss: 0.9654, step time: 0.6498\n",
            "487/1001, train_loss: 0.4310, step time: 0.6771\n",
            "488/1001, train_loss: 0.3844, step time: 0.6671\n",
            "489/1001, train_loss: 0.1624, step time: 0.6569\n",
            "490/1001, train_loss: 1.0000, step time: 0.6257\n",
            "491/1001, train_loss: 0.7271, step time: 0.6499\n",
            "492/1001, train_loss: 0.0728, step time: 0.6513\n",
            "493/1001, train_loss: 0.7295, step time: 0.6706\n",
            "494/1001, train_loss: 0.1191, step time: 0.6539\n",
            "495/1001, train_loss: 0.2912, step time: 0.6524\n",
            "496/1001, train_loss: 0.0504, step time: 0.6465\n",
            "497/1001, train_loss: 0.0626, step time: 0.6491\n",
            "498/1001, train_loss: 0.1104, step time: 0.6482\n",
            "499/1001, train_loss: 0.0671, step time: 0.6600\n",
            "500/1001, train_loss: 0.0419, step time: 0.6572\n",
            "501/1001, train_loss: 0.0943, step time: 0.6454\n",
            "502/1001, train_loss: 0.6627, step time: 0.6646\n",
            "503/1001, train_loss: 0.7276, step time: 0.6547\n",
            "504/1001, train_loss: 0.0408, step time: 0.6589\n",
            "505/1001, train_loss: 0.1338, step time: 0.6804\n",
            "506/1001, train_loss: 0.5974, step time: 0.6515\n",
            "507/1001, train_loss: 0.0303, step time: 0.6493\n",
            "508/1001, train_loss: 0.0817, step time: 0.6482\n",
            "509/1001, train_loss: 0.2833, step time: 0.6542\n",
            "510/1001, train_loss: 0.0524, step time: 0.6474\n",
            "511/1001, train_loss: 0.0387, step time: 0.6511\n",
            "512/1001, train_loss: 0.0551, step time: 0.6818\n",
            "513/1001, train_loss: 0.2317, step time: 0.6552\n",
            "514/1001, train_loss: 0.0432, step time: 0.6747\n",
            "515/1001, train_loss: 0.5855, step time: 0.6829\n",
            "516/1001, train_loss: 1.0000, step time: 0.6316\n",
            "517/1001, train_loss: 0.9260, step time: 0.6518\n",
            "518/1001, train_loss: 0.0645, step time: 0.6701\n",
            "519/1001, train_loss: 0.7189, step time: 0.6577\n",
            "520/1001, train_loss: 0.0880, step time: 0.6508\n",
            "521/1001, train_loss: 0.0499, step time: 0.6535\n",
            "522/1001, train_loss: 0.1167, step time: 0.6508\n",
            "523/1001, train_loss: 0.1168, step time: 0.6510\n",
            "524/1001, train_loss: 0.0681, step time: 0.6506\n",
            "525/1001, train_loss: 0.0449, step time: 0.6485\n",
            "526/1001, train_loss: 0.2160, step time: 0.6527\n",
            "527/1001, train_loss: 0.3629, step time: 0.6480\n",
            "528/1001, train_loss: 0.1274, step time: 0.6695\n",
            "529/1001, train_loss: 0.0474, step time: 0.6572\n",
            "530/1001, train_loss: 0.0822, step time: 0.6493\n",
            "531/1001, train_loss: 0.8768, step time: 0.6517\n",
            "532/1001, train_loss: 0.0696, step time: 0.6491\n",
            "533/1001, train_loss: 0.7782, step time: 0.6526\n",
            "534/1001, train_loss: 1.0000, step time: 0.6282\n",
            "535/1001, train_loss: 0.0433, step time: 0.6567\n",
            "536/1001, train_loss: 0.0844, step time: 0.6483\n",
            "537/1001, train_loss: 0.0747, step time: 0.6501\n",
            "538/1001, train_loss: 0.1070, step time: 0.6557\n",
            "539/1001, train_loss: 1.0000, step time: 0.6492\n",
            "540/1001, train_loss: 0.9897, step time: 0.6437\n",
            "541/1001, train_loss: 0.6390, step time: 0.6744\n",
            "542/1001, train_loss: 0.1510, step time: 0.6543\n",
            "543/1001, train_loss: 1.0000, step time: 0.6413\n",
            "544/1001, train_loss: 0.0741, step time: 0.6498\n",
            "545/1001, train_loss: 0.1675, step time: 0.6561\n",
            "546/1001, train_loss: 1.0000, step time: 0.6500\n",
            "547/1001, train_loss: 0.7571, step time: 0.6774\n",
            "548/1001, train_loss: 0.0892, step time: 0.6506\n",
            "549/1001, train_loss: 0.1027, step time: 0.6493\n",
            "550/1001, train_loss: 0.1666, step time: 0.6499\n",
            "551/1001, train_loss: 0.7821, step time: 0.6534\n",
            "552/1001, train_loss: 0.0457, step time: 0.6450\n",
            "553/1001, train_loss: 0.1347, step time: 0.6568\n",
            "554/1001, train_loss: 0.7033, step time: 0.6855\n",
            "555/1001, train_loss: 0.7022, step time: 0.6565\n",
            "556/1001, train_loss: 0.0428, step time: 0.6492\n",
            "557/1001, train_loss: 0.0416, step time: 0.6487\n",
            "558/1001, train_loss: 0.0332, step time: 0.6610\n",
            "559/1001, train_loss: 0.8102, step time: 0.6524\n",
            "560/1001, train_loss: 0.0828, step time: 0.6512\n",
            "561/1001, train_loss: 1.0000, step time: 0.6232\n",
            "562/1001, train_loss: 0.0332, step time: 0.6435\n",
            "563/1001, train_loss: 0.0526, step time: 0.6481\n",
            "564/1001, train_loss: 0.0382, step time: 0.6483\n",
            "565/1001, train_loss: 0.0891, step time: 0.6780\n",
            "566/1001, train_loss: 0.0592, step time: 0.6489\n",
            "567/1001, train_loss: 0.7244, step time: 0.6531\n",
            "568/1001, train_loss: 0.0327, step time: 0.6768\n",
            "569/1001, train_loss: 0.3099, step time: 0.6852\n",
            "570/1001, train_loss: 0.0772, step time: 0.6550\n",
            "571/1001, train_loss: 1.0000, step time: 0.7561\n",
            "572/1001, train_loss: 0.0917, step time: 0.6544\n",
            "573/1001, train_loss: 0.0461, step time: 0.6523\n",
            "574/1001, train_loss: 0.1171, step time: 0.6517\n",
            "575/1001, train_loss: 0.0487, step time: 0.6695\n",
            "576/1001, train_loss: 0.1169, step time: 0.6597\n",
            "577/1001, train_loss: 0.9975, step time: 0.6436\n",
            "578/1001, train_loss: 0.1819, step time: 0.6743\n",
            "579/1001, train_loss: 0.0625, step time: 0.7031\n",
            "580/1001, train_loss: 0.2297, step time: 0.6532\n",
            "581/1001, train_loss: 0.2529, step time: 0.6612\n",
            "582/1001, train_loss: 1.0000, step time: 0.6244\n",
            "583/1001, train_loss: 0.1261, step time: 0.6505\n",
            "584/1001, train_loss: 1.0000, step time: 0.6232\n",
            "585/1001, train_loss: 0.0403, step time: 0.6564\n",
            "586/1001, train_loss: 0.2526, step time: 0.6746\n",
            "587/1001, train_loss: 1.0000, step time: 0.6437\n",
            "588/1001, train_loss: 1.0000, step time: 0.6383\n",
            "589/1001, train_loss: 0.0369, step time: 0.6816\n",
            "590/1001, train_loss: 1.0000, step time: 0.6232\n",
            "591/1001, train_loss: 0.8308, step time: 0.6568\n",
            "592/1001, train_loss: 0.0596, step time: 0.6639\n",
            "593/1001, train_loss: 0.6346, step time: 0.6531\n",
            "594/1001, train_loss: 0.0452, step time: 0.6551\n",
            "595/1001, train_loss: 0.0776, step time: 0.6632\n",
            "596/1001, train_loss: 0.0506, step time: 0.6837\n",
            "597/1001, train_loss: 0.0795, step time: 0.6813\n",
            "598/1001, train_loss: 0.0247, step time: 0.6668\n",
            "599/1001, train_loss: 0.1101, step time: 0.6539\n",
            "600/1001, train_loss: 0.3650, step time: 0.6763\n",
            "601/1001, train_loss: 0.0576, step time: 0.6507\n",
            "602/1001, train_loss: 0.0907, step time: 0.6517\n",
            "603/1001, train_loss: 1.0000, step time: 0.6373\n",
            "604/1001, train_loss: 0.0508, step time: 0.6502\n",
            "605/1001, train_loss: 0.6174, step time: 0.6524\n",
            "606/1001, train_loss: 0.1163, step time: 0.6510\n",
            "607/1001, train_loss: 0.0428, step time: 0.6513\n",
            "608/1001, train_loss: 1.0000, step time: 0.6231\n",
            "609/1001, train_loss: 0.1682, step time: 0.6524\n",
            "610/1001, train_loss: 0.0296, step time: 0.6465\n",
            "611/1001, train_loss: 0.0580, step time: 0.6626\n",
            "612/1001, train_loss: 0.0646, step time: 0.6726\n",
            "613/1001, train_loss: 0.0490, step time: 0.6483\n",
            "614/1001, train_loss: 0.0514, step time: 0.6487\n",
            "615/1001, train_loss: 0.0552, step time: 0.6511\n",
            "616/1001, train_loss: 0.0338, step time: 0.6515\n",
            "617/1001, train_loss: 0.0900, step time: 0.6830\n",
            "618/1001, train_loss: 0.2931, step time: 0.6620\n",
            "619/1001, train_loss: 0.0667, step time: 0.6751\n",
            "620/1001, train_loss: 0.7576, step time: 0.6535\n",
            "621/1001, train_loss: 0.0541, step time: 0.6748\n",
            "622/1001, train_loss: 0.0310, step time: 0.6901\n",
            "623/1001, train_loss: 0.1390, step time: 0.6755\n",
            "624/1001, train_loss: 0.1067, step time: 0.6525\n",
            "625/1001, train_loss: 0.1377, step time: 0.6501\n",
            "626/1001, train_loss: 1.0000, step time: 0.6230\n",
            "627/1001, train_loss: 0.2421, step time: 0.6525\n",
            "628/1001, train_loss: 0.0697, step time: 0.6549\n",
            "629/1001, train_loss: 0.4032, step time: 0.6647\n",
            "630/1001, train_loss: 0.0318, step time: 0.6497\n",
            "631/1001, train_loss: 0.0537, step time: 0.6509\n",
            "632/1001, train_loss: 0.9809, step time: 0.6485\n",
            "633/1001, train_loss: 0.6673, step time: 0.6621\n",
            "634/1001, train_loss: 0.0676, step time: 0.6526\n",
            "635/1001, train_loss: 0.2164, step time: 0.6497\n",
            "636/1001, train_loss: 1.0000, step time: 0.6232\n",
            "637/1001, train_loss: 0.0427, step time: 0.6549\n",
            "638/1001, train_loss: 0.0824, step time: 0.6562\n",
            "639/1001, train_loss: 0.2449, step time: 0.6707\n",
            "640/1001, train_loss: 0.4633, step time: 0.6515\n",
            "641/1001, train_loss: 0.0562, step time: 0.6478\n",
            "642/1001, train_loss: 0.0813, step time: 0.6498\n",
            "643/1001, train_loss: 0.3978, step time: 0.6519\n",
            "644/1001, train_loss: 1.0000, step time: 0.6234\n",
            "645/1001, train_loss: 0.0893, step time: 0.6498\n",
            "646/1001, train_loss: 0.0765, step time: 0.6559\n",
            "647/1001, train_loss: 0.0846, step time: 0.6750\n",
            "648/1001, train_loss: 1.0000, step time: 0.6442\n",
            "649/1001, train_loss: 0.0559, step time: 0.6480\n",
            "650/1001, train_loss: 0.0667, step time: 0.6515\n",
            "651/1001, train_loss: 0.0459, step time: 0.6675\n",
            "652/1001, train_loss: 0.0446, step time: 0.6821\n",
            "653/1001, train_loss: 0.0703, step time: 0.6525\n",
            "654/1001, train_loss: 0.0462, step time: 0.6610\n",
            "655/1001, train_loss: 0.0875, step time: 0.6506\n",
            "656/1001, train_loss: 0.1270, step time: 0.6514\n",
            "657/1001, train_loss: 0.2294, step time: 0.6729\n",
            "658/1001, train_loss: 0.9954, step time: 0.6631\n",
            "659/1001, train_loss: 0.0841, step time: 0.6495\n",
            "660/1001, train_loss: 0.7119, step time: 0.6811\n",
            "661/1001, train_loss: 0.0972, step time: 0.6689\n",
            "662/1001, train_loss: 0.0472, step time: 0.6466\n",
            "663/1001, train_loss: 0.8960, step time: 0.6515\n",
            "664/1001, train_loss: 0.1407, step time: 0.6506\n",
            "665/1001, train_loss: 0.3987, step time: 0.6691\n",
            "666/1001, train_loss: 0.4863, step time: 0.6640\n",
            "667/1001, train_loss: 0.0973, step time: 0.6547\n",
            "668/1001, train_loss: 0.0575, step time: 0.6804\n",
            "669/1001, train_loss: 0.1017, step time: 0.6735\n",
            "670/1001, train_loss: 0.4584, step time: 0.6573\n",
            "671/1001, train_loss: 0.0435, step time: 0.6614\n",
            "672/1001, train_loss: 0.0781, step time: 0.6670\n",
            "673/1001, train_loss: 0.0544, step time: 0.6488\n",
            "674/1001, train_loss: 0.1802, step time: 0.6486\n",
            "675/1001, train_loss: 0.0315, step time: 0.6466\n",
            "676/1001, train_loss: 1.0000, step time: 0.6245\n",
            "677/1001, train_loss: 0.1672, step time: 0.6539\n",
            "678/1001, train_loss: 0.0434, step time: 0.6524\n",
            "679/1001, train_loss: 0.0702, step time: 0.6512\n",
            "680/1001, train_loss: 0.6250, step time: 0.6771\n",
            "681/1001, train_loss: 0.0464, step time: 0.6571\n",
            "682/1001, train_loss: 0.1607, step time: 0.6649\n",
            "683/1001, train_loss: 0.0703, step time: 0.6480\n",
            "684/1001, train_loss: 0.2196, step time: 0.6533\n",
            "685/1001, train_loss: 0.0802, step time: 0.6486\n",
            "686/1001, train_loss: 0.0454, step time: 0.6515\n",
            "687/1001, train_loss: 0.0905, step time: 0.6552\n",
            "688/1001, train_loss: 1.0000, step time: 0.6368\n",
            "689/1001, train_loss: 0.1232, step time: 0.6598\n",
            "690/1001, train_loss: 0.0936, step time: 0.6568\n",
            "691/1001, train_loss: 0.1258, step time: 0.6517\n",
            "692/1001, train_loss: 0.0526, step time: 0.6740\n",
            "693/1001, train_loss: 0.2436, step time: 0.6609\n",
            "694/1001, train_loss: 1.0000, step time: 0.6431\n",
            "695/1001, train_loss: 0.6850, step time: 0.6797\n",
            "696/1001, train_loss: 0.0535, step time: 0.6556\n",
            "697/1001, train_loss: 0.0681, step time: 0.6656\n",
            "698/1001, train_loss: 0.0530, step time: 0.6564\n",
            "699/1001, train_loss: 1.0000, step time: 0.6241\n",
            "700/1001, train_loss: 0.0685, step time: 0.6687\n",
            "701/1001, train_loss: 0.0413, step time: 0.6532\n",
            "702/1001, train_loss: 0.7021, step time: 0.6726\n",
            "703/1001, train_loss: 1.0000, step time: 0.6402\n",
            "704/1001, train_loss: 0.0438, step time: 0.6522\n",
            "705/1001, train_loss: 0.0694, step time: 0.6499\n",
            "706/1001, train_loss: 0.0688, step time: 0.6531\n",
            "707/1001, train_loss: 0.2242, step time: 0.6566\n",
            "708/1001, train_loss: 0.0831, step time: 0.6492\n",
            "709/1001, train_loss: 1.0000, step time: 0.6248\n",
            "710/1001, train_loss: 0.0648, step time: 0.6521\n",
            "711/1001, train_loss: 0.0772, step time: 0.6508\n",
            "712/1001, train_loss: 1.0000, step time: 0.6249\n",
            "713/1001, train_loss: 0.1053, step time: 0.6527\n",
            "714/1001, train_loss: 0.1746, step time: 0.6691\n",
            "715/1001, train_loss: 0.9417, step time: 0.6785\n",
            "716/1001, train_loss: 0.4880, step time: 0.6559\n",
            "717/1001, train_loss: 0.3861, step time: 0.6633\n",
            "718/1001, train_loss: 0.9199, step time: 0.6532\n",
            "719/1001, train_loss: 0.0567, step time: 0.6506\n",
            "720/1001, train_loss: 0.1323, step time: 0.6564\n",
            "721/1001, train_loss: 0.0436, step time: 0.6992\n",
            "722/1001, train_loss: 0.0846, step time: 0.6469\n",
            "723/1001, train_loss: 0.8703, step time: 0.6503\n",
            "724/1001, train_loss: 0.1525, step time: 0.6643\n",
            "725/1001, train_loss: 0.0666, step time: 0.6559\n",
            "726/1001, train_loss: 0.2946, step time: 0.6549\n",
            "727/1001, train_loss: 0.0370, step time: 0.6459\n",
            "728/1001, train_loss: 1.0000, step time: 0.6244\n",
            "729/1001, train_loss: 0.6961, step time: 0.6542\n",
            "730/1001, train_loss: 0.0796, step time: 0.6490\n",
            "731/1001, train_loss: 0.0337, step time: 0.6832\n",
            "732/1001, train_loss: 0.3998, step time: 0.6539\n",
            "733/1001, train_loss: 0.5090, step time: 0.6582\n",
            "734/1001, train_loss: 0.0978, step time: 0.6706\n",
            "735/1001, train_loss: 0.9987, step time: 0.6473\n",
            "736/1001, train_loss: 0.0464, step time: 0.6562\n",
            "737/1001, train_loss: 0.6037, step time: 0.6525\n",
            "738/1001, train_loss: 0.9715, step time: 0.6549\n",
            "739/1001, train_loss: 0.0869, step time: 0.6769\n",
            "740/1001, train_loss: 0.2386, step time: 0.6551\n",
            "741/1001, train_loss: 0.0235, step time: 0.6608\n",
            "742/1001, train_loss: 0.7542, step time: 0.6723\n",
            "743/1001, train_loss: 0.9999, step time: 0.6271\n",
            "744/1001, train_loss: 0.0597, step time: 0.6562\n",
            "745/1001, train_loss: 0.2024, step time: 0.6663\n",
            "746/1001, train_loss: 0.0544, step time: 0.6516\n",
            "747/1001, train_loss: 0.2068, step time: 0.6518\n",
            "748/1001, train_loss: 0.0406, step time: 0.6756\n",
            "749/1001, train_loss: 1.0000, step time: 0.6246\n",
            "750/1001, train_loss: 0.9464, step time: 0.6543\n",
            "751/1001, train_loss: 0.6206, step time: 0.6571\n",
            "752/1001, train_loss: 1.0000, step time: 0.6240\n",
            "753/1001, train_loss: 0.0399, step time: 0.6518\n",
            "754/1001, train_loss: 0.8560, step time: 0.6672\n",
            "755/1001, train_loss: 0.0331, step time: 0.6607\n",
            "756/1001, train_loss: 0.1109, step time: 0.6768\n",
            "757/1001, train_loss: 0.0653, step time: 0.6565\n",
            "758/1001, train_loss: 0.1276, step time: 0.6736\n",
            "759/1001, train_loss: 0.0575, step time: 0.6494\n",
            "760/1001, train_loss: 0.1744, step time: 0.6569\n",
            "761/1001, train_loss: 0.2579, step time: 0.6757\n",
            "762/1001, train_loss: 0.7187, step time: 0.6726\n",
            "763/1001, train_loss: 0.1417, step time: 0.6605\n",
            "764/1001, train_loss: 0.1119, step time: 0.6623\n",
            "765/1001, train_loss: 0.0537, step time: 0.6759\n",
            "766/1001, train_loss: 0.0870, step time: 0.6490\n",
            "767/1001, train_loss: 0.9618, step time: 0.6488\n",
            "768/1001, train_loss: 1.0000, step time: 0.6308\n",
            "769/1001, train_loss: 0.1022, step time: 0.6706\n",
            "770/1001, train_loss: 0.0509, step time: 0.6517\n",
            "771/1001, train_loss: 0.0663, step time: 0.6518\n",
            "772/1001, train_loss: 0.1292, step time: 0.6563\n",
            "773/1001, train_loss: 0.1421, step time: 0.6978\n",
            "774/1001, train_loss: 0.0935, step time: 0.7971\n",
            "775/1001, train_loss: 0.0518, step time: 0.6522\n",
            "776/1001, train_loss: 0.9838, step time: 0.6807\n",
            "777/1001, train_loss: 1.0000, step time: 0.6267\n",
            "778/1001, train_loss: 0.2012, step time: 0.6757\n",
            "779/1001, train_loss: 0.1006, step time: 0.6523\n",
            "780/1001, train_loss: 0.0351, step time: 0.6482\n",
            "781/1001, train_loss: 0.0808, step time: 0.6572\n",
            "782/1001, train_loss: 0.8532, step time: 0.6526\n",
            "783/1001, train_loss: 0.3433, step time: 0.6504\n",
            "784/1001, train_loss: 0.0724, step time: 0.6632\n",
            "785/1001, train_loss: 0.9875, step time: 0.6483\n",
            "786/1001, train_loss: 0.0463, step time: 0.6485\n",
            "787/1001, train_loss: 0.9401, step time: 0.6588\n",
            "788/1001, train_loss: 0.4331, step time: 0.6506\n",
            "789/1001, train_loss: 0.3755, step time: 0.6885\n",
            "790/1001, train_loss: 0.0416, step time: 0.6592\n",
            "791/1001, train_loss: 0.9678, step time: 0.6502\n",
            "792/1001, train_loss: 0.0823, step time: 0.6482\n",
            "793/1001, train_loss: 0.1222, step time: 0.6508\n",
            "794/1001, train_loss: 0.1440, step time: 0.6516\n",
            "795/1001, train_loss: 0.5702, step time: 0.6679\n",
            "796/1001, train_loss: 0.3122, step time: 0.6544\n",
            "797/1001, train_loss: 0.0370, step time: 0.6507\n",
            "798/1001, train_loss: 0.7151, step time: 0.6609\n",
            "799/1001, train_loss: 0.0768, step time: 0.6571\n",
            "800/1001, train_loss: 0.1159, step time: 0.6551\n",
            "801/1001, train_loss: 0.0495, step time: 0.6525\n",
            "802/1001, train_loss: 0.1385, step time: 0.6511\n",
            "803/1001, train_loss: 0.0424, step time: 0.6709\n",
            "804/1001, train_loss: 0.0689, step time: 0.6555\n",
            "805/1001, train_loss: 0.1659, step time: 0.6768\n",
            "806/1001, train_loss: 0.0340, step time: 0.6484\n",
            "807/1001, train_loss: 1.0000, step time: 0.6245\n",
            "808/1001, train_loss: 0.1149, step time: 0.6755\n",
            "809/1001, train_loss: 0.1242, step time: 0.6562\n",
            "810/1001, train_loss: 0.0757, step time: 0.6748\n",
            "811/1001, train_loss: 0.0618, step time: 0.6737\n",
            "812/1001, train_loss: 0.2157, step time: 0.6510\n",
            "813/1001, train_loss: 0.0535, step time: 0.6500\n",
            "814/1001, train_loss: 0.1151, step time: 0.6623\n",
            "815/1001, train_loss: 0.1584, step time: 0.6478\n",
            "816/1001, train_loss: 0.0478, step time: 0.6489\n",
            "817/1001, train_loss: 0.0837, step time: 0.6541\n",
            "818/1001, train_loss: 0.9996, step time: 0.6603\n",
            "819/1001, train_loss: 0.0638, step time: 0.6756\n",
            "820/1001, train_loss: 0.1054, step time: 0.6502\n",
            "821/1001, train_loss: 0.1345, step time: 0.6538\n",
            "822/1001, train_loss: 0.1982, step time: 0.6668\n",
            "823/1001, train_loss: 1.0000, step time: 0.6501\n",
            "824/1001, train_loss: 0.6614, step time: 0.6904\n",
            "825/1001, train_loss: 0.0751, step time: 0.6621\n",
            "826/1001, train_loss: 0.0413, step time: 0.6900\n",
            "827/1001, train_loss: 0.0821, step time: 0.6751\n",
            "828/1001, train_loss: 0.0402, step time: 0.6539\n",
            "829/1001, train_loss: 0.7046, step time: 0.6455\n",
            "830/1001, train_loss: 0.0723, step time: 0.6554\n",
            "831/1001, train_loss: 0.6942, step time: 0.6782\n",
            "832/1001, train_loss: 0.0490, step time: 0.6694\n",
            "833/1001, train_loss: 0.1055, step time: 0.6576\n",
            "834/1001, train_loss: 0.0559, step time: 0.6505\n",
            "835/1001, train_loss: 0.5902, step time: 0.6548\n",
            "836/1001, train_loss: 0.3169, step time: 0.6524\n",
            "837/1001, train_loss: 0.0263, step time: 0.6777\n",
            "838/1001, train_loss: 0.1070, step time: 0.6651\n",
            "839/1001, train_loss: 0.1644, step time: 0.6501\n",
            "840/1001, train_loss: 1.0000, step time: 0.6390\n",
            "841/1001, train_loss: 0.2337, step time: 0.6558\n",
            "842/1001, train_loss: 1.0000, step time: 0.6369\n",
            "843/1001, train_loss: 0.3380, step time: 0.6556\n",
            "844/1001, train_loss: 0.3972, step time: 0.6576\n",
            "845/1001, train_loss: 0.0338, step time: 0.6609\n",
            "846/1001, train_loss: 0.0459, step time: 0.6580\n",
            "847/1001, train_loss: 0.0615, step time: 0.6801\n",
            "848/1001, train_loss: 0.0587, step time: 0.6745\n",
            "849/1001, train_loss: 0.5575, step time: 0.6695\n",
            "850/1001, train_loss: 0.0339, step time: 0.6732\n",
            "851/1001, train_loss: 0.2550, step time: 0.6746\n",
            "852/1001, train_loss: 0.1212, step time: 0.6726\n",
            "853/1001, train_loss: 0.0751, step time: 0.6488\n",
            "854/1001, train_loss: 0.6923, step time: 0.6496\n",
            "855/1001, train_loss: 0.1107, step time: 0.6749\n",
            "856/1001, train_loss: 0.8145, step time: 0.6527\n",
            "857/1001, train_loss: 0.6889, step time: 0.6525\n",
            "858/1001, train_loss: 0.7786, step time: 0.6532\n",
            "859/1001, train_loss: 0.0542, step time: 0.6525\n",
            "860/1001, train_loss: 1.0000, step time: 0.6269\n",
            "861/1001, train_loss: 0.0882, step time: 0.6537\n",
            "862/1001, train_loss: 0.3890, step time: 0.6566\n",
            "863/1001, train_loss: 1.0000, step time: 0.6512\n",
            "864/1001, train_loss: 0.0850, step time: 0.6474\n",
            "865/1001, train_loss: 0.7373, step time: 0.6511\n",
            "866/1001, train_loss: 0.0574, step time: 0.6491\n",
            "867/1001, train_loss: 0.9935, step time: 0.6630\n",
            "868/1001, train_loss: 0.8431, step time: 0.6556\n",
            "869/1001, train_loss: 0.0752, step time: 0.6511\n",
            "870/1001, train_loss: 0.1192, step time: 0.6516\n",
            "871/1001, train_loss: 0.1170, step time: 0.6752\n",
            "872/1001, train_loss: 0.8603, step time: 0.6720\n",
            "873/1001, train_loss: 0.0352, step time: 0.6492\n",
            "874/1001, train_loss: 0.6841, step time: 0.6442\n",
            "875/1001, train_loss: 0.8827, step time: 0.6669\n",
            "876/1001, train_loss: 0.1713, step time: 0.6707\n",
            "877/1001, train_loss: 0.4826, step time: 0.6684\n",
            "878/1001, train_loss: 0.4100, step time: 0.6574\n",
            "879/1001, train_loss: 0.6806, step time: 0.6508\n",
            "880/1001, train_loss: 0.0672, step time: 0.6614\n",
            "881/1001, train_loss: 0.7576, step time: 0.6685\n",
            "882/1001, train_loss: 0.1543, step time: 0.6542\n",
            "883/1001, train_loss: 0.2498, step time: 0.6531\n",
            "884/1001, train_loss: 0.5164, step time: 0.6495\n",
            "885/1001, train_loss: 0.0254, step time: 0.6613\n",
            "886/1001, train_loss: 0.9957, step time: 0.6756\n",
            "887/1001, train_loss: 0.0685, step time: 0.6508\n",
            "888/1001, train_loss: 1.0000, step time: 0.6466\n",
            "889/1001, train_loss: 0.0733, step time: 0.6620\n",
            "890/1001, train_loss: 0.0628, step time: 0.6460\n",
            "891/1001, train_loss: 0.6777, step time: 0.6403\n",
            "892/1001, train_loss: 0.1313, step time: 0.6640\n",
            "893/1001, train_loss: 0.0310, step time: 0.6824\n",
            "894/1001, train_loss: 0.0469, step time: 0.6680\n",
            "895/1001, train_loss: 0.0691, step time: 0.6524\n",
            "896/1001, train_loss: 0.0464, step time: 0.6489\n",
            "897/1001, train_loss: 0.0437, step time: 0.6502\n",
            "898/1001, train_loss: 0.9973, step time: 0.6611\n",
            "899/1001, train_loss: 0.6929, step time: 0.6458\n",
            "900/1001, train_loss: 0.9966, step time: 0.6401\n",
            "901/1001, train_loss: 0.0571, step time: 0.6556\n",
            "902/1001, train_loss: 0.0837, step time: 0.6497\n",
            "903/1001, train_loss: 0.4124, step time: 0.6580\n",
            "904/1001, train_loss: 1.0000, step time: 0.6236\n",
            "905/1001, train_loss: 1.0000, step time: 0.6239\n",
            "906/1001, train_loss: 0.6938, step time: 0.6666\n",
            "907/1001, train_loss: 0.7619, step time: 0.6583\n",
            "908/1001, train_loss: 0.2516, step time: 0.6529\n",
            "909/1001, train_loss: 0.2735, step time: 0.6551\n",
            "910/1001, train_loss: 0.0421, step time: 0.6592\n",
            "911/1001, train_loss: 0.0691, step time: 0.6554\n",
            "912/1001, train_loss: 0.0654, step time: 0.6645\n",
            "913/1001, train_loss: 1.0000, step time: 0.6295\n",
            "914/1001, train_loss: 0.3705, step time: 0.6568\n",
            "915/1001, train_loss: 0.0856, step time: 0.6538\n",
            "916/1001, train_loss: 0.0621, step time: 0.6502\n",
            "917/1001, train_loss: 0.1510, step time: 0.6644\n",
            "918/1001, train_loss: 0.3312, step time: 0.6536\n",
            "919/1001, train_loss: 0.0524, step time: 0.6495\n",
            "920/1001, train_loss: 0.0655, step time: 0.6515\n",
            "921/1001, train_loss: 0.1960, step time: 0.6556\n",
            "922/1001, train_loss: 0.0345, step time: 0.6536\n",
            "923/1001, train_loss: 0.7216, step time: 0.6543\n",
            "924/1001, train_loss: 0.0612, step time: 0.6745\n",
            "925/1001, train_loss: 0.0888, step time: 0.6520\n",
            "926/1001, train_loss: 0.0483, step time: 0.6502\n",
            "927/1001, train_loss: 0.5441, step time: 0.6545\n",
            "928/1001, train_loss: 0.0493, step time: 0.6592\n",
            "929/1001, train_loss: 0.0444, step time: 0.6585\n",
            "930/1001, train_loss: 0.4912, step time: 0.6510\n",
            "931/1001, train_loss: 0.0347, step time: 0.6706\n",
            "932/1001, train_loss: 0.4846, step time: 0.6595\n",
            "933/1001, train_loss: 0.6965, step time: 0.6458\n",
            "934/1001, train_loss: 0.3848, step time: 0.6591\n",
            "935/1001, train_loss: 0.0582, step time: 0.6616\n",
            "936/1001, train_loss: 0.0961, step time: 0.6535\n",
            "937/1001, train_loss: 0.0243, step time: 0.6628\n",
            "938/1001, train_loss: 0.6827, step time: 0.6368\n",
            "939/1001, train_loss: 0.0382, step time: 0.6454\n",
            "940/1001, train_loss: 0.2065, step time: 0.6544\n",
            "941/1001, train_loss: 0.0450, step time: 0.6491\n",
            "942/1001, train_loss: 0.0842, step time: 0.6677\n",
            "943/1001, train_loss: 0.1320, step time: 0.6592\n",
            "944/1001, train_loss: 1.0000, step time: 0.6472\n",
            "945/1001, train_loss: 0.0989, step time: 0.6627\n",
            "946/1001, train_loss: 0.1022, step time: 0.6873\n",
            "947/1001, train_loss: 0.0418, step time: 0.6615\n",
            "948/1001, train_loss: 0.0623, step time: 0.6497\n",
            "949/1001, train_loss: 0.5270, step time: 0.6783\n",
            "950/1001, train_loss: 0.0652, step time: 0.6533\n",
            "951/1001, train_loss: 0.0758, step time: 0.6434\n",
            "952/1001, train_loss: 0.0296, step time: 0.6473\n",
            "953/1001, train_loss: 0.1093, step time: 0.6557\n",
            "954/1001, train_loss: 0.4599, step time: 0.6483\n",
            "955/1001, train_loss: 0.0576, step time: 0.6516\n",
            "956/1001, train_loss: 0.1516, step time: 0.6708\n",
            "957/1001, train_loss: 0.0323, step time: 0.6554\n",
            "958/1001, train_loss: 0.0457, step time: 0.6541\n",
            "959/1001, train_loss: 0.0657, step time: 0.6537\n",
            "960/1001, train_loss: 0.3324, step time: 0.6763\n",
            "961/1001, train_loss: 0.0759, step time: 0.6570\n",
            "962/1001, train_loss: 0.0387, step time: 0.6656\n",
            "963/1001, train_loss: 0.1873, step time: 0.6499\n",
            "964/1001, train_loss: 0.0708, step time: 0.6483\n",
            "965/1001, train_loss: 0.0824, step time: 0.7900\n",
            "966/1001, train_loss: 0.0469, step time: 0.6634\n",
            "967/1001, train_loss: 0.0893, step time: 0.6514\n",
            "968/1001, train_loss: 0.0940, step time: 0.6659\n",
            "969/1001, train_loss: 0.9768, step time: 0.6761\n",
            "970/1001, train_loss: 0.0886, step time: 0.6622\n",
            "971/1001, train_loss: 0.0763, step time: 0.6770\n",
            "972/1001, train_loss: 0.0479, step time: 0.6529\n",
            "973/1001, train_loss: 0.0861, step time: 0.6501\n",
            "974/1001, train_loss: 0.6608, step time: 0.6653\n",
            "975/1001, train_loss: 0.1421, step time: 0.6523\n",
            "976/1001, train_loss: 0.0682, step time: 0.6570\n",
            "977/1001, train_loss: 0.1858, step time: 0.6588\n",
            "978/1001, train_loss: 0.0580, step time: 0.6629\n",
            "979/1001, train_loss: 0.1670, step time: 0.6516\n",
            "980/1001, train_loss: 1.0000, step time: 0.6379\n",
            "981/1001, train_loss: 0.1389, step time: 0.6633\n",
            "982/1001, train_loss: 0.0895, step time: 0.6521\n",
            "983/1001, train_loss: 0.1083, step time: 0.6868\n",
            "984/1001, train_loss: 0.2387, step time: 0.6867\n",
            "985/1001, train_loss: 0.0966, step time: 0.6749\n",
            "986/1001, train_loss: 0.1177, step time: 0.6526\n",
            "987/1001, train_loss: 0.0442, step time: 0.6456\n",
            "988/1001, train_loss: 0.0431, step time: 0.6496\n",
            "989/1001, train_loss: 0.0328, step time: 0.6439\n",
            "990/1001, train_loss: 0.0541, step time: 0.6502\n",
            "991/1001, train_loss: 0.0762, step time: 0.6503\n",
            "992/1001, train_loss: 0.8219, step time: 0.6515\n",
            "993/1001, train_loss: 0.6941, step time: 0.6473\n",
            "994/1001, train_loss: 0.0437, step time: 0.6405\n",
            "995/1001, train_loss: 0.1212, step time: 0.6513\n",
            "996/1001, train_loss: 0.9773, step time: 0.6509\n",
            "997/1001, train_loss: 0.0534, step time: 0.6508\n",
            "998/1001, train_loss: 0.0469, step time: 0.6508\n",
            "999/1001, train_loss: 0.0435, step time: 0.6495\n",
            "1000/1001, train_loss: 0.1025, step time: 0.6503\n",
            "1001/1001, train_loss: 0.0387, step time: 0.6453\n",
            "epoch 16 average loss: 0.2939\n",
            "current epoch: 16 current mean dice: 0.8642 tc: 0.8592 wt: 0.8972 et: 0.8404\n",
            "best mean dice: 0.8665 at epoch: 14\n",
            "time consuming of epoch 16 is: 831.4130\n",
            "----------\n",
            "epoch 17/20\n",
            "1/1001, train_loss: 0.0598, step time: 0.7243\n",
            "2/1001, train_loss: 0.8563, step time: 0.7128\n",
            "3/1001, train_loss: 0.0413, step time: 0.7171\n",
            "4/1001, train_loss: 0.0430, step time: 0.6997\n",
            "5/1001, train_loss: 1.0000, step time: 0.7076\n",
            "6/1001, train_loss: 0.0317, step time: 0.6700\n",
            "7/1001, train_loss: 0.6777, step time: 0.6830\n",
            "8/1001, train_loss: 0.6803, step time: 0.7047\n",
            "9/1001, train_loss: 0.0455, step time: 0.6627\n",
            "10/1001, train_loss: 1.0000, step time: 0.6454\n",
            "11/1001, train_loss: 0.1555, step time: 0.6759\n",
            "12/1001, train_loss: 0.0808, step time: 0.6680\n",
            "13/1001, train_loss: 0.0356, step time: 0.7151\n",
            "14/1001, train_loss: 0.0565, step time: 0.6729\n",
            "15/1001, train_loss: 0.2238, step time: 0.6574\n",
            "16/1001, train_loss: 1.0000, step time: 0.6648\n",
            "17/1001, train_loss: 0.8656, step time: 0.6769\n",
            "18/1001, train_loss: 0.0769, step time: 0.6677\n",
            "19/1001, train_loss: 0.4241, step time: 0.6619\n",
            "20/1001, train_loss: 0.1264, step time: 0.6519\n",
            "21/1001, train_loss: 0.0283, step time: 0.6487\n",
            "22/1001, train_loss: 0.0680, step time: 0.6483\n",
            "23/1001, train_loss: 0.0352, step time: 0.6757\n",
            "24/1001, train_loss: 0.0388, step time: 0.6518\n",
            "25/1001, train_loss: 0.0495, step time: 0.6477\n",
            "26/1001, train_loss: 0.9996, step time: 0.6283\n",
            "27/1001, train_loss: 0.1213, step time: 0.6522\n",
            "28/1001, train_loss: 1.0000, step time: 0.6265\n",
            "29/1001, train_loss: 1.0000, step time: 0.6278\n",
            "30/1001, train_loss: 0.0342, step time: 0.6450\n",
            "31/1001, train_loss: 0.0434, step time: 0.6650\n",
            "32/1001, train_loss: 0.1538, step time: 0.6866\n",
            "33/1001, train_loss: 0.6765, step time: 0.6771\n",
            "34/1001, train_loss: 0.0504, step time: 0.6536\n",
            "35/1001, train_loss: 0.7213, step time: 0.6512\n",
            "36/1001, train_loss: 0.1790, step time: 0.6520\n",
            "37/1001, train_loss: 0.1001, step time: 0.6542\n",
            "38/1001, train_loss: 0.9757, step time: 0.6520\n",
            "39/1001, train_loss: 0.0930, step time: 0.6466\n",
            "40/1001, train_loss: 0.0655, step time: 0.6520\n",
            "41/1001, train_loss: 0.0612, step time: 0.6497\n",
            "42/1001, train_loss: 0.0339, step time: 0.6511\n",
            "43/1001, train_loss: 0.6605, step time: 0.6605\n",
            "44/1001, train_loss: 0.1169, step time: 0.6507\n",
            "45/1001, train_loss: 1.0000, step time: 0.6284\n",
            "46/1001, train_loss: 0.9960, step time: 0.6422\n",
            "47/1001, train_loss: 0.1047, step time: 0.6621\n",
            "48/1001, train_loss: 0.0443, step time: 0.6505\n",
            "49/1001, train_loss: 0.0359, step time: 0.6472\n",
            "50/1001, train_loss: 0.2704, step time: 0.6525\n",
            "51/1001, train_loss: 0.0733, step time: 0.6709\n",
            "52/1001, train_loss: 0.1031, step time: 0.6683\n",
            "53/1001, train_loss: 0.1246, step time: 0.6613\n",
            "54/1001, train_loss: 0.4038, step time: 0.6560\n",
            "55/1001, train_loss: 0.2746, step time: 0.6643\n",
            "56/1001, train_loss: 0.9687, step time: 0.6637\n",
            "57/1001, train_loss: 0.1608, step time: 0.6508\n",
            "58/1001, train_loss: 0.0777, step time: 0.6553\n",
            "59/1001, train_loss: 0.0384, step time: 0.6481\n",
            "60/1001, train_loss: 0.5499, step time: 0.6569\n",
            "61/1001, train_loss: 1.0000, step time: 0.6251\n",
            "62/1001, train_loss: 0.1179, step time: 0.6638\n",
            "63/1001, train_loss: 0.2068, step time: 0.6857\n",
            "64/1001, train_loss: 0.1228, step time: 0.6574\n",
            "65/1001, train_loss: 0.0626, step time: 0.6493\n",
            "66/1001, train_loss: 0.8625, step time: 0.6621\n",
            "67/1001, train_loss: 0.0450, step time: 0.6458\n",
            "68/1001, train_loss: 0.7267, step time: 0.6507\n",
            "69/1001, train_loss: 0.0558, step time: 0.6459\n",
            "70/1001, train_loss: 0.6388, step time: 0.6522\n",
            "71/1001, train_loss: 0.0410, step time: 0.6451\n",
            "72/1001, train_loss: 0.0653, step time: 0.6658\n",
            "73/1001, train_loss: 0.1663, step time: 0.6567\n",
            "74/1001, train_loss: 0.0689, step time: 0.6490\n",
            "75/1001, train_loss: 1.0000, step time: 0.6235\n",
            "76/1001, train_loss: 0.7170, step time: 0.6505\n",
            "77/1001, train_loss: 0.4708, step time: 0.6529\n",
            "78/1001, train_loss: 0.0300, step time: 0.6711\n",
            "79/1001, train_loss: 0.1891, step time: 0.6557\n",
            "80/1001, train_loss: 0.0636, step time: 0.6532\n",
            "81/1001, train_loss: 0.8644, step time: 0.6625\n",
            "82/1001, train_loss: 0.2310, step time: 0.6566\n",
            "83/1001, train_loss: 0.2014, step time: 0.6566\n",
            "84/1001, train_loss: 1.0000, step time: 0.6418\n",
            "85/1001, train_loss: 0.0507, step time: 0.6523\n",
            "86/1001, train_loss: 0.3524, step time: 0.6519\n",
            "87/1001, train_loss: 0.8011, step time: 0.6591\n",
            "88/1001, train_loss: 0.0863, step time: 0.6498\n",
            "89/1001, train_loss: 0.6221, step time: 0.6751\n",
            "90/1001, train_loss: 1.0000, step time: 0.6230\n",
            "91/1001, train_loss: 0.0383, step time: 0.6496\n",
            "92/1001, train_loss: 0.0452, step time: 0.6520\n",
            "93/1001, train_loss: 0.0577, step time: 0.6498\n",
            "94/1001, train_loss: 0.0848, step time: 0.6502\n",
            "95/1001, train_loss: 0.0451, step time: 0.6484\n",
            "96/1001, train_loss: 0.0377, step time: 0.6666\n",
            "97/1001, train_loss: 0.0871, step time: 0.6509\n",
            "98/1001, train_loss: 0.0741, step time: 0.6475\n",
            "99/1001, train_loss: 0.1053, step time: 0.6496\n",
            "100/1001, train_loss: 0.0572, step time: 0.6831\n",
            "101/1001, train_loss: 0.0493, step time: 0.6504\n",
            "102/1001, train_loss: 0.9289, step time: 0.6520\n",
            "103/1001, train_loss: 1.0000, step time: 0.6247\n",
            "104/1001, train_loss: 0.0593, step time: 0.6450\n",
            "105/1001, train_loss: 0.0528, step time: 0.6615\n",
            "106/1001, train_loss: 0.1140, step time: 0.6543\n",
            "107/1001, train_loss: 0.0308, step time: 0.6731\n",
            "108/1001, train_loss: 0.1521, step time: 0.6618\n",
            "109/1001, train_loss: 0.1666, step time: 0.6477\n",
            "110/1001, train_loss: 1.0000, step time: 0.6479\n",
            "111/1001, train_loss: 0.0667, step time: 0.6547\n",
            "112/1001, train_loss: 0.0668, step time: 0.6607\n",
            "113/1001, train_loss: 0.1170, step time: 0.6606\n",
            "114/1001, train_loss: 0.0518, step time: 0.6527\n",
            "115/1001, train_loss: 0.4450, step time: 0.6502\n",
            "116/1001, train_loss: 0.1128, step time: 0.6667\n",
            "117/1001, train_loss: 0.6618, step time: 0.6638\n",
            "118/1001, train_loss: 0.1244, step time: 0.6557\n",
            "119/1001, train_loss: 0.0281, step time: 0.6473\n",
            "120/1001, train_loss: 0.0480, step time: 0.6774\n",
            "121/1001, train_loss: 0.0872, step time: 0.6529\n",
            "122/1001, train_loss: 1.0000, step time: 0.6225\n",
            "123/1001, train_loss: 0.0569, step time: 0.6410\n",
            "124/1001, train_loss: 0.0554, step time: 0.6476\n",
            "125/1001, train_loss: 1.0000, step time: 0.6328\n",
            "126/1001, train_loss: 1.0000, step time: 0.6421\n",
            "127/1001, train_loss: 0.7069, step time: 0.6545\n",
            "128/1001, train_loss: 0.0513, step time: 0.6496\n",
            "129/1001, train_loss: 0.0930, step time: 0.6511\n",
            "130/1001, train_loss: 0.1017, step time: 0.6560\n",
            "131/1001, train_loss: 0.0564, step time: 0.6811\n",
            "132/1001, train_loss: 0.0531, step time: 0.6491\n",
            "133/1001, train_loss: 0.0437, step time: 0.6785\n",
            "134/1001, train_loss: 0.0852, step time: 0.6551\n",
            "135/1001, train_loss: 0.0324, step time: 0.6481\n",
            "136/1001, train_loss: 0.2370, step time: 0.6569\n",
            "137/1001, train_loss: 0.4468, step time: 0.6513\n",
            "138/1001, train_loss: 0.0608, step time: 0.6710\n",
            "139/1001, train_loss: 0.0792, step time: 0.6812\n",
            "140/1001, train_loss: 0.0487, step time: 0.6476\n",
            "141/1001, train_loss: 0.0467, step time: 0.6480\n",
            "142/1001, train_loss: 0.0364, step time: 0.6506\n",
            "143/1001, train_loss: 1.0000, step time: 0.6511\n",
            "144/1001, train_loss: 0.0428, step time: 0.6514\n",
            "145/1001, train_loss: 0.0477, step time: 0.6652\n",
            "146/1001, train_loss: 0.7289, step time: 0.6513\n",
            "147/1001, train_loss: 0.0704, step time: 0.6506\n",
            "148/1001, train_loss: 0.0751, step time: 0.6618\n",
            "149/1001, train_loss: 0.0380, step time: 0.6619\n",
            "150/1001, train_loss: 0.0608, step time: 0.6527\n",
            "151/1001, train_loss: 0.0857, step time: 0.6478\n",
            "152/1001, train_loss: 0.0680, step time: 0.6497\n",
            "153/1001, train_loss: 0.0445, step time: 0.6596\n",
            "154/1001, train_loss: 0.0834, step time: 0.6481\n",
            "155/1001, train_loss: 0.4035, step time: 0.6512\n",
            "156/1001, train_loss: 0.1533, step time: 0.6563\n",
            "157/1001, train_loss: 0.0735, step time: 0.6888\n",
            "158/1001, train_loss: 0.0846, step time: 0.6519\n",
            "159/1001, train_loss: 0.1821, step time: 0.6547\n",
            "160/1001, train_loss: 0.3452, step time: 0.6519\n",
            "161/1001, train_loss: 0.1380, step time: 0.6601\n",
            "162/1001, train_loss: 0.0788, step time: 0.6533\n",
            "163/1001, train_loss: 0.0373, step time: 0.6491\n",
            "164/1001, train_loss: 0.0436, step time: 0.6501\n",
            "165/1001, train_loss: 0.0505, step time: 0.6483\n",
            "166/1001, train_loss: 0.1062, step time: 0.6497\n",
            "167/1001, train_loss: 0.0807, step time: 0.6748\n",
            "168/1001, train_loss: 1.0000, step time: 0.6528\n",
            "169/1001, train_loss: 0.2024, step time: 0.6536\n",
            "170/1001, train_loss: 1.0000, step time: 0.6236\n",
            "171/1001, train_loss: 0.2474, step time: 0.6520\n",
            "172/1001, train_loss: 0.0380, step time: 0.6489\n",
            "173/1001, train_loss: 0.2737, step time: 0.6531\n",
            "174/1001, train_loss: 0.1238, step time: 0.6520\n",
            "175/1001, train_loss: 0.0453, step time: 0.6788\n",
            "176/1001, train_loss: 0.0528, step time: 0.6516\n",
            "177/1001, train_loss: 0.4981, step time: 0.6508\n",
            "178/1001, train_loss: 0.1433, step time: 0.6815\n",
            "179/1001, train_loss: 0.1476, step time: 0.6504\n",
            "180/1001, train_loss: 0.1509, step time: 0.6723\n",
            "181/1001, train_loss: 0.9999, step time: 0.6365\n",
            "182/1001, train_loss: 0.1096, step time: 0.6497\n",
            "183/1001, train_loss: 0.3604, step time: 0.6530\n",
            "184/1001, train_loss: 0.0601, step time: 0.6532\n",
            "185/1001, train_loss: 0.1245, step time: 0.6520\n",
            "186/1001, train_loss: 1.0000, step time: 0.6231\n",
            "187/1001, train_loss: 0.1262, step time: 0.6514\n",
            "188/1001, train_loss: 0.0905, step time: 0.6500\n",
            "189/1001, train_loss: 0.1909, step time: 0.6672\n",
            "190/1001, train_loss: 0.1341, step time: 0.6580\n",
            "191/1001, train_loss: 0.3060, step time: 0.6523\n",
            "192/1001, train_loss: 0.0880, step time: 0.6585\n",
            "193/1001, train_loss: 0.0313, step time: 0.6472\n",
            "194/1001, train_loss: 0.2911, step time: 0.6514\n",
            "195/1001, train_loss: 0.1202, step time: 0.6499\n",
            "196/1001, train_loss: 1.0000, step time: 0.6450\n",
            "197/1001, train_loss: 0.0836, step time: 0.6498\n",
            "198/1001, train_loss: 0.6851, step time: 0.6565\n",
            "199/1001, train_loss: 0.0309, step time: 0.6490\n",
            "200/1001, train_loss: 0.9006, step time: 0.6492\n",
            "201/1001, train_loss: 0.0501, step time: 0.6479\n",
            "202/1001, train_loss: 0.0330, step time: 0.6534\n",
            "203/1001, train_loss: 0.1034, step time: 0.6866\n",
            "204/1001, train_loss: 0.0456, step time: 0.6521\n",
            "205/1001, train_loss: 0.1557, step time: 0.6525\n",
            "206/1001, train_loss: 0.0333, step time: 0.6456\n",
            "207/1001, train_loss: 0.1161, step time: 0.6508\n",
            "208/1001, train_loss: 0.7527, step time: 0.6508\n",
            "209/1001, train_loss: 0.0485, step time: 0.6473\n",
            "210/1001, train_loss: 0.2211, step time: 0.6776\n",
            "211/1001, train_loss: 0.0846, step time: 0.6702\n",
            "212/1001, train_loss: 0.1037, step time: 0.6440\n",
            "213/1001, train_loss: 0.7297, step time: 0.6511\n",
            "214/1001, train_loss: 0.0711, step time: 0.6493\n",
            "215/1001, train_loss: 0.0476, step time: 0.6444\n",
            "216/1001, train_loss: 0.1149, step time: 0.6506\n",
            "217/1001, train_loss: 0.0331, step time: 0.6538\n",
            "218/1001, train_loss: 0.1113, step time: 0.6665\n",
            "219/1001, train_loss: 0.0382, step time: 0.6488\n",
            "220/1001, train_loss: 0.7977, step time: 0.6534\n",
            "221/1001, train_loss: 1.0000, step time: 0.6236\n",
            "222/1001, train_loss: 0.4411, step time: 0.6529\n",
            "223/1001, train_loss: 0.0539, step time: 0.6464\n",
            "224/1001, train_loss: 1.0000, step time: 0.6446\n",
            "225/1001, train_loss: 0.3118, step time: 0.6594\n",
            "226/1001, train_loss: 0.0754, step time: 0.6496\n",
            "227/1001, train_loss: 0.1122, step time: 0.6480\n",
            "228/1001, train_loss: 0.0492, step time: 0.6532\n",
            "229/1001, train_loss: 0.9366, step time: 0.6496\n",
            "230/1001, train_loss: 0.0843, step time: 0.6477\n",
            "231/1001, train_loss: 0.0780, step time: 0.6490\n",
            "232/1001, train_loss: 0.0841, step time: 0.6471\n",
            "233/1001, train_loss: 0.0665, step time: 0.6461\n",
            "234/1001, train_loss: 0.1172, step time: 0.6620\n",
            "235/1001, train_loss: 0.0575, step time: 0.6469\n",
            "236/1001, train_loss: 0.0597, step time: 0.6457\n",
            "237/1001, train_loss: 0.0724, step time: 0.6756\n",
            "238/1001, train_loss: 0.1448, step time: 0.6477\n",
            "239/1001, train_loss: 1.0000, step time: 0.6244\n",
            "240/1001, train_loss: 0.1185, step time: 0.6544\n",
            "241/1001, train_loss: 0.1787, step time: 0.6635\n",
            "242/1001, train_loss: 0.1062, step time: 0.6856\n",
            "243/1001, train_loss: 0.0453, step time: 0.6487\n",
            "244/1001, train_loss: 0.3561, step time: 0.6577\n",
            "245/1001, train_loss: 0.1491, step time: 0.6501\n",
            "246/1001, train_loss: 0.0529, step time: 0.6609\n",
            "247/1001, train_loss: 0.0800, step time: 0.6501\n",
            "248/1001, train_loss: 1.0000, step time: 0.6238\n",
            "249/1001, train_loss: 0.0568, step time: 0.6493\n",
            "250/1001, train_loss: 0.0713, step time: 0.6786\n",
            "251/1001, train_loss: 0.0525, step time: 0.6659\n",
            "252/1001, train_loss: 0.6877, step time: 0.6491\n",
            "253/1001, train_loss: 0.1058, step time: 0.6536\n",
            "254/1001, train_loss: 0.0395, step time: 0.6497\n",
            "255/1001, train_loss: 0.3721, step time: 0.6514\n",
            "256/1001, train_loss: 1.0000, step time: 0.6293\n",
            "257/1001, train_loss: 0.0499, step time: 0.6501\n",
            "258/1001, train_loss: 0.1573, step time: 0.6582\n",
            "259/1001, train_loss: 0.9994, step time: 0.6305\n",
            "260/1001, train_loss: 0.4568, step time: 0.6518\n",
            "261/1001, train_loss: 0.0676, step time: 0.6476\n",
            "262/1001, train_loss: 0.0555, step time: 0.6675\n",
            "263/1001, train_loss: 0.9996, step time: 0.6344\n",
            "264/1001, train_loss: 0.9899, step time: 0.6506\n",
            "265/1001, train_loss: 0.0486, step time: 0.6567\n",
            "266/1001, train_loss: 0.1906, step time: 0.6514\n",
            "267/1001, train_loss: 0.0231, step time: 0.6415\n",
            "268/1001, train_loss: 0.0575, step time: 0.6493\n",
            "269/1001, train_loss: 0.1052, step time: 0.6490\n",
            "270/1001, train_loss: 0.1845, step time: 0.6535\n",
            "271/1001, train_loss: 0.6915, step time: 0.6510\n",
            "272/1001, train_loss: 0.0391, step time: 0.6683\n",
            "273/1001, train_loss: 0.0510, step time: 0.6499\n",
            "274/1001, train_loss: 1.0000, step time: 0.6237\n",
            "275/1001, train_loss: 0.0682, step time: 0.6691\n",
            "276/1001, train_loss: 0.1115, step time: 0.6513\n",
            "277/1001, train_loss: 0.0632, step time: 0.6505\n",
            "278/1001, train_loss: 0.0373, step time: 0.6551\n",
            "279/1001, train_loss: 0.0828, step time: 0.6523\n",
            "280/1001, train_loss: 0.9971, step time: 0.6502\n",
            "281/1001, train_loss: 0.4940, step time: 0.6526\n",
            "282/1001, train_loss: 0.7201, step time: 0.6673\n",
            "283/1001, train_loss: 0.0899, step time: 0.6671\n",
            "284/1001, train_loss: 0.0885, step time: 0.6852\n",
            "285/1001, train_loss: 1.0000, step time: 0.6242\n",
            "286/1001, train_loss: 0.6998, step time: 0.6475\n",
            "287/1001, train_loss: 0.2191, step time: 0.6503\n",
            "288/1001, train_loss: 0.0488, step time: 0.6516\n",
            "289/1001, train_loss: 0.1878, step time: 0.6522\n",
            "290/1001, train_loss: 0.0662, step time: 0.6491\n",
            "291/1001, train_loss: 0.0397, step time: 0.6497\n",
            "292/1001, train_loss: 0.0540, step time: 0.6453\n",
            "293/1001, train_loss: 0.9814, step time: 0.6516\n",
            "294/1001, train_loss: 0.1655, step time: 0.6514\n",
            "295/1001, train_loss: 0.0465, step time: 0.6439\n",
            "296/1001, train_loss: 0.1854, step time: 0.6506\n",
            "297/1001, train_loss: 0.0914, step time: 0.6501\n",
            "298/1001, train_loss: 0.0749, step time: 0.6681\n",
            "299/1001, train_loss: 0.0244, step time: 0.6419\n",
            "300/1001, train_loss: 0.6847, step time: 0.6719\n",
            "301/1001, train_loss: 0.0405, step time: 0.6704\n",
            "302/1001, train_loss: 0.6946, step time: 0.6466\n",
            "303/1001, train_loss: 0.0673, step time: 0.6710\n",
            "304/1001, train_loss: 0.3497, step time: 0.6573\n",
            "305/1001, train_loss: 0.1162, step time: 0.6529\n",
            "306/1001, train_loss: 0.0434, step time: 0.6534\n",
            "307/1001, train_loss: 0.0877, step time: 0.6493\n",
            "308/1001, train_loss: 0.0571, step time: 0.6431\n",
            "309/1001, train_loss: 0.1127, step time: 0.6756\n",
            "310/1001, train_loss: 0.0470, step time: 0.6786\n",
            "311/1001, train_loss: 0.0693, step time: 0.6499\n",
            "312/1001, train_loss: 0.0692, step time: 0.6496\n",
            "313/1001, train_loss: 0.1106, step time: 0.6507\n",
            "314/1001, train_loss: 0.6837, step time: 0.6375\n",
            "315/1001, train_loss: 0.0894, step time: 0.6566\n",
            "316/1001, train_loss: 0.1873, step time: 0.6580\n",
            "317/1001, train_loss: 0.3389, step time: 0.6511\n",
            "318/1001, train_loss: 0.3785, step time: 0.6479\n",
            "319/1001, train_loss: 0.7304, step time: 0.6503\n",
            "320/1001, train_loss: 0.0314, step time: 0.6441\n",
            "321/1001, train_loss: 1.0000, step time: 0.6231\n",
            "322/1001, train_loss: 0.6763, step time: 0.6500\n",
            "323/1001, train_loss: 0.0718, step time: 0.6588\n",
            "324/1001, train_loss: 0.3877, step time: 0.6536\n",
            "325/1001, train_loss: 0.3882, step time: 0.6711\n",
            "326/1001, train_loss: 0.0354, step time: 0.6445\n",
            "327/1001, train_loss: 0.2386, step time: 0.6669\n",
            "328/1001, train_loss: 0.1292, step time: 0.6506\n",
            "329/1001, train_loss: 0.3449, step time: 0.6888\n",
            "330/1001, train_loss: 0.0539, step time: 0.6518\n",
            "331/1001, train_loss: 0.0905, step time: 0.6506\n",
            "332/1001, train_loss: 0.0432, step time: 0.6500\n",
            "333/1001, train_loss: 0.0408, step time: 0.7767\n",
            "334/1001, train_loss: 0.5190, step time: 0.6798\n",
            "335/1001, train_loss: 0.0421, step time: 0.6488\n",
            "336/1001, train_loss: 0.0714, step time: 0.6663\n",
            "337/1001, train_loss: 0.1853, step time: 0.6645\n",
            "338/1001, train_loss: 0.0826, step time: 0.6523\n",
            "339/1001, train_loss: 1.0000, step time: 0.6259\n",
            "340/1001, train_loss: 0.0667, step time: 0.6594\n",
            "341/1001, train_loss: 0.1339, step time: 0.6580\n",
            "342/1001, train_loss: 0.1287, step time: 0.6749\n",
            "343/1001, train_loss: 0.6989, step time: 0.6459\n",
            "344/1001, train_loss: 0.0487, step time: 0.6609\n",
            "345/1001, train_loss: 0.0621, step time: 0.6639\n",
            "346/1001, train_loss: 0.1698, step time: 0.6497\n",
            "347/1001, train_loss: 0.0285, step time: 0.6521\n",
            "348/1001, train_loss: 0.5055, step time: 0.6657\n",
            "349/1001, train_loss: 0.0760, step time: 0.6708\n",
            "350/1001, train_loss: 0.0280, step time: 0.6473\n",
            "351/1001, train_loss: 0.0484, step time: 0.6491\n",
            "352/1001, train_loss: 0.7421, step time: 0.6650\n",
            "353/1001, train_loss: 0.2342, step time: 0.6536\n",
            "354/1001, train_loss: 1.0000, step time: 0.6355\n",
            "355/1001, train_loss: 0.9898, step time: 0.6414\n",
            "356/1001, train_loss: 0.0749, step time: 0.6511\n",
            "357/1001, train_loss: 0.0405, step time: 0.6514\n",
            "358/1001, train_loss: 0.1078, step time: 0.6700\n",
            "359/1001, train_loss: 0.0444, step time: 0.6509\n",
            "360/1001, train_loss: 0.1392, step time: 0.6481\n",
            "361/1001, train_loss: 0.9526, step time: 0.7220\n",
            "362/1001, train_loss: 0.4542, step time: 0.6731\n",
            "363/1001, train_loss: 0.1092, step time: 0.6586\n",
            "364/1001, train_loss: 0.0596, step time: 0.6472\n",
            "365/1001, train_loss: 0.0647, step time: 0.6501\n",
            "366/1001, train_loss: 1.0000, step time: 0.6591\n",
            "367/1001, train_loss: 0.8764, step time: 0.6687\n",
            "368/1001, train_loss: 0.0405, step time: 0.6724\n",
            "369/1001, train_loss: 0.0443, step time: 0.6783\n",
            "370/1001, train_loss: 0.0649, step time: 0.6522\n",
            "371/1001, train_loss: 0.0442, step time: 0.6513\n",
            "372/1001, train_loss: 0.2856, step time: 0.6710\n",
            "373/1001, train_loss: 1.0000, step time: 0.6462\n",
            "374/1001, train_loss: 0.3348, step time: 0.6534\n",
            "375/1001, train_loss: 0.1078, step time: 0.6483\n",
            "376/1001, train_loss: 0.1293, step time: 0.6521\n",
            "377/1001, train_loss: 0.0701, step time: 0.6675\n",
            "378/1001, train_loss: 0.0967, step time: 0.6624\n",
            "379/1001, train_loss: 0.0576, step time: 0.6505\n",
            "380/1001, train_loss: 0.9997, step time: 0.6277\n",
            "381/1001, train_loss: 0.8279, step time: 0.6562\n",
            "382/1001, train_loss: 0.5169, step time: 0.6523\n",
            "383/1001, train_loss: 0.0502, step time: 0.6456\n",
            "384/1001, train_loss: 0.0540, step time: 0.6540\n",
            "385/1001, train_loss: 0.1627, step time: 0.6545\n",
            "386/1001, train_loss: 0.0698, step time: 0.6671\n",
            "387/1001, train_loss: 0.0359, step time: 0.6649\n",
            "388/1001, train_loss: 0.0807, step time: 0.6563\n",
            "389/1001, train_loss: 0.0507, step time: 0.6700\n",
            "390/1001, train_loss: 0.0646, step time: 0.6625\n",
            "391/1001, train_loss: 0.0739, step time: 0.6788\n",
            "392/1001, train_loss: 0.0402, step time: 0.6447\n",
            "393/1001, train_loss: 1.0000, step time: 0.6294\n",
            "394/1001, train_loss: 0.0677, step time: 0.6417\n",
            "395/1001, train_loss: 1.0000, step time: 0.6281\n",
            "396/1001, train_loss: 0.0978, step time: 0.6527\n",
            "397/1001, train_loss: 1.0000, step time: 0.6234\n",
            "398/1001, train_loss: 0.0614, step time: 0.6505\n",
            "399/1001, train_loss: 0.0504, step time: 0.6642\n",
            "400/1001, train_loss: 0.0572, step time: 0.6513\n",
            "401/1001, train_loss: 0.0522, step time: 0.6528\n",
            "402/1001, train_loss: 0.0660, step time: 0.6748\n",
            "403/1001, train_loss: 0.1350, step time: 0.6525\n",
            "404/1001, train_loss: 0.0400, step time: 0.6451\n",
            "405/1001, train_loss: 0.0494, step time: 0.6591\n",
            "406/1001, train_loss: 0.1535, step time: 0.6528\n",
            "407/1001, train_loss: 0.1924, step time: 0.6685\n",
            "408/1001, train_loss: 0.1423, step time: 0.6597\n",
            "409/1001, train_loss: 0.2093, step time: 0.6604\n",
            "410/1001, train_loss: 0.3991, step time: 0.6514\n",
            "411/1001, train_loss: 0.0586, step time: 0.6461\n",
            "412/1001, train_loss: 0.1021, step time: 0.6553\n",
            "413/1001, train_loss: 0.0905, step time: 0.6641\n",
            "414/1001, train_loss: 0.9976, step time: 0.6410\n",
            "415/1001, train_loss: 0.0450, step time: 0.6481\n",
            "416/1001, train_loss: 0.9992, step time: 0.6356\n",
            "417/1001, train_loss: 0.3574, step time: 0.6547\n",
            "418/1001, train_loss: 0.1048, step time: 0.6489\n",
            "419/1001, train_loss: 0.0377, step time: 0.6649\n",
            "420/1001, train_loss: 0.7332, step time: 0.6761\n",
            "421/1001, train_loss: 0.1245, step time: 0.6578\n",
            "422/1001, train_loss: 1.0000, step time: 0.6264\n",
            "423/1001, train_loss: 0.1735, step time: 0.6677\n",
            "424/1001, train_loss: 0.0983, step time: 0.6733\n",
            "425/1001, train_loss: 0.7282, step time: 0.6498\n",
            "426/1001, train_loss: 0.0609, step time: 0.6546\n",
            "427/1001, train_loss: 0.9992, step time: 0.6722\n",
            "428/1001, train_loss: 0.0963, step time: 0.6706\n",
            "429/1001, train_loss: 0.0474, step time: 0.6552\n",
            "430/1001, train_loss: 0.0579, step time: 0.6759\n",
            "431/1001, train_loss: 0.1493, step time: 0.6562\n",
            "432/1001, train_loss: 0.0408, step time: 0.6735\n",
            "433/1001, train_loss: 0.0507, step time: 0.6553\n",
            "434/1001, train_loss: 0.2218, step time: 0.6516\n",
            "435/1001, train_loss: 0.0387, step time: 0.6501\n",
            "436/1001, train_loss: 0.4786, step time: 0.6790\n",
            "437/1001, train_loss: 0.4946, step time: 0.6522\n",
            "438/1001, train_loss: 0.0794, step time: 0.6505\n",
            "439/1001, train_loss: 0.0635, step time: 0.6489\n",
            "440/1001, train_loss: 0.0632, step time: 0.6517\n",
            "441/1001, train_loss: 0.1603, step time: 0.6509\n",
            "442/1001, train_loss: 0.1118, step time: 0.6500\n",
            "443/1001, train_loss: 0.2304, step time: 0.6733\n",
            "444/1001, train_loss: 0.0397, step time: 0.6703\n",
            "445/1001, train_loss: 0.7135, step time: 0.6501\n",
            "446/1001, train_loss: 0.6755, step time: 0.6399\n",
            "447/1001, train_loss: 0.4865, step time: 0.6489\n",
            "448/1001, train_loss: 0.1748, step time: 0.6561\n",
            "449/1001, train_loss: 0.0532, step time: 0.6785\n",
            "450/1001, train_loss: 0.0391, step time: 0.6499\n",
            "451/1001, train_loss: 0.2068, step time: 0.6512\n",
            "452/1001, train_loss: 0.1031, step time: 0.6525\n",
            "453/1001, train_loss: 0.0729, step time: 0.6650\n",
            "454/1001, train_loss: 0.2084, step time: 0.6519\n",
            "455/1001, train_loss: 1.0000, step time: 0.6239\n",
            "456/1001, train_loss: 0.6943, step time: 0.6532\n",
            "457/1001, train_loss: 0.8054, step time: 0.6523\n",
            "458/1001, train_loss: 1.0000, step time: 0.6236\n",
            "459/1001, train_loss: 0.0330, step time: 0.6646\n",
            "460/1001, train_loss: 0.1738, step time: 0.6524\n",
            "461/1001, train_loss: 0.7016, step time: 0.6503\n",
            "462/1001, train_loss: 0.0641, step time: 0.6476\n",
            "463/1001, train_loss: 0.8523, step time: 0.6678\n",
            "464/1001, train_loss: 0.1067, step time: 0.6571\n",
            "465/1001, train_loss: 0.0485, step time: 0.6933\n",
            "466/1001, train_loss: 0.6806, step time: 0.6474\n",
            "467/1001, train_loss: 0.6935, step time: 0.6465\n",
            "468/1001, train_loss: 0.0454, step time: 0.6524\n",
            "469/1001, train_loss: 0.3807, step time: 0.6698\n",
            "470/1001, train_loss: 0.3960, step time: 0.6576\n",
            "471/1001, train_loss: 0.5968, step time: 0.6790\n",
            "472/1001, train_loss: 0.0511, step time: 0.6518\n",
            "473/1001, train_loss: 0.0562, step time: 0.6534\n",
            "474/1001, train_loss: 0.2685, step time: 0.6761\n",
            "475/1001, train_loss: 1.0000, step time: 0.6341\n",
            "476/1001, train_loss: 0.0635, step time: 0.6488\n",
            "477/1001, train_loss: 0.0479, step time: 0.6480\n",
            "478/1001, train_loss: 0.0348, step time: 0.6492\n",
            "479/1001, train_loss: 0.0432, step time: 0.6485\n",
            "480/1001, train_loss: 0.1420, step time: 0.6510\n",
            "481/1001, train_loss: 0.6782, step time: 0.6400\n",
            "482/1001, train_loss: 0.2287, step time: 0.6641\n",
            "483/1001, train_loss: 0.8502, step time: 0.6556\n",
            "484/1001, train_loss: 0.0425, step time: 0.6508\n",
            "485/1001, train_loss: 0.0323, step time: 0.6634\n",
            "486/1001, train_loss: 0.9091, step time: 0.6520\n",
            "487/1001, train_loss: 0.0559, step time: 0.6703\n",
            "488/1001, train_loss: 0.0314, step time: 0.6480\n",
            "489/1001, train_loss: 1.0000, step time: 0.6228\n",
            "490/1001, train_loss: 0.7370, step time: 0.6535\n",
            "491/1001, train_loss: 0.1776, step time: 0.6503\n",
            "492/1001, train_loss: 0.1093, step time: 0.6524\n",
            "493/1001, train_loss: 0.0511, step time: 0.6677\n",
            "494/1001, train_loss: 0.0451, step time: 0.6511\n",
            "495/1001, train_loss: 0.0366, step time: 0.6636\n",
            "496/1001, train_loss: 0.0417, step time: 0.6482\n",
            "497/1001, train_loss: 0.0971, step time: 0.6492\n",
            "498/1001, train_loss: 0.0552, step time: 0.6471\n",
            "499/1001, train_loss: 0.0843, step time: 0.6708\n",
            "500/1001, train_loss: 0.0579, step time: 0.6516\n",
            "501/1001, train_loss: 0.0710, step time: 0.6809\n",
            "502/1001, train_loss: 0.0525, step time: 0.6443\n",
            "503/1001, train_loss: 0.0555, step time: 0.6520\n",
            "504/1001, train_loss: 0.1613, step time: 0.6569\n",
            "505/1001, train_loss: 0.1029, step time: 0.6570\n",
            "506/1001, train_loss: 0.0596, step time: 0.6512\n",
            "507/1001, train_loss: 1.0000, step time: 0.6304\n",
            "508/1001, train_loss: 0.0473, step time: 0.6921\n",
            "509/1001, train_loss: 0.7684, step time: 0.6906\n",
            "510/1001, train_loss: 0.0913, step time: 0.6933\n",
            "511/1001, train_loss: 0.1158, step time: 0.6654\n",
            "512/1001, train_loss: 0.7263, step time: 0.6570\n",
            "513/1001, train_loss: 0.7305, step time: 0.6530\n",
            "514/1001, train_loss: 0.0594, step time: 0.6641\n",
            "515/1001, train_loss: 0.2825, step time: 0.6515\n",
            "516/1001, train_loss: 0.0928, step time: 0.6592\n",
            "517/1001, train_loss: 0.0623, step time: 0.6586\n",
            "518/1001, train_loss: 0.0686, step time: 0.6509\n",
            "519/1001, train_loss: 0.1123, step time: 0.6517\n",
            "520/1001, train_loss: 0.2429, step time: 0.6686\n",
            "521/1001, train_loss: 0.4063, step time: 0.6594\n",
            "522/1001, train_loss: 0.0751, step time: 0.6777\n",
            "523/1001, train_loss: 0.0879, step time: 0.6494\n",
            "524/1001, train_loss: 0.8475, step time: 0.6499\n",
            "525/1001, train_loss: 0.0892, step time: 0.6813\n",
            "526/1001, train_loss: 0.3223, step time: 0.6556\n",
            "527/1001, train_loss: 1.0000, step time: 0.6242\n",
            "528/1001, train_loss: 0.1206, step time: 0.6572\n",
            "529/1001, train_loss: 0.0289, step time: 0.6499\n",
            "530/1001, train_loss: 0.7102, step time: 0.6598\n",
            "531/1001, train_loss: 0.1016, step time: 0.6526\n",
            "532/1001, train_loss: 0.2639, step time: 0.6504\n",
            "533/1001, train_loss: 1.0000, step time: 0.6290\n",
            "534/1001, train_loss: 0.2277, step time: 0.6557\n",
            "535/1001, train_loss: 0.0413, step time: 0.6738\n",
            "536/1001, train_loss: 0.0404, step time: 0.7210\n",
            "537/1001, train_loss: 0.0363, step time: 0.6719\n",
            "538/1001, train_loss: 0.2808, step time: 0.6798\n",
            "539/1001, train_loss: 0.1957, step time: 0.6490\n",
            "540/1001, train_loss: 0.1012, step time: 0.6736\n",
            "541/1001, train_loss: 0.1105, step time: 0.6506\n",
            "542/1001, train_loss: 0.0370, step time: 0.6594\n",
            "543/1001, train_loss: 0.0764, step time: 0.6706\n",
            "544/1001, train_loss: 0.2252, step time: 0.6904\n",
            "545/1001, train_loss: 0.0380, step time: 0.6525\n",
            "546/1001, train_loss: 0.0319, step time: 0.6522\n",
            "547/1001, train_loss: 0.1281, step time: 0.6574\n",
            "548/1001, train_loss: 1.0000, step time: 0.6284\n",
            "549/1001, train_loss: 0.3688, step time: 0.6616\n",
            "550/1001, train_loss: 0.0980, step time: 0.6508\n",
            "551/1001, train_loss: 0.1726, step time: 0.6518\n",
            "552/1001, train_loss: 0.1838, step time: 0.6538\n",
            "553/1001, train_loss: 0.0652, step time: 0.6642\n",
            "554/1001, train_loss: 0.0365, step time: 0.6694\n",
            "555/1001, train_loss: 0.0691, step time: 0.6690\n",
            "556/1001, train_loss: 0.8197, step time: 0.6813\n",
            "557/1001, train_loss: 0.0369, step time: 0.6522\n",
            "558/1001, train_loss: 0.0345, step time: 0.6447\n",
            "559/1001, train_loss: 0.5497, step time: 0.6515\n",
            "560/1001, train_loss: 0.0423, step time: 0.6721\n",
            "561/1001, train_loss: 0.0335, step time: 0.6541\n",
            "562/1001, train_loss: 0.5749, step time: 0.6849\n",
            "563/1001, train_loss: 1.0000, step time: 0.6253\n",
            "564/1001, train_loss: 0.7210, step time: 0.6506\n",
            "565/1001, train_loss: 0.0317, step time: 0.6511\n",
            "566/1001, train_loss: 0.0835, step time: 0.6518\n",
            "567/1001, train_loss: 0.0541, step time: 0.6634\n",
            "568/1001, train_loss: 0.1846, step time: 0.6600\n",
            "569/1001, train_loss: 0.8620, step time: 0.6525\n",
            "570/1001, train_loss: 0.5801, step time: 0.6933\n",
            "571/1001, train_loss: 1.0000, step time: 0.6239\n",
            "572/1001, train_loss: 0.9944, step time: 0.6646\n",
            "573/1001, train_loss: 0.0326, step time: 0.6458\n",
            "574/1001, train_loss: 0.0465, step time: 0.6477\n",
            "575/1001, train_loss: 0.0460, step time: 0.6480\n",
            "576/1001, train_loss: 0.1621, step time: 0.6518\n",
            "577/1001, train_loss: 0.0604, step time: 0.6719\n",
            "578/1001, train_loss: 0.6776, step time: 0.6645\n",
            "579/1001, train_loss: 0.2405, step time: 0.6790\n",
            "580/1001, train_loss: 0.0728, step time: 0.6730\n",
            "581/1001, train_loss: 0.8766, step time: 0.6532\n",
            "582/1001, train_loss: 0.0628, step time: 0.6673\n",
            "583/1001, train_loss: 0.7262, step time: 0.6528\n",
            "584/1001, train_loss: 0.0531, step time: 0.6735\n",
            "585/1001, train_loss: 0.0818, step time: 0.6534\n",
            "586/1001, train_loss: 0.1149, step time: 0.6502\n",
            "587/1001, train_loss: 0.0254, step time: 0.6506\n",
            "588/1001, train_loss: 0.0524, step time: 0.6703\n",
            "589/1001, train_loss: 0.3930, step time: 0.6848\n",
            "590/1001, train_loss: 0.0499, step time: 0.6512\n",
            "591/1001, train_loss: 0.0654, step time: 0.6544\n",
            "592/1001, train_loss: 0.0374, step time: 0.6504\n",
            "593/1001, train_loss: 0.1789, step time: 0.6870\n",
            "594/1001, train_loss: 0.0680, step time: 0.6495\n",
            "595/1001, train_loss: 0.0733, step time: 0.6493\n",
            "596/1001, train_loss: 0.4743, step time: 0.6513\n",
            "597/1001, train_loss: 0.1903, step time: 0.6782\n",
            "598/1001, train_loss: 0.1581, step time: 0.6661\n",
            "599/1001, train_loss: 0.0315, step time: 0.6584\n",
            "600/1001, train_loss: 0.0812, step time: 0.6581\n",
            "601/1001, train_loss: 1.0000, step time: 0.6804\n",
            "602/1001, train_loss: 0.0526, step time: 0.6486\n",
            "603/1001, train_loss: 0.2196, step time: 0.6895\n",
            "604/1001, train_loss: 0.0339, step time: 0.6525\n",
            "605/1001, train_loss: 0.9736, step time: 0.6550\n",
            "606/1001, train_loss: 0.5375, step time: 0.6538\n",
            "607/1001, train_loss: 0.0273, step time: 0.6607\n",
            "608/1001, train_loss: 1.0000, step time: 0.6261\n",
            "609/1001, train_loss: 0.0392, step time: 0.6440\n",
            "610/1001, train_loss: 0.0901, step time: 0.6814\n",
            "611/1001, train_loss: 0.0357, step time: 0.6536\n",
            "612/1001, train_loss: 0.1360, step time: 0.6511\n",
            "613/1001, train_loss: 0.1795, step time: 0.6493\n",
            "614/1001, train_loss: 0.1037, step time: 0.6779\n",
            "615/1001, train_loss: 0.7671, step time: 0.6547\n",
            "616/1001, train_loss: 0.6856, step time: 0.6498\n",
            "617/1001, train_loss: 0.0434, step time: 0.6487\n",
            "618/1001, train_loss: 0.0649, step time: 0.6483\n",
            "619/1001, train_loss: 0.0809, step time: 0.6692\n",
            "620/1001, train_loss: 0.0984, step time: 0.6535\n",
            "621/1001, train_loss: 0.0316, step time: 0.6477\n",
            "622/1001, train_loss: 0.6944, step time: 0.6498\n",
            "623/1001, train_loss: 0.1835, step time: 0.6611\n",
            "624/1001, train_loss: 0.0724, step time: 0.6486\n",
            "625/1001, train_loss: 0.0529, step time: 0.6509\n",
            "626/1001, train_loss: 0.0597, step time: 0.6495\n",
            "627/1001, train_loss: 0.7274, step time: 0.6506\n",
            "628/1001, train_loss: 0.5122, step time: 0.6580\n",
            "629/1001, train_loss: 0.1074, step time: 0.6512\n",
            "630/1001, train_loss: 0.1702, step time: 0.6504\n",
            "631/1001, train_loss: 0.0612, step time: 0.6602\n",
            "632/1001, train_loss: 0.1864, step time: 0.6645\n",
            "633/1001, train_loss: 0.6811, step time: 0.6578\n",
            "634/1001, train_loss: 0.0790, step time: 0.6552\n",
            "635/1001, train_loss: 0.0722, step time: 0.6601\n",
            "636/1001, train_loss: 0.2747, step time: 0.6824\n",
            "637/1001, train_loss: 0.0294, step time: 0.6553\n",
            "638/1001, train_loss: 0.6853, step time: 0.6572\n",
            "639/1001, train_loss: 0.8838, step time: 0.6537\n",
            "640/1001, train_loss: 0.0582, step time: 0.6474\n",
            "641/1001, train_loss: 0.0262, step time: 0.6502\n",
            "642/1001, train_loss: 0.9778, step time: 0.6590\n",
            "643/1001, train_loss: 1.0000, step time: 0.6263\n",
            "644/1001, train_loss: 0.0412, step time: 0.6483\n",
            "645/1001, train_loss: 0.0303, step time: 0.6590\n",
            "646/1001, train_loss: 0.7001, step time: 0.6541\n",
            "647/1001, train_loss: 0.3353, step time: 0.6555\n",
            "648/1001, train_loss: 0.0413, step time: 0.6472\n",
            "649/1001, train_loss: 1.0000, step time: 0.6370\n",
            "650/1001, train_loss: 0.1060, step time: 0.6863\n",
            "651/1001, train_loss: 1.0000, step time: 0.6261\n",
            "652/1001, train_loss: 0.0784, step time: 0.6465\n",
            "653/1001, train_loss: 0.7415, step time: 0.6568\n",
            "654/1001, train_loss: 0.6967, step time: 0.6489\n",
            "655/1001, train_loss: 0.0563, step time: 0.6618\n",
            "656/1001, train_loss: 1.0000, step time: 0.6388\n",
            "657/1001, train_loss: 0.0385, step time: 0.6583\n",
            "658/1001, train_loss: 0.0285, step time: 0.6669\n",
            "659/1001, train_loss: 1.0000, step time: 0.6339\n",
            "660/1001, train_loss: 0.9995, step time: 0.6428\n",
            "661/1001, train_loss: 0.0894, step time: 0.6527\n",
            "662/1001, train_loss: 0.1212, step time: 0.6734\n",
            "663/1001, train_loss: 0.0848, step time: 0.6528\n",
            "664/1001, train_loss: 0.9905, step time: 0.6504\n",
            "665/1001, train_loss: 0.0609, step time: 0.6522\n",
            "666/1001, train_loss: 0.0355, step time: 0.6508\n",
            "667/1001, train_loss: 0.1345, step time: 0.6526\n",
            "668/1001, train_loss: 0.6407, step time: 0.6555\n",
            "669/1001, train_loss: 0.0532, step time: 0.6793\n",
            "670/1001, train_loss: 0.0391, step time: 0.6501\n",
            "671/1001, train_loss: 0.1668, step time: 0.6528\n",
            "672/1001, train_loss: 0.0428, step time: 0.6499\n",
            "673/1001, train_loss: 0.0930, step time: 0.6735\n",
            "674/1001, train_loss: 0.1084, step time: 0.6754\n",
            "675/1001, train_loss: 0.1376, step time: 0.6646\n",
            "676/1001, train_loss: 0.2270, step time: 0.6712\n",
            "677/1001, train_loss: 0.0962, step time: 0.6597\n",
            "678/1001, train_loss: 0.1175, step time: 0.6519\n",
            "679/1001, train_loss: 0.1126, step time: 0.6503\n",
            "680/1001, train_loss: 0.8735, step time: 0.6511\n",
            "681/1001, train_loss: 0.0229, step time: 0.6448\n",
            "682/1001, train_loss: 0.6569, step time: 0.6845\n",
            "683/1001, train_loss: 0.0531, step time: 0.6709\n",
            "684/1001, train_loss: 0.0316, step time: 0.6464\n",
            "685/1001, train_loss: 0.0865, step time: 0.6524\n",
            "686/1001, train_loss: 0.0520, step time: 0.6487\n",
            "687/1001, train_loss: 0.1108, step time: 0.6610\n",
            "688/1001, train_loss: 0.0543, step time: 0.6661\n",
            "689/1001, train_loss: 1.0000, step time: 0.6234\n",
            "690/1001, train_loss: 0.0678, step time: 0.6537\n",
            "691/1001, train_loss: 0.0908, step time: 0.6557\n",
            "692/1001, train_loss: 0.9037, step time: 0.6722\n",
            "693/1001, train_loss: 0.1340, step time: 0.6665\n",
            "694/1001, train_loss: 1.0000, step time: 0.6291\n",
            "695/1001, train_loss: 0.0301, step time: 0.6483\n",
            "696/1001, train_loss: 0.0621, step time: 0.6694\n",
            "697/1001, train_loss: 0.1928, step time: 0.6612\n",
            "698/1001, train_loss: 0.0321, step time: 0.6516\n",
            "699/1001, train_loss: 0.3044, step time: 0.6597\n",
            "700/1001, train_loss: 0.0604, step time: 0.6683\n",
            "701/1001, train_loss: 0.2191, step time: 0.6632\n",
            "702/1001, train_loss: 1.0000, step time: 0.6246\n",
            "703/1001, train_loss: 0.9949, step time: 0.6471\n",
            "704/1001, train_loss: 0.0876, step time: 0.6732\n",
            "705/1001, train_loss: 0.1566, step time: 0.6565\n",
            "706/1001, train_loss: 1.0000, step time: 0.6473\n",
            "707/1001, train_loss: 0.0572, step time: 0.6556\n",
            "708/1001, train_loss: 0.4624, step time: 0.6592\n",
            "709/1001, train_loss: 0.0427, step time: 0.6781\n",
            "710/1001, train_loss: 0.0895, step time: 0.6742\n",
            "711/1001, train_loss: 0.0982, step time: 0.6645\n",
            "712/1001, train_loss: 0.8546, step time: 0.6575\n",
            "713/1001, train_loss: 0.6849, step time: 0.6517\n",
            "714/1001, train_loss: 0.0935, step time: 0.6568\n",
            "715/1001, train_loss: 0.6910, step time: 0.6416\n",
            "716/1001, train_loss: 1.0000, step time: 0.6237\n",
            "717/1001, train_loss: 0.0835, step time: 0.6548\n",
            "718/1001, train_loss: 0.1194, step time: 0.6527\n",
            "719/1001, train_loss: 0.8633, step time: 0.6571\n",
            "720/1001, train_loss: 0.2286, step time: 0.6529\n",
            "721/1001, train_loss: 0.1374, step time: 0.6552\n",
            "722/1001, train_loss: 0.1934, step time: 0.6623\n",
            "723/1001, train_loss: 0.0846, step time: 0.6486\n",
            "724/1001, train_loss: 0.0396, step time: 0.6476\n",
            "725/1001, train_loss: 0.1383, step time: 0.6520\n",
            "726/1001, train_loss: 0.0406, step time: 0.6478\n",
            "727/1001, train_loss: 0.0338, step time: 0.6504\n",
            "728/1001, train_loss: 0.1445, step time: 0.7324\n",
            "729/1001, train_loss: 0.7816, step time: 0.6591\n",
            "730/1001, train_loss: 0.0900, step time: 0.6514\n",
            "731/1001, train_loss: 0.0978, step time: 0.6502\n",
            "732/1001, train_loss: 0.5788, step time: 0.6547\n",
            "733/1001, train_loss: 0.0406, step time: 0.6508\n",
            "734/1001, train_loss: 0.0984, step time: 0.6659\n",
            "735/1001, train_loss: 0.0489, step time: 0.6771\n",
            "736/1001, train_loss: 0.1115, step time: 0.6735\n",
            "737/1001, train_loss: 0.3946, step time: 0.6518\n",
            "738/1001, train_loss: 0.0410, step time: 0.6500\n",
            "739/1001, train_loss: 1.0000, step time: 0.6248\n",
            "740/1001, train_loss: 0.7019, step time: 0.6434\n",
            "741/1001, train_loss: 0.8125, step time: 0.6832\n",
            "742/1001, train_loss: 0.0569, step time: 0.6573\n",
            "743/1001, train_loss: 0.0661, step time: 0.6506\n",
            "744/1001, train_loss: 0.3214, step time: 0.6517\n",
            "745/1001, train_loss: 0.0819, step time: 0.6536\n",
            "746/1001, train_loss: 0.0429, step time: 0.6567\n",
            "747/1001, train_loss: 0.0377, step time: 0.6457\n",
            "748/1001, train_loss: 0.0391, step time: 0.6479\n",
            "749/1001, train_loss: 0.0744, step time: 0.6624\n",
            "750/1001, train_loss: 0.1038, step time: 0.6828\n",
            "751/1001, train_loss: 0.7328, step time: 0.6677\n",
            "752/1001, train_loss: 0.7040, step time: 0.6531\n",
            "753/1001, train_loss: 0.0306, step time: 0.6464\n",
            "754/1001, train_loss: 0.0952, step time: 0.6518\n",
            "755/1001, train_loss: 1.0000, step time: 0.6298\n",
            "756/1001, train_loss: 0.6622, step time: 0.6528\n",
            "757/1001, train_loss: 0.7264, step time: 0.6504\n",
            "758/1001, train_loss: 0.0901, step time: 0.6575\n",
            "759/1001, train_loss: 0.0380, step time: 0.6495\n",
            "760/1001, train_loss: 0.2220, step time: 0.6565\n",
            "761/1001, train_loss: 0.0917, step time: 0.6786\n",
            "762/1001, train_loss: 0.0554, step time: 0.6538\n",
            "763/1001, train_loss: 0.0521, step time: 0.6607\n",
            "764/1001, train_loss: 0.1528, step time: 0.6730\n",
            "765/1001, train_loss: 0.0465, step time: 0.6588\n",
            "766/1001, train_loss: 0.1927, step time: 0.6550\n",
            "767/1001, train_loss: 0.0485, step time: 0.6490\n",
            "768/1001, train_loss: 0.0917, step time: 0.6489\n",
            "769/1001, train_loss: 0.1663, step time: 0.6551\n",
            "770/1001, train_loss: 0.7754, step time: 0.6657\n",
            "771/1001, train_loss: 0.2066, step time: 0.6575\n",
            "772/1001, train_loss: 0.2346, step time: 0.6681\n",
            "773/1001, train_loss: 0.0690, step time: 0.6500\n",
            "774/1001, train_loss: 0.6885, step time: 0.6479\n",
            "775/1001, train_loss: 0.0673, step time: 0.6632\n",
            "776/1001, train_loss: 1.0000, step time: 0.6245\n",
            "777/1001, train_loss: 0.0597, step time: 0.6555\n",
            "778/1001, train_loss: 0.1120, step time: 0.6735\n",
            "779/1001, train_loss: 0.0395, step time: 0.6658\n",
            "780/1001, train_loss: 0.0383, step time: 0.6690\n",
            "781/1001, train_loss: 0.0414, step time: 0.6428\n",
            "782/1001, train_loss: 0.5855, step time: 0.6549\n",
            "783/1001, train_loss: 0.9763, step time: 0.6517\n",
            "784/1001, train_loss: 0.1766, step time: 0.6721\n",
            "785/1001, train_loss: 0.1601, step time: 0.6591\n",
            "786/1001, train_loss: 0.0595, step time: 0.6516\n",
            "787/1001, train_loss: 0.1482, step time: 0.6509\n",
            "788/1001, train_loss: 0.0751, step time: 0.6471\n",
            "789/1001, train_loss: 0.1058, step time: 0.6527\n",
            "790/1001, train_loss: 0.9973, step time: 0.6701\n",
            "791/1001, train_loss: 0.0418, step time: 0.6502\n",
            "792/1001, train_loss: 0.8473, step time: 0.6523\n",
            "793/1001, train_loss: 0.0478, step time: 0.6438\n",
            "794/1001, train_loss: 1.0000, step time: 0.6232\n",
            "795/1001, train_loss: 0.2048, step time: 0.6522\n",
            "796/1001, train_loss: 0.0952, step time: 0.6537\n",
            "797/1001, train_loss: 0.0337, step time: 0.6654\n",
            "798/1001, train_loss: 0.0274, step time: 0.6465\n",
            "799/1001, train_loss: 0.0659, step time: 0.6461\n",
            "800/1001, train_loss: 0.1041, step time: 0.6804\n",
            "801/1001, train_loss: 0.0775, step time: 0.6828\n",
            "802/1001, train_loss: 0.1047, step time: 0.6524\n",
            "803/1001, train_loss: 0.4534, step time: 0.6498\n",
            "804/1001, train_loss: 0.1053, step time: 0.6518\n",
            "805/1001, train_loss: 0.0674, step time: 0.6511\n",
            "806/1001, train_loss: 0.9277, step time: 0.6518\n",
            "807/1001, train_loss: 0.9999, step time: 0.6256\n",
            "808/1001, train_loss: 0.0431, step time: 0.6520\n",
            "809/1001, train_loss: 0.1742, step time: 0.6521\n",
            "810/1001, train_loss: 0.0852, step time: 0.6522\n",
            "811/1001, train_loss: 0.1390, step time: 0.6513\n",
            "812/1001, train_loss: 0.1409, step time: 0.6522\n",
            "813/1001, train_loss: 0.1175, step time: 0.6914\n",
            "814/1001, train_loss: 0.0596, step time: 0.6488\n",
            "815/1001, train_loss: 0.0864, step time: 0.6822\n",
            "816/1001, train_loss: 0.0757, step time: 0.6527\n",
            "817/1001, train_loss: 0.0459, step time: 0.6513\n",
            "818/1001, train_loss: 0.0452, step time: 0.6485\n",
            "819/1001, train_loss: 0.9777, step time: 0.6727\n",
            "820/1001, train_loss: 0.0583, step time: 0.6751\n",
            "821/1001, train_loss: 0.0564, step time: 0.6496\n",
            "822/1001, train_loss: 0.6941, step time: 0.6604\n",
            "823/1001, train_loss: 0.3524, step time: 0.6518\n",
            "824/1001, train_loss: 1.0000, step time: 0.6243\n",
            "825/1001, train_loss: 0.6759, step time: 0.6361\n",
            "826/1001, train_loss: 0.0488, step time: 0.6818\n",
            "827/1001, train_loss: 0.0558, step time: 0.6863\n",
            "828/1001, train_loss: 0.0403, step time: 0.6653\n",
            "829/1001, train_loss: 0.1526, step time: 0.6533\n",
            "830/1001, train_loss: 0.2573, step time: 0.6518\n",
            "831/1001, train_loss: 0.0302, step time: 0.6613\n",
            "832/1001, train_loss: 0.0386, step time: 0.6495\n",
            "833/1001, train_loss: 0.0822, step time: 0.6818\n",
            "834/1001, train_loss: 0.0343, step time: 0.6592\n",
            "835/1001, train_loss: 1.0000, step time: 0.6570\n",
            "836/1001, train_loss: 0.0930, step time: 0.6507\n",
            "837/1001, train_loss: 0.0450, step time: 0.6500\n",
            "838/1001, train_loss: 0.6815, step time: 0.6778\n",
            "839/1001, train_loss: 0.1000, step time: 0.6523\n",
            "840/1001, train_loss: 0.1114, step time: 0.6536\n",
            "841/1001, train_loss: 0.0489, step time: 0.6813\n",
            "842/1001, train_loss: 0.0772, step time: 0.6496\n",
            "843/1001, train_loss: 0.0274, step time: 0.6443\n",
            "844/1001, train_loss: 0.3691, step time: 0.6581\n",
            "845/1001, train_loss: 1.0000, step time: 0.6270\n",
            "846/1001, train_loss: 0.4533, step time: 0.6509\n",
            "847/1001, train_loss: 0.0804, step time: 0.6833\n",
            "848/1001, train_loss: 0.0371, step time: 0.6485\n",
            "849/1001, train_loss: 0.8765, step time: 0.6520\n",
            "850/1001, train_loss: 0.0971, step time: 0.6608\n",
            "851/1001, train_loss: 0.3501, step time: 0.6634\n",
            "852/1001, train_loss: 0.0448, step time: 0.6556\n",
            "853/1001, train_loss: 0.3222, step time: 0.6600\n",
            "854/1001, train_loss: 0.1172, step time: 0.6779\n",
            "855/1001, train_loss: 0.1319, step time: 0.6571\n",
            "856/1001, train_loss: 0.0464, step time: 0.6517\n",
            "857/1001, train_loss: 0.0851, step time: 0.6881\n",
            "858/1001, train_loss: 1.0000, step time: 0.6417\n",
            "859/1001, train_loss: 0.1584, step time: 0.6523\n",
            "860/1001, train_loss: 0.0685, step time: 0.6551\n",
            "861/1001, train_loss: 1.0000, step time: 0.6253\n",
            "862/1001, train_loss: 0.0444, step time: 0.6532\n",
            "863/1001, train_loss: 0.0480, step time: 0.6704\n",
            "864/1001, train_loss: 0.0859, step time: 0.6653\n",
            "865/1001, train_loss: 0.0866, step time: 0.6713\n",
            "866/1001, train_loss: 0.5741, step time: 0.6736\n",
            "867/1001, train_loss: 0.0627, step time: 0.6641\n",
            "868/1001, train_loss: 0.3639, step time: 0.6518\n",
            "869/1001, train_loss: 0.4055, step time: 0.6863\n",
            "870/1001, train_loss: 0.0871, step time: 0.6557\n",
            "871/1001, train_loss: 0.4957, step time: 0.6996\n",
            "872/1001, train_loss: 1.0000, step time: 0.6570\n",
            "873/1001, train_loss: 0.1898, step time: 0.6543\n",
            "874/1001, train_loss: 1.0000, step time: 0.6234\n",
            "875/1001, train_loss: 0.1251, step time: 0.6923\n",
            "876/1001, train_loss: 0.0915, step time: 0.6511\n",
            "877/1001, train_loss: 0.6995, step time: 0.6509\n",
            "878/1001, train_loss: 0.0435, step time: 0.6481\n",
            "879/1001, train_loss: 0.2548, step time: 0.6511\n",
            "880/1001, train_loss: 0.1019, step time: 0.6500\n",
            "881/1001, train_loss: 0.0670, step time: 0.6514\n",
            "882/1001, train_loss: 0.0401, step time: 0.6455\n",
            "883/1001, train_loss: 0.0586, step time: 0.6462\n",
            "884/1001, train_loss: 0.0388, step time: 0.6751\n",
            "885/1001, train_loss: 0.4834, step time: 0.6909\n",
            "886/1001, train_loss: 0.1876, step time: 0.6553\n",
            "887/1001, train_loss: 0.0613, step time: 0.6662\n",
            "888/1001, train_loss: 0.0875, step time: 0.6564\n",
            "889/1001, train_loss: 1.0000, step time: 0.6381\n",
            "890/1001, train_loss: 0.0369, step time: 0.6502\n",
            "891/1001, train_loss: 0.0574, step time: 0.6582\n",
            "892/1001, train_loss: 0.2354, step time: 0.6563\n",
            "893/1001, train_loss: 0.7054, step time: 0.6529\n",
            "894/1001, train_loss: 0.5639, step time: 0.6636\n",
            "895/1001, train_loss: 0.0682, step time: 0.6500\n",
            "896/1001, train_loss: 0.9349, step time: 0.6513\n",
            "897/1001, train_loss: 0.0738, step time: 0.6554\n",
            "898/1001, train_loss: 0.0557, step time: 0.6594\n",
            "899/1001, train_loss: 0.0767, step time: 0.6572\n",
            "900/1001, train_loss: 0.0633, step time: 0.6460\n",
            "901/1001, train_loss: 0.0551, step time: 0.6522\n",
            "902/1001, train_loss: 0.2080, step time: 0.6525\n",
            "903/1001, train_loss: 0.1095, step time: 0.6801\n",
            "904/1001, train_loss: 0.1162, step time: 0.6606\n",
            "905/1001, train_loss: 0.1078, step time: 0.6557\n",
            "906/1001, train_loss: 0.0827, step time: 0.6799\n",
            "907/1001, train_loss: 0.0587, step time: 0.6553\n",
            "908/1001, train_loss: 0.1475, step time: 0.6786\n",
            "909/1001, train_loss: 0.7072, step time: 0.6538\n",
            "910/1001, train_loss: 0.1251, step time: 0.6768\n",
            "911/1001, train_loss: 0.2069, step time: 0.6531\n",
            "912/1001, train_loss: 0.1315, step time: 0.6634\n",
            "913/1001, train_loss: 0.0739, step time: 0.6523\n",
            "914/1001, train_loss: 0.0372, step time: 0.6524\n",
            "915/1001, train_loss: 0.0355, step time: 0.6503\n",
            "916/1001, train_loss: 0.5800, step time: 0.6520\n",
            "917/1001, train_loss: 0.0590, step time: 0.6522\n",
            "918/1001, train_loss: 0.0573, step time: 0.6528\n",
            "919/1001, train_loss: 0.1696, step time: 0.6788\n",
            "920/1001, train_loss: 0.1554, step time: 0.6662\n",
            "921/1001, train_loss: 0.3592, step time: 0.6559\n",
            "922/1001, train_loss: 0.0421, step time: 0.6490\n",
            "923/1001, train_loss: 0.0488, step time: 0.6505\n",
            "924/1001, train_loss: 0.0880, step time: 0.6665\n",
            "925/1001, train_loss: 0.0559, step time: 0.6756\n",
            "926/1001, train_loss: 0.1148, step time: 0.6571\n",
            "927/1001, train_loss: 0.0380, step time: 0.6593\n",
            "928/1001, train_loss: 0.7514, step time: 0.6544\n",
            "929/1001, train_loss: 0.0887, step time: 0.6601\n",
            "930/1001, train_loss: 0.0738, step time: 0.6644\n",
            "931/1001, train_loss: 0.4272, step time: 0.6747\n",
            "932/1001, train_loss: 0.1492, step time: 0.6663\n",
            "933/1001, train_loss: 0.0660, step time: 0.6791\n",
            "934/1001, train_loss: 0.0227, step time: 0.6690\n",
            "935/1001, train_loss: 0.9429, step time: 0.6531\n",
            "936/1001, train_loss: 0.1159, step time: 0.6504\n",
            "937/1001, train_loss: 0.0788, step time: 0.6725\n",
            "938/1001, train_loss: 0.1923, step time: 0.6581\n",
            "939/1001, train_loss: 0.5653, step time: 0.6504\n",
            "940/1001, train_loss: 1.0000, step time: 0.6428\n",
            "941/1001, train_loss: 0.0637, step time: 0.6575\n",
            "942/1001, train_loss: 0.7712, step time: 0.6642\n",
            "943/1001, train_loss: 0.0421, step time: 0.6575\n",
            "944/1001, train_loss: 0.0839, step time: 0.6567\n",
            "945/1001, train_loss: 1.0000, step time: 0.6295\n",
            "946/1001, train_loss: 0.1219, step time: 0.6562\n",
            "947/1001, train_loss: 0.0553, step time: 0.6519\n",
            "948/1001, train_loss: 0.3707, step time: 0.6616\n",
            "949/1001, train_loss: 0.1313, step time: 0.6546\n",
            "950/1001, train_loss: 0.0644, step time: 0.6559\n",
            "951/1001, train_loss: 0.0524, step time: 0.6595\n",
            "952/1001, train_loss: 0.0962, step time: 0.6515\n",
            "953/1001, train_loss: 0.6800, step time: 0.6516\n",
            "954/1001, train_loss: 0.1875, step time: 0.6676\n",
            "955/1001, train_loss: 0.0870, step time: 0.6568\n",
            "956/1001, train_loss: 0.0626, step time: 0.6515\n",
            "957/1001, train_loss: 0.0749, step time: 0.6542\n",
            "958/1001, train_loss: 0.0545, step time: 0.6524\n",
            "959/1001, train_loss: 0.2276, step time: 0.6538\n",
            "960/1001, train_loss: 0.0503, step time: 0.6768\n",
            "961/1001, train_loss: 0.0699, step time: 0.6728\n",
            "962/1001, train_loss: 0.0394, step time: 0.6663\n",
            "963/1001, train_loss: 0.0842, step time: 0.6514\n",
            "964/1001, train_loss: 0.4001, step time: 0.6783\n",
            "965/1001, train_loss: 1.0000, step time: 0.6455\n",
            "966/1001, train_loss: 0.0596, step time: 0.6728\n",
            "967/1001, train_loss: 0.4177, step time: 0.6523\n",
            "968/1001, train_loss: 0.0742, step time: 0.6598\n",
            "969/1001, train_loss: 0.0462, step time: 0.6827\n",
            "970/1001, train_loss: 0.1448, step time: 0.6548\n",
            "971/1001, train_loss: 0.0974, step time: 0.6579\n",
            "972/1001, train_loss: 1.0000, step time: 0.6239\n",
            "973/1001, train_loss: 0.0484, step time: 0.6496\n",
            "974/1001, train_loss: 0.1024, step time: 0.6504\n",
            "975/1001, train_loss: 0.0460, step time: 0.6475\n",
            "976/1001, train_loss: 0.2365, step time: 0.6520\n",
            "977/1001, train_loss: 0.4362, step time: 0.6557\n",
            "978/1001, train_loss: 0.0270, step time: 0.6630\n",
            "979/1001, train_loss: 0.0461, step time: 0.6696\n",
            "980/1001, train_loss: 0.7855, step time: 0.6621\n",
            "981/1001, train_loss: 0.1930, step time: 0.6784\n",
            "982/1001, train_loss: 0.3380, step time: 0.6611\n",
            "983/1001, train_loss: 0.1531, step time: 0.6547\n",
            "984/1001, train_loss: 0.5239, step time: 0.6596\n",
            "985/1001, train_loss: 0.2173, step time: 0.6552\n",
            "986/1001, train_loss: 0.7175, step time: 0.6526\n",
            "987/1001, train_loss: 0.6993, step time: 0.6509\n",
            "988/1001, train_loss: 0.0392, step time: 0.6481\n",
            "989/1001, train_loss: 0.9889, step time: 0.6403\n",
            "990/1001, train_loss: 0.2898, step time: 0.6509\n",
            "991/1001, train_loss: 0.0612, step time: 0.6503\n",
            "992/1001, train_loss: 0.9999, step time: 0.6288\n",
            "993/1001, train_loss: 0.0393, step time: 0.6502\n",
            "994/1001, train_loss: 0.1533, step time: 0.6517\n",
            "995/1001, train_loss: 0.1277, step time: 0.6501\n",
            "996/1001, train_loss: 0.7221, step time: 0.6521\n",
            "997/1001, train_loss: 0.0766, step time: 0.6521\n",
            "998/1001, train_loss: 0.3994, step time: 0.6521\n",
            "999/1001, train_loss: 0.0463, step time: 0.6488\n",
            "1000/1001, train_loss: 0.0560, step time: 0.6518\n",
            "1001/1001, train_loss: 0.0548, step time: 0.6474\n",
            "epoch 17 average loss: 0.2797\n",
            "current epoch: 17 current mean dice: 0.8655 tc: 0.8604 wt: 0.8993 et: 0.8410\n",
            "best mean dice: 0.8665 at epoch: 14\n",
            "time consuming of epoch 17 is: 831.8781\n",
            "----------\n",
            "epoch 18/20\n",
            "1/1001, train_loss: 0.8556, step time: 0.7007\n",
            "2/1001, train_loss: 0.1563, step time: 0.7160\n",
            "3/1001, train_loss: 0.0737, step time: 0.6627\n",
            "4/1001, train_loss: 0.0566, step time: 0.6876\n",
            "5/1001, train_loss: 0.0560, step time: 0.6600\n",
            "6/1001, train_loss: 0.1541, step time: 0.6824\n",
            "7/1001, train_loss: 0.9867, step time: 0.6611\n",
            "8/1001, train_loss: 0.0612, step time: 0.6647\n",
            "9/1001, train_loss: 0.0279, step time: 0.6531\n",
            "10/1001, train_loss: 0.7812, step time: 0.6572\n",
            "11/1001, train_loss: 0.0300, step time: 0.6485\n",
            "12/1001, train_loss: 0.3768, step time: 0.6517\n",
            "13/1001, train_loss: 0.3640, step time: 0.7206\n",
            "14/1001, train_loss: 0.0945, step time: 0.6979\n",
            "15/1001, train_loss: 0.0715, step time: 0.6503\n",
            "16/1001, train_loss: 0.0385, step time: 0.6932\n",
            "17/1001, train_loss: 0.2849, step time: 0.7352\n",
            "18/1001, train_loss: 0.1540, step time: 0.7474\n",
            "19/1001, train_loss: 0.0451, step time: 0.7169\n",
            "20/1001, train_loss: 1.0000, step time: 0.6848\n",
            "21/1001, train_loss: 0.7710, step time: 0.7101\n",
            "22/1001, train_loss: 0.0445, step time: 0.6530\n",
            "23/1001, train_loss: 0.1434, step time: 0.6826\n",
            "24/1001, train_loss: 1.0000, step time: 0.6300\n",
            "25/1001, train_loss: 0.0436, step time: 0.6741\n",
            "26/1001, train_loss: 0.0750, step time: 0.6707\n",
            "27/1001, train_loss: 0.0424, step time: 0.6749\n",
            "28/1001, train_loss: 0.0376, step time: 0.6486\n",
            "29/1001, train_loss: 1.0000, step time: 0.6227\n",
            "30/1001, train_loss: 0.1029, step time: 0.6501\n",
            "31/1001, train_loss: 0.0949, step time: 0.6529\n",
            "32/1001, train_loss: 0.4447, step time: 0.6525\n",
            "33/1001, train_loss: 0.2713, step time: 0.6523\n",
            "34/1001, train_loss: 0.0876, step time: 0.6888\n",
            "35/1001, train_loss: 0.1035, step time: 0.6554\n",
            "36/1001, train_loss: 0.0573, step time: 0.6509\n",
            "37/1001, train_loss: 0.1146, step time: 0.6650\n",
            "38/1001, train_loss: 0.0752, step time: 0.6498\n",
            "39/1001, train_loss: 0.0736, step time: 0.6520\n",
            "40/1001, train_loss: 0.8487, step time: 0.6715\n",
            "41/1001, train_loss: 0.0605, step time: 0.6498\n",
            "42/1001, train_loss: 0.0251, step time: 0.6494\n",
            "43/1001, train_loss: 0.0469, step time: 0.6656\n",
            "44/1001, train_loss: 1.0000, step time: 0.6247\n",
            "45/1001, train_loss: 0.0513, step time: 0.6602\n",
            "46/1001, train_loss: 0.0848, step time: 0.6825\n",
            "47/1001, train_loss: 0.0652, step time: 0.6528\n",
            "48/1001, train_loss: 0.1484, step time: 0.6576\n",
            "49/1001, train_loss: 0.0411, step time: 0.6500\n",
            "50/1001, train_loss: 1.0000, step time: 0.6346\n",
            "51/1001, train_loss: 0.1870, step time: 0.6673\n",
            "52/1001, train_loss: 0.3287, step time: 0.6539\n",
            "53/1001, train_loss: 0.1551, step time: 0.6677\n",
            "54/1001, train_loss: 0.1368, step time: 0.6528\n",
            "55/1001, train_loss: 0.1439, step time: 0.6539\n",
            "56/1001, train_loss: 0.1288, step time: 0.6539\n",
            "57/1001, train_loss: 0.3105, step time: 0.6518\n",
            "58/1001, train_loss: 0.7623, step time: 0.6520\n",
            "59/1001, train_loss: 0.7245, step time: 0.6519\n",
            "60/1001, train_loss: 0.0519, step time: 0.6518\n",
            "61/1001, train_loss: 0.0310, step time: 0.6496\n",
            "62/1001, train_loss: 0.3559, step time: 0.6519\n",
            "63/1001, train_loss: 1.0000, step time: 0.6258\n",
            "64/1001, train_loss: 0.7118, step time: 0.6733\n",
            "65/1001, train_loss: 0.0600, step time: 0.6649\n",
            "66/1001, train_loss: 0.1136, step time: 0.6532\n",
            "67/1001, train_loss: 0.0491, step time: 0.6506\n",
            "68/1001, train_loss: 0.0862, step time: 0.6521\n",
            "69/1001, train_loss: 0.0812, step time: 0.7250\n",
            "70/1001, train_loss: 0.1258, step time: 0.6662\n",
            "71/1001, train_loss: 0.1802, step time: 0.6511\n",
            "72/1001, train_loss: 0.0541, step time: 0.6542\n",
            "73/1001, train_loss: 0.7588, step time: 0.6569\n",
            "74/1001, train_loss: 0.8271, step time: 0.6550\n",
            "75/1001, train_loss: 0.1104, step time: 0.6678\n",
            "76/1001, train_loss: 0.1259, step time: 0.6820\n",
            "77/1001, train_loss: 1.0000, step time: 0.6235\n",
            "78/1001, train_loss: 0.1107, step time: 0.6843\n",
            "79/1001, train_loss: 0.0416, step time: 0.6599\n",
            "80/1001, train_loss: 0.0409, step time: 0.6486\n",
            "81/1001, train_loss: 0.0804, step time: 0.6521\n",
            "82/1001, train_loss: 0.0412, step time: 0.6525\n",
            "83/1001, train_loss: 1.0000, step time: 0.6235\n",
            "84/1001, train_loss: 0.1093, step time: 0.6825\n",
            "85/1001, train_loss: 0.0323, step time: 0.6499\n",
            "86/1001, train_loss: 1.0000, step time: 0.6231\n",
            "87/1001, train_loss: 0.1240, step time: 0.6827\n",
            "88/1001, train_loss: 1.0000, step time: 0.6225\n",
            "89/1001, train_loss: 0.1891, step time: 0.6527\n",
            "90/1001, train_loss: 0.7296, step time: 0.6580\n",
            "91/1001, train_loss: 0.5688, step time: 0.6780\n",
            "92/1001, train_loss: 0.0803, step time: 0.6518\n",
            "93/1001, train_loss: 0.1995, step time: 0.6528\n",
            "94/1001, train_loss: 0.0371, step time: 0.6513\n",
            "95/1001, train_loss: 0.4010, step time: 0.6479\n",
            "96/1001, train_loss: 0.0266, step time: 0.6594\n",
            "97/1001, train_loss: 0.0938, step time: 0.6567\n",
            "98/1001, train_loss: 0.1586, step time: 0.6616\n",
            "99/1001, train_loss: 0.1191, step time: 0.6610\n",
            "100/1001, train_loss: 0.0572, step time: 0.6542\n",
            "101/1001, train_loss: 0.1342, step time: 0.6567\n",
            "102/1001, train_loss: 0.0661, step time: 0.6586\n",
            "103/1001, train_loss: 0.1313, step time: 0.6546\n",
            "104/1001, train_loss: 0.0834, step time: 0.6660\n",
            "105/1001, train_loss: 0.0332, step time: 0.6537\n",
            "106/1001, train_loss: 1.0000, step time: 0.6238\n",
            "107/1001, train_loss: 0.1160, step time: 0.6558\n",
            "108/1001, train_loss: 0.1651, step time: 0.6524\n",
            "109/1001, train_loss: 0.0573, step time: 0.6524\n",
            "110/1001, train_loss: 0.0660, step time: 0.6503\n",
            "111/1001, train_loss: 0.0628, step time: 0.6510\n",
            "112/1001, train_loss: 0.0273, step time: 0.6498\n",
            "113/1001, train_loss: 0.0432, step time: 0.6492\n",
            "114/1001, train_loss: 0.1063, step time: 0.6793\n",
            "115/1001, train_loss: 0.0587, step time: 0.6629\n",
            "116/1001, train_loss: 0.1112, step time: 0.6502\n",
            "117/1001, train_loss: 0.0378, step time: 0.6508\n",
            "118/1001, train_loss: 0.0361, step time: 0.6521\n",
            "119/1001, train_loss: 0.0456, step time: 0.6498\n",
            "120/1001, train_loss: 0.0491, step time: 0.6510\n",
            "121/1001, train_loss: 0.0546, step time: 0.6747\n",
            "122/1001, train_loss: 0.1289, step time: 0.6653\n",
            "123/1001, train_loss: 0.3438, step time: 0.6528\n",
            "124/1001, train_loss: 0.0394, step time: 0.6484\n",
            "125/1001, train_loss: 0.1667, step time: 0.6565\n",
            "126/1001, train_loss: 0.1018, step time: 0.6685\n",
            "127/1001, train_loss: 0.0655, step time: 0.6529\n",
            "128/1001, train_loss: 0.0541, step time: 0.6521\n",
            "129/1001, train_loss: 0.0350, step time: 0.6547\n",
            "130/1001, train_loss: 0.4638, step time: 0.6600\n",
            "131/1001, train_loss: 0.0773, step time: 0.6540\n",
            "132/1001, train_loss: 0.0843, step time: 0.6531\n",
            "133/1001, train_loss: 0.0341, step time: 0.6546\n",
            "134/1001, train_loss: 0.6775, step time: 0.6522\n",
            "135/1001, train_loss: 0.0356, step time: 0.6539\n",
            "136/1001, train_loss: 0.0719, step time: 0.6500\n",
            "137/1001, train_loss: 0.6800, step time: 0.6594\n",
            "138/1001, train_loss: 0.0735, step time: 0.6579\n",
            "139/1001, train_loss: 0.0808, step time: 0.6515\n",
            "140/1001, train_loss: 0.1891, step time: 0.6577\n",
            "141/1001, train_loss: 0.0853, step time: 0.6510\n",
            "142/1001, train_loss: 0.3262, step time: 0.6529\n",
            "143/1001, train_loss: 0.3094, step time: 0.6775\n",
            "144/1001, train_loss: 1.0000, step time: 0.6283\n",
            "145/1001, train_loss: 0.4223, step time: 0.6549\n",
            "146/1001, train_loss: 0.1077, step time: 0.6653\n",
            "147/1001, train_loss: 0.0648, step time: 0.6512\n",
            "148/1001, train_loss: 0.0520, step time: 0.6712\n",
            "149/1001, train_loss: 1.0000, step time: 0.6247\n",
            "150/1001, train_loss: 0.0413, step time: 0.6549\n",
            "151/1001, train_loss: 0.1181, step time: 0.6530\n",
            "152/1001, train_loss: 0.5129, step time: 0.6679\n",
            "153/1001, train_loss: 0.6858, step time: 0.6479\n",
            "154/1001, train_loss: 0.5250, step time: 0.6633\n",
            "155/1001, train_loss: 0.7457, step time: 0.6869\n",
            "156/1001, train_loss: 0.0358, step time: 0.6631\n",
            "157/1001, train_loss: 0.0458, step time: 0.6866\n",
            "158/1001, train_loss: 0.9439, step time: 0.6539\n",
            "159/1001, train_loss: 0.0343, step time: 0.6810\n",
            "160/1001, train_loss: 0.4845, step time: 0.6526\n",
            "161/1001, train_loss: 0.0616, step time: 0.6504\n",
            "162/1001, train_loss: 0.0478, step time: 0.6579\n",
            "163/1001, train_loss: 0.2048, step time: 0.6568\n",
            "164/1001, train_loss: 1.0000, step time: 0.6252\n",
            "165/1001, train_loss: 0.3629, step time: 0.6532\n",
            "166/1001, train_loss: 0.2625, step time: 0.6527\n",
            "167/1001, train_loss: 0.0636, step time: 0.6513\n",
            "168/1001, train_loss: 0.1430, step time: 0.6777\n",
            "169/1001, train_loss: 0.4746, step time: 0.6612\n",
            "170/1001, train_loss: 0.7015, step time: 0.7089\n",
            "171/1001, train_loss: 0.1457, step time: 0.6525\n",
            "172/1001, train_loss: 0.0618, step time: 0.6498\n",
            "173/1001, train_loss: 0.0613, step time: 0.6650\n",
            "174/1001, train_loss: 0.0746, step time: 0.6505\n",
            "175/1001, train_loss: 0.0839, step time: 0.6526\n",
            "176/1001, train_loss: 0.0746, step time: 0.6588\n",
            "177/1001, train_loss: 0.0354, step time: 0.6618\n",
            "178/1001, train_loss: 0.0520, step time: 0.6513\n",
            "179/1001, train_loss: 0.0271, step time: 0.6511\n",
            "180/1001, train_loss: 0.1576, step time: 0.6642\n",
            "181/1001, train_loss: 1.0000, step time: 0.6307\n",
            "182/1001, train_loss: 0.0814, step time: 0.6629\n",
            "183/1001, train_loss: 0.7180, step time: 0.6516\n",
            "184/1001, train_loss: 0.0515, step time: 0.6486\n",
            "185/1001, train_loss: 0.0323, step time: 0.6487\n",
            "186/1001, train_loss: 0.9959, step time: 0.6557\n",
            "187/1001, train_loss: 0.0410, step time: 0.6610\n",
            "188/1001, train_loss: 0.0770, step time: 0.6531\n",
            "189/1001, train_loss: 0.0483, step time: 0.6597\n",
            "190/1001, train_loss: 0.2465, step time: 0.6572\n",
            "191/1001, train_loss: 0.0833, step time: 0.6501\n",
            "192/1001, train_loss: 0.0942, step time: 0.6553\n",
            "193/1001, train_loss: 0.0433, step time: 0.6513\n",
            "194/1001, train_loss: 0.3949, step time: 0.6521\n",
            "195/1001, train_loss: 0.9075, step time: 0.6527\n",
            "196/1001, train_loss: 0.0475, step time: 0.6791\n",
            "197/1001, train_loss: 0.7152, step time: 0.6677\n",
            "198/1001, train_loss: 0.4305, step time: 0.6589\n",
            "199/1001, train_loss: 0.4570, step time: 0.6514\n",
            "200/1001, train_loss: 0.0698, step time: 0.6519\n",
            "201/1001, train_loss: 0.0632, step time: 0.6509\n",
            "202/1001, train_loss: 0.1693, step time: 0.6609\n",
            "203/1001, train_loss: 0.0423, step time: 0.6576\n",
            "204/1001, train_loss: 0.0545, step time: 0.6513\n",
            "205/1001, train_loss: 1.0000, step time: 0.6246\n",
            "206/1001, train_loss: 0.0534, step time: 0.6503\n",
            "207/1001, train_loss: 0.2505, step time: 0.6590\n",
            "208/1001, train_loss: 0.1168, step time: 0.6551\n",
            "209/1001, train_loss: 0.0778, step time: 0.6536\n",
            "210/1001, train_loss: 0.1945, step time: 0.6647\n",
            "211/1001, train_loss: 1.0000, step time: 0.6240\n",
            "212/1001, train_loss: 0.0979, step time: 0.6499\n",
            "213/1001, train_loss: 0.0767, step time: 0.6505\n",
            "214/1001, train_loss: 0.0956, step time: 0.6579\n",
            "215/1001, train_loss: 0.3249, step time: 0.6540\n",
            "216/1001, train_loss: 0.3134, step time: 0.6519\n",
            "217/1001, train_loss: 0.0639, step time: 0.6751\n",
            "218/1001, train_loss: 0.1963, step time: 0.6544\n",
            "219/1001, train_loss: 0.0441, step time: 0.6615\n",
            "220/1001, train_loss: 0.2034, step time: 0.6764\n",
            "221/1001, train_loss: 0.1399, step time: 0.6783\n",
            "222/1001, train_loss: 0.3899, step time: 0.6630\n",
            "223/1001, train_loss: 0.1014, step time: 0.6592\n",
            "224/1001, train_loss: 0.0454, step time: 0.6564\n",
            "225/1001, train_loss: 0.1083, step time: 0.6529\n",
            "226/1001, train_loss: 0.0309, step time: 0.6543\n",
            "227/1001, train_loss: 0.1047, step time: 0.6903\n",
            "228/1001, train_loss: 1.0000, step time: 0.6266\n",
            "229/1001, train_loss: 0.9354, step time: 0.6518\n",
            "230/1001, train_loss: 0.0702, step time: 0.6521\n",
            "231/1001, train_loss: 0.9641, step time: 0.6514\n",
            "232/1001, train_loss: 0.1591, step time: 0.6523\n",
            "233/1001, train_loss: 0.6931, step time: 0.6547\n",
            "234/1001, train_loss: 0.1404, step time: 0.6529\n",
            "235/1001, train_loss: 0.9610, step time: 0.6503\n",
            "236/1001, train_loss: 0.2013, step time: 0.6538\n",
            "237/1001, train_loss: 0.0365, step time: 0.6517\n",
            "238/1001, train_loss: 0.0530, step time: 0.6509\n",
            "239/1001, train_loss: 0.7801, step time: 0.6528\n",
            "240/1001, train_loss: 1.0000, step time: 0.6293\n",
            "241/1001, train_loss: 0.1743, step time: 0.6554\n",
            "242/1001, train_loss: 0.0776, step time: 0.6492\n",
            "243/1001, train_loss: 0.0402, step time: 0.6548\n",
            "244/1001, train_loss: 0.1596, step time: 0.6760\n",
            "245/1001, train_loss: 0.0503, step time: 0.6760\n",
            "246/1001, train_loss: 0.0901, step time: 0.6493\n",
            "247/1001, train_loss: 1.0000, step time: 0.6237\n",
            "248/1001, train_loss: 0.1888, step time: 0.6528\n",
            "249/1001, train_loss: 0.1323, step time: 0.6517\n",
            "250/1001, train_loss: 1.0000, step time: 0.6264\n",
            "251/1001, train_loss: 0.4402, step time: 0.6522\n",
            "252/1001, train_loss: 0.0708, step time: 0.6493\n",
            "253/1001, train_loss: 0.0580, step time: 0.6479\n",
            "254/1001, train_loss: 0.0666, step time: 0.6552\n",
            "255/1001, train_loss: 0.0224, step time: 0.6437\n",
            "256/1001, train_loss: 0.0576, step time: 0.6510\n",
            "257/1001, train_loss: 0.0402, step time: 0.6483\n",
            "258/1001, train_loss: 0.0776, step time: 0.6716\n",
            "259/1001, train_loss: 0.5572, step time: 0.6853\n",
            "260/1001, train_loss: 0.6985, step time: 0.6514\n",
            "261/1001, train_loss: 0.6084, step time: 0.6558\n",
            "262/1001, train_loss: 0.0544, step time: 0.6492\n",
            "263/1001, train_loss: 0.0495, step time: 0.6495\n",
            "264/1001, train_loss: 0.0723, step time: 0.6498\n",
            "265/1001, train_loss: 0.0662, step time: 0.6561\n",
            "266/1001, train_loss: 0.0263, step time: 0.6744\n",
            "267/1001, train_loss: 0.0314, step time: 0.6512\n",
            "268/1001, train_loss: 0.0444, step time: 0.6538\n",
            "269/1001, train_loss: 0.0554, step time: 0.6688\n",
            "270/1001, train_loss: 0.3513, step time: 0.6521\n",
            "271/1001, train_loss: 0.0378, step time: 0.6708\n",
            "272/1001, train_loss: 0.1059, step time: 0.6532\n",
            "273/1001, train_loss: 0.0738, step time: 0.6519\n",
            "274/1001, train_loss: 0.1147, step time: 0.6523\n",
            "275/1001, train_loss: 0.2242, step time: 0.6601\n",
            "276/1001, train_loss: 0.1132, step time: 0.6541\n",
            "277/1001, train_loss: 0.0423, step time: 0.6554\n",
            "278/1001, train_loss: 0.0543, step time: 0.7432\n",
            "279/1001, train_loss: 0.7608, step time: 0.6520\n",
            "280/1001, train_loss: 0.0390, step time: 0.6520\n",
            "281/1001, train_loss: 0.0752, step time: 0.6531\n",
            "282/1001, train_loss: 0.4384, step time: 0.6526\n",
            "283/1001, train_loss: 0.0769, step time: 0.6917\n",
            "284/1001, train_loss: 0.9983, step time: 0.6531\n",
            "285/1001, train_loss: 0.0642, step time: 0.6608\n",
            "286/1001, train_loss: 0.8484, step time: 0.6532\n",
            "287/1001, train_loss: 0.2374, step time: 0.6520\n",
            "288/1001, train_loss: 0.0479, step time: 0.6501\n",
            "289/1001, train_loss: 0.1268, step time: 0.6693\n",
            "290/1001, train_loss: 0.0569, step time: 0.6496\n",
            "291/1001, train_loss: 0.1189, step time: 0.6509\n",
            "292/1001, train_loss: 0.6264, step time: 0.6543\n",
            "293/1001, train_loss: 0.0314, step time: 0.6480\n",
            "294/1001, train_loss: 0.0503, step time: 0.6488\n",
            "295/1001, train_loss: 0.0644, step time: 0.6518\n",
            "296/1001, train_loss: 0.2010, step time: 0.6696\n",
            "297/1001, train_loss: 0.0411, step time: 0.6544\n",
            "298/1001, train_loss: 0.0350, step time: 0.6818\n",
            "299/1001, train_loss: 0.7953, step time: 0.6578\n",
            "300/1001, train_loss: 0.6824, step time: 0.6577\n",
            "301/1001, train_loss: 0.1449, step time: 0.6500\n",
            "302/1001, train_loss: 0.0680, step time: 0.6512\n",
            "303/1001, train_loss: 0.4436, step time: 0.6656\n",
            "304/1001, train_loss: 0.0815, step time: 0.6516\n",
            "305/1001, train_loss: 0.0329, step time: 0.6719\n",
            "306/1001, train_loss: 0.0423, step time: 0.6717\n",
            "307/1001, train_loss: 0.0651, step time: 0.6519\n",
            "308/1001, train_loss: 0.1023, step time: 0.6733\n",
            "309/1001, train_loss: 0.0905, step time: 0.6568\n",
            "310/1001, train_loss: 0.0655, step time: 0.6538\n",
            "311/1001, train_loss: 0.2414, step time: 0.6569\n",
            "312/1001, train_loss: 0.0604, step time: 0.6664\n",
            "313/1001, train_loss: 0.7925, step time: 0.6615\n",
            "314/1001, train_loss: 0.0808, step time: 0.6582\n",
            "315/1001, train_loss: 0.0388, step time: 0.6700\n",
            "316/1001, train_loss: 0.0870, step time: 0.6546\n",
            "317/1001, train_loss: 0.0330, step time: 0.6890\n",
            "318/1001, train_loss: 0.0779, step time: 0.6539\n",
            "319/1001, train_loss: 0.4373, step time: 0.6776\n",
            "320/1001, train_loss: 0.1332, step time: 0.6581\n",
            "321/1001, train_loss: 0.0436, step time: 0.6621\n",
            "322/1001, train_loss: 1.0000, step time: 0.6222\n",
            "323/1001, train_loss: 0.5946, step time: 0.6566\n",
            "324/1001, train_loss: 0.8646, step time: 0.6536\n",
            "325/1001, train_loss: 0.0336, step time: 0.6515\n",
            "326/1001, train_loss: 0.0405, step time: 0.6536\n",
            "327/1001, train_loss: 0.0595, step time: 0.6742\n",
            "328/1001, train_loss: 0.1393, step time: 0.6549\n",
            "329/1001, train_loss: 0.0480, step time: 0.6497\n",
            "330/1001, train_loss: 0.0500, step time: 0.6505\n",
            "331/1001, train_loss: 0.4042, step time: 0.6780\n",
            "332/1001, train_loss: 0.0431, step time: 0.6496\n",
            "333/1001, train_loss: 0.6588, step time: 0.6557\n",
            "334/1001, train_loss: 0.0547, step time: 0.6488\n",
            "335/1001, train_loss: 0.1318, step time: 0.6539\n",
            "336/1001, train_loss: 0.0701, step time: 0.6532\n",
            "337/1001, train_loss: 0.0665, step time: 0.6650\n",
            "338/1001, train_loss: 0.0821, step time: 0.6576\n",
            "339/1001, train_loss: 0.1306, step time: 0.6516\n",
            "340/1001, train_loss: 0.0502, step time: 0.6709\n",
            "341/1001, train_loss: 0.0723, step time: 0.6557\n",
            "342/1001, train_loss: 0.3415, step time: 0.6531\n",
            "343/1001, train_loss: 0.1897, step time: 0.6514\n",
            "344/1001, train_loss: 0.0799, step time: 0.6565\n",
            "345/1001, train_loss: 0.0311, step time: 0.6513\n",
            "346/1001, train_loss: 1.0000, step time: 0.6581\n",
            "347/1001, train_loss: 0.0775, step time: 0.6543\n",
            "348/1001, train_loss: 0.0353, step time: 0.6790\n",
            "349/1001, train_loss: 0.7132, step time: 0.6779\n",
            "350/1001, train_loss: 0.0923, step time: 0.6522\n",
            "351/1001, train_loss: 0.0616, step time: 0.6601\n",
            "352/1001, train_loss: 0.0573, step time: 0.6922\n",
            "353/1001, train_loss: 0.0579, step time: 0.6529\n",
            "354/1001, train_loss: 0.4203, step time: 0.6501\n",
            "355/1001, train_loss: 0.0638, step time: 0.6766\n",
            "356/1001, train_loss: 0.0890, step time: 0.6526\n",
            "357/1001, train_loss: 0.0423, step time: 0.6568\n",
            "358/1001, train_loss: 0.0840, step time: 0.6607\n",
            "359/1001, train_loss: 0.0457, step time: 0.6800\n",
            "360/1001, train_loss: 0.0598, step time: 0.6545\n",
            "361/1001, train_loss: 0.3821, step time: 0.6497\n",
            "362/1001, train_loss: 0.9932, step time: 0.6723\n",
            "363/1001, train_loss: 0.2130, step time: 0.6551\n",
            "364/1001, train_loss: 0.7076, step time: 0.6509\n",
            "365/1001, train_loss: 0.2094, step time: 0.6519\n",
            "366/1001, train_loss: 0.0736, step time: 0.6529\n",
            "367/1001, train_loss: 0.1103, step time: 0.6517\n",
            "368/1001, train_loss: 0.2229, step time: 0.6519\n",
            "369/1001, train_loss: 0.5189, step time: 0.6603\n",
            "370/1001, train_loss: 0.7231, step time: 0.6909\n",
            "371/1001, train_loss: 0.0770, step time: 0.6841\n",
            "372/1001, train_loss: 0.0352, step time: 0.6541\n",
            "373/1001, train_loss: 0.4385, step time: 0.6711\n",
            "374/1001, train_loss: 0.9684, step time: 0.6531\n",
            "375/1001, train_loss: 0.0462, step time: 0.6530\n",
            "376/1001, train_loss: 0.1042, step time: 0.6512\n",
            "377/1001, train_loss: 0.0840, step time: 0.6561\n",
            "378/1001, train_loss: 0.0554, step time: 0.6492\n",
            "379/1001, train_loss: 0.0796, step time: 0.6498\n",
            "380/1001, train_loss: 0.1177, step time: 0.6703\n",
            "381/1001, train_loss: 0.0890, step time: 0.6613\n",
            "382/1001, train_loss: 0.0682, step time: 0.6524\n",
            "383/1001, train_loss: 0.2184, step time: 0.6521\n",
            "384/1001, train_loss: 0.0632, step time: 0.6598\n",
            "385/1001, train_loss: 0.0771, step time: 0.6522\n",
            "386/1001, train_loss: 0.0433, step time: 0.6542\n",
            "387/1001, train_loss: 0.0751, step time: 0.6597\n",
            "388/1001, train_loss: 0.1237, step time: 0.6527\n",
            "389/1001, train_loss: 0.2977, step time: 0.6551\n",
            "390/1001, train_loss: 0.0584, step time: 0.6507\n",
            "391/1001, train_loss: 0.0471, step time: 0.6495\n",
            "392/1001, train_loss: 0.8313, step time: 0.6785\n",
            "393/1001, train_loss: 0.1489, step time: 0.6520\n",
            "394/1001, train_loss: 0.0993, step time: 0.6582\n",
            "395/1001, train_loss: 0.0329, step time: 0.6497\n",
            "396/1001, train_loss: 0.1839, step time: 0.6771\n",
            "397/1001, train_loss: 0.2952, step time: 0.6527\n",
            "398/1001, train_loss: 0.0433, step time: 0.6499\n",
            "399/1001, train_loss: 1.0000, step time: 0.6429\n",
            "400/1001, train_loss: 0.0719, step time: 0.6522\n",
            "401/1001, train_loss: 0.1111, step time: 0.6572\n",
            "402/1001, train_loss: 0.0457, step time: 0.6513\n",
            "403/1001, train_loss: 0.0528, step time: 0.6557\n",
            "404/1001, train_loss: 0.0933, step time: 0.6786\n",
            "405/1001, train_loss: 0.2839, step time: 0.6566\n",
            "406/1001, train_loss: 0.1551, step time: 0.6519\n",
            "407/1001, train_loss: 0.4137, step time: 0.6579\n",
            "408/1001, train_loss: 0.0440, step time: 0.6522\n",
            "409/1001, train_loss: 0.9387, step time: 0.6625\n",
            "410/1001, train_loss: 0.2908, step time: 0.6558\n",
            "411/1001, train_loss: 0.3500, step time: 0.6529\n",
            "412/1001, train_loss: 1.0000, step time: 0.6230\n",
            "413/1001, train_loss: 0.0469, step time: 0.6514\n",
            "414/1001, train_loss: 0.0656, step time: 0.6610\n",
            "415/1001, train_loss: 0.0698, step time: 0.6534\n",
            "416/1001, train_loss: 0.8214, step time: 0.6520\n",
            "417/1001, train_loss: 0.0363, step time: 0.6787\n",
            "418/1001, train_loss: 1.0000, step time: 0.6539\n",
            "419/1001, train_loss: 0.6925, step time: 0.6643\n",
            "420/1001, train_loss: 0.7435, step time: 0.6707\n",
            "421/1001, train_loss: 0.1038, step time: 0.6572\n",
            "422/1001, train_loss: 0.0780, step time: 0.6525\n",
            "423/1001, train_loss: 0.1046, step time: 0.6707\n",
            "424/1001, train_loss: 0.0341, step time: 0.6757\n",
            "425/1001, train_loss: 0.7970, step time: 0.6542\n",
            "426/1001, train_loss: 0.1076, step time: 0.6684\n",
            "427/1001, train_loss: 0.0970, step time: 0.6600\n",
            "428/1001, train_loss: 0.7993, step time: 0.6756\n",
            "429/1001, train_loss: 0.1719, step time: 0.6575\n",
            "430/1001, train_loss: 0.0302, step time: 0.6489\n",
            "431/1001, train_loss: 0.1838, step time: 0.6559\n",
            "432/1001, train_loss: 0.0746, step time: 0.6573\n",
            "433/1001, train_loss: 0.0542, step time: 0.6580\n",
            "434/1001, train_loss: 0.1842, step time: 0.6585\n",
            "435/1001, train_loss: 0.1588, step time: 0.6544\n",
            "436/1001, train_loss: 0.1519, step time: 0.6570\n",
            "437/1001, train_loss: 0.2112, step time: 0.6572\n",
            "438/1001, train_loss: 0.4254, step time: 0.6557\n",
            "439/1001, train_loss: 0.0304, step time: 0.6743\n",
            "440/1001, train_loss: 0.0912, step time: 0.6533\n",
            "441/1001, train_loss: 0.1575, step time: 0.6766\n",
            "442/1001, train_loss: 0.0313, step time: 0.6664\n",
            "443/1001, train_loss: 0.0445, step time: 0.6525\n",
            "444/1001, train_loss: 0.0289, step time: 0.6480\n",
            "445/1001, train_loss: 0.0928, step time: 0.6583\n",
            "446/1001, train_loss: 0.4857, step time: 0.6519\n",
            "447/1001, train_loss: 0.5032, step time: 0.6784\n",
            "448/1001, train_loss: 0.6993, step time: 0.6591\n",
            "449/1001, train_loss: 0.7470, step time: 0.6734\n",
            "450/1001, train_loss: 0.1153, step time: 0.6664\n",
            "451/1001, train_loss: 0.0429, step time: 0.6799\n",
            "452/1001, train_loss: 0.1443, step time: 0.6867\n",
            "453/1001, train_loss: 0.1898, step time: 0.6529\n",
            "454/1001, train_loss: 0.0860, step time: 0.6548\n",
            "455/1001, train_loss: 0.7076, step time: 0.6482\n",
            "456/1001, train_loss: 0.1208, step time: 0.6531\n",
            "457/1001, train_loss: 0.7694, step time: 0.6629\n",
            "458/1001, train_loss: 0.1175, step time: 0.6533\n",
            "459/1001, train_loss: 0.1139, step time: 0.6581\n",
            "460/1001, train_loss: 0.3839, step time: 0.6895\n",
            "461/1001, train_loss: 0.1118, step time: 0.6662\n",
            "462/1001, train_loss: 0.2167, step time: 0.6515\n",
            "463/1001, train_loss: 0.0933, step time: 0.6625\n",
            "464/1001, train_loss: 0.1540, step time: 0.6551\n",
            "465/1001, train_loss: 0.0665, step time: 0.6587\n",
            "466/1001, train_loss: 0.4642, step time: 0.6758\n",
            "467/1001, train_loss: 0.0374, step time: 0.6649\n",
            "468/1001, train_loss: 0.0682, step time: 0.6534\n",
            "469/1001, train_loss: 0.3256, step time: 0.6774\n",
            "470/1001, train_loss: 0.0842, step time: 0.6544\n",
            "471/1001, train_loss: 0.7314, step time: 0.6588\n",
            "472/1001, train_loss: 0.0398, step time: 0.6536\n",
            "473/1001, train_loss: 0.0510, step time: 0.6722\n",
            "474/1001, train_loss: 0.0622, step time: 0.6740\n",
            "475/1001, train_loss: 0.0557, step time: 0.6579\n",
            "476/1001, train_loss: 0.0481, step time: 0.6556\n",
            "477/1001, train_loss: 0.0459, step time: 0.6535\n",
            "478/1001, train_loss: 0.0424, step time: 0.6848\n",
            "479/1001, train_loss: 0.0581, step time: 0.6565\n",
            "480/1001, train_loss: 0.0297, step time: 0.6519\n",
            "481/1001, train_loss: 0.7096, step time: 0.6548\n",
            "482/1001, train_loss: 0.0672, step time: 0.6741\n",
            "483/1001, train_loss: 0.0617, step time: 0.6548\n",
            "484/1001, train_loss: 0.1163, step time: 0.6632\n",
            "485/1001, train_loss: 0.6280, step time: 0.6529\n",
            "486/1001, train_loss: 0.0350, step time: 0.6538\n",
            "487/1001, train_loss: 0.0631, step time: 0.6510\n",
            "488/1001, train_loss: 0.0989, step time: 0.6518\n",
            "489/1001, train_loss: 0.0786, step time: 0.6672\n",
            "490/1001, train_loss: 0.0998, step time: 0.6578\n",
            "491/1001, train_loss: 0.1668, step time: 0.6763\n",
            "492/1001, train_loss: 0.0689, step time: 0.6825\n",
            "493/1001, train_loss: 0.4293, step time: 0.6552\n",
            "494/1001, train_loss: 1.0000, step time: 0.6722\n",
            "495/1001, train_loss: 0.2029, step time: 0.6543\n",
            "496/1001, train_loss: 0.0472, step time: 0.6548\n",
            "497/1001, train_loss: 0.0451, step time: 0.6536\n",
            "498/1001, train_loss: 0.6929, step time: 0.6513\n",
            "499/1001, train_loss: 0.0947, step time: 0.6524\n",
            "500/1001, train_loss: 0.2368, step time: 0.6569\n",
            "501/1001, train_loss: 0.0699, step time: 0.6525\n",
            "502/1001, train_loss: 0.9978, step time: 0.6445\n",
            "503/1001, train_loss: 0.0384, step time: 0.6485\n",
            "504/1001, train_loss: 0.4593, step time: 0.6515\n",
            "505/1001, train_loss: 0.0766, step time: 0.6538\n",
            "506/1001, train_loss: 1.0000, step time: 0.6264\n",
            "507/1001, train_loss: 0.1511, step time: 0.6522\n",
            "508/1001, train_loss: 0.0388, step time: 0.6540\n",
            "509/1001, train_loss: 0.1921, step time: 0.6556\n",
            "510/1001, train_loss: 0.0705, step time: 0.6531\n",
            "511/1001, train_loss: 0.0564, step time: 0.6500\n",
            "512/1001, train_loss: 0.1114, step time: 0.6519\n",
            "513/1001, train_loss: 1.0000, step time: 0.6364\n",
            "514/1001, train_loss: 0.8526, step time: 0.6772\n",
            "515/1001, train_loss: 0.0641, step time: 0.6526\n",
            "516/1001, train_loss: 0.0350, step time: 0.6504\n",
            "517/1001, train_loss: 0.0907, step time: 0.6495\n",
            "518/1001, train_loss: 1.0000, step time: 0.6241\n",
            "519/1001, train_loss: 0.0555, step time: 0.6517\n",
            "520/1001, train_loss: 0.0506, step time: 0.6560\n",
            "521/1001, train_loss: 0.0660, step time: 0.6514\n",
            "522/1001, train_loss: 0.1208, step time: 0.6744\n",
            "523/1001, train_loss: 0.0317, step time: 0.6975\n",
            "524/1001, train_loss: 0.1265, step time: 0.6540\n",
            "525/1001, train_loss: 0.1214, step time: 0.6551\n",
            "526/1001, train_loss: 0.3343, step time: 0.6539\n",
            "527/1001, train_loss: 0.0897, step time: 0.6674\n",
            "528/1001, train_loss: 0.0587, step time: 0.6494\n",
            "529/1001, train_loss: 0.0644, step time: 0.6547\n",
            "530/1001, train_loss: 0.7317, step time: 0.6724\n",
            "531/1001, train_loss: 0.0363, step time: 0.6547\n",
            "532/1001, train_loss: 0.2354, step time: 0.6692\n",
            "533/1001, train_loss: 0.0423, step time: 0.6510\n",
            "534/1001, train_loss: 0.0365, step time: 0.6653\n",
            "535/1001, train_loss: 0.0874, step time: 0.6834\n",
            "536/1001, train_loss: 0.0427, step time: 0.6510\n",
            "537/1001, train_loss: 0.0899, step time: 0.6626\n",
            "538/1001, train_loss: 0.2841, step time: 0.6529\n",
            "539/1001, train_loss: 0.7214, step time: 0.6672\n",
            "540/1001, train_loss: 0.3453, step time: 0.6684\n",
            "541/1001, train_loss: 0.1508, step time: 0.6534\n",
            "542/1001, train_loss: 0.0449, step time: 0.6845\n",
            "543/1001, train_loss: 0.2938, step time: 0.6725\n",
            "544/1001, train_loss: 0.8466, step time: 0.6520\n",
            "545/1001, train_loss: 0.0898, step time: 0.6510\n",
            "546/1001, train_loss: 0.0615, step time: 0.6997\n",
            "547/1001, train_loss: 0.0613, step time: 0.6648\n",
            "548/1001, train_loss: 0.1061, step time: 0.6507\n",
            "549/1001, train_loss: 0.0329, step time: 0.6663\n",
            "550/1001, train_loss: 0.0337, step time: 0.6746\n",
            "551/1001, train_loss: 0.7423, step time: 0.6726\n",
            "552/1001, train_loss: 0.0305, step time: 0.6519\n",
            "553/1001, train_loss: 0.0641, step time: 0.6552\n",
            "554/1001, train_loss: 0.0685, step time: 0.6515\n",
            "555/1001, train_loss: 0.0424, step time: 0.6543\n",
            "556/1001, train_loss: 0.0755, step time: 0.6543\n",
            "557/1001, train_loss: 0.5005, step time: 0.6790\n",
            "558/1001, train_loss: 0.8849, step time: 0.6712\n",
            "559/1001, train_loss: 0.0663, step time: 0.6527\n",
            "560/1001, train_loss: 0.1130, step time: 0.6495\n",
            "561/1001, train_loss: 0.3973, step time: 0.6515\n",
            "562/1001, train_loss: 0.0718, step time: 0.6495\n",
            "563/1001, train_loss: 0.4762, step time: 0.6750\n",
            "564/1001, train_loss: 0.0351, step time: 0.6517\n",
            "565/1001, train_loss: 0.0344, step time: 0.6818\n",
            "566/1001, train_loss: 0.4271, step time: 0.6808\n",
            "567/1001, train_loss: 0.1022, step time: 0.6688\n",
            "568/1001, train_loss: 0.1291, step time: 0.6735\n",
            "569/1001, train_loss: 0.9010, step time: 0.6629\n",
            "570/1001, train_loss: 0.3023, step time: 0.6523\n",
            "571/1001, train_loss: 0.0386, step time: 0.6488\n",
            "572/1001, train_loss: 0.8059, step time: 0.6872\n",
            "573/1001, train_loss: 0.0640, step time: 0.6700\n",
            "574/1001, train_loss: 0.1708, step time: 0.6532\n",
            "575/1001, train_loss: 0.7779, step time: 0.6525\n",
            "576/1001, train_loss: 0.0346, step time: 0.6560\n",
            "577/1001, train_loss: 0.1460, step time: 0.6537\n",
            "578/1001, train_loss: 0.0718, step time: 0.6539\n",
            "579/1001, train_loss: 0.3472, step time: 0.6521\n",
            "580/1001, train_loss: 0.0502, step time: 0.6545\n",
            "581/1001, train_loss: 0.1139, step time: 0.6508\n",
            "582/1001, train_loss: 0.2139, step time: 0.6516\n",
            "583/1001, train_loss: 0.0330, step time: 0.6540\n",
            "584/1001, train_loss: 0.0909, step time: 0.6535\n",
            "585/1001, train_loss: 0.0693, step time: 0.6570\n",
            "586/1001, train_loss: 1.0000, step time: 0.6249\n",
            "587/1001, train_loss: 0.0321, step time: 0.6546\n",
            "588/1001, train_loss: 0.0536, step time: 0.6505\n",
            "589/1001, train_loss: 0.3809, step time: 0.6558\n",
            "590/1001, train_loss: 0.2464, step time: 0.6561\n",
            "591/1001, train_loss: 0.0485, step time: 0.6498\n",
            "592/1001, train_loss: 0.0526, step time: 0.6516\n",
            "593/1001, train_loss: 1.0000, step time: 0.6219\n",
            "594/1001, train_loss: 0.1277, step time: 0.6860\n",
            "595/1001, train_loss: 0.0521, step time: 0.6511\n",
            "596/1001, train_loss: 0.0723, step time: 0.6502\n",
            "597/1001, train_loss: 0.0289, step time: 0.6568\n",
            "598/1001, train_loss: 0.0570, step time: 0.6632\n",
            "599/1001, train_loss: 0.6956, step time: 0.6699\n",
            "600/1001, train_loss: 0.1025, step time: 0.6613\n",
            "601/1001, train_loss: 0.0215, step time: 0.6639\n",
            "602/1001, train_loss: 0.1828, step time: 0.6612\n",
            "603/1001, train_loss: 0.3694, step time: 0.6522\n",
            "604/1001, train_loss: 0.0857, step time: 0.6567\n",
            "605/1001, train_loss: 0.1021, step time: 0.6665\n",
            "606/1001, train_loss: 0.1399, step time: 0.6589\n",
            "607/1001, train_loss: 0.8524, step time: 0.6575\n",
            "608/1001, train_loss: 0.4307, step time: 0.6525\n",
            "609/1001, train_loss: 0.0474, step time: 0.6499\n",
            "610/1001, train_loss: 0.0242, step time: 0.6498\n",
            "611/1001, train_loss: 0.0305, step time: 0.6542\n",
            "612/1001, train_loss: 0.2001, step time: 0.6816\n",
            "613/1001, train_loss: 0.6214, step time: 0.6547\n",
            "614/1001, train_loss: 0.1022, step time: 0.6677\n",
            "615/1001, train_loss: 0.0485, step time: 0.6677\n",
            "616/1001, train_loss: 0.2387, step time: 0.6681\n",
            "617/1001, train_loss: 0.0523, step time: 0.6846\n",
            "618/1001, train_loss: 0.6527, step time: 0.6835\n",
            "619/1001, train_loss: 0.1591, step time: 0.6511\n",
            "620/1001, train_loss: 0.0731, step time: 0.6557\n",
            "621/1001, train_loss: 0.0605, step time: 0.6533\n",
            "622/1001, train_loss: 0.7629, step time: 0.6608\n",
            "623/1001, train_loss: 0.0522, step time: 0.6493\n",
            "624/1001, train_loss: 0.0302, step time: 0.6474\n",
            "625/1001, train_loss: 0.0979, step time: 0.6507\n",
            "626/1001, train_loss: 0.0673, step time: 0.6563\n",
            "627/1001, train_loss: 0.4596, step time: 0.6528\n",
            "628/1001, train_loss: 0.0608, step time: 0.6556\n",
            "629/1001, train_loss: 0.0546, step time: 0.6551\n",
            "630/1001, train_loss: 0.1541, step time: 0.6528\n",
            "631/1001, train_loss: 0.0647, step time: 0.6522\n",
            "632/1001, train_loss: 0.0588, step time: 0.6547\n",
            "633/1001, train_loss: 1.0000, step time: 0.6267\n",
            "634/1001, train_loss: 0.0959, step time: 0.6517\n",
            "635/1001, train_loss: 0.0526, step time: 0.6515\n",
            "636/1001, train_loss: 0.1135, step time: 0.6825\n",
            "637/1001, train_loss: 0.0713, step time: 0.6570\n",
            "638/1001, train_loss: 0.3849, step time: 0.6678\n",
            "639/1001, train_loss: 1.0000, step time: 0.6294\n",
            "640/1001, train_loss: 0.9679, step time: 0.6650\n",
            "641/1001, train_loss: 0.2067, step time: 0.6752\n",
            "642/1001, train_loss: 0.1022, step time: 0.6591\n",
            "643/1001, train_loss: 0.1177, step time: 0.6525\n",
            "644/1001, train_loss: 1.0000, step time: 0.6247\n",
            "645/1001, train_loss: 0.0709, step time: 0.6517\n",
            "646/1001, train_loss: 0.1350, step time: 0.6633\n",
            "647/1001, train_loss: 0.0446, step time: 0.6488\n",
            "648/1001, train_loss: 0.0485, step time: 0.6507\n",
            "649/1001, train_loss: 0.0482, step time: 0.6616\n",
            "650/1001, train_loss: 0.0535, step time: 0.6917\n",
            "651/1001, train_loss: 1.0000, step time: 0.6481\n",
            "652/1001, train_loss: 0.0358, step time: 0.6497\n",
            "653/1001, train_loss: 0.0485, step time: 0.6518\n",
            "654/1001, train_loss: 0.1902, step time: 0.6561\n",
            "655/1001, train_loss: 0.4436, step time: 0.6543\n",
            "656/1001, train_loss: 0.0481, step time: 0.6631\n",
            "657/1001, train_loss: 0.0902, step time: 0.6511\n",
            "658/1001, train_loss: 0.1079, step time: 0.6566\n",
            "659/1001, train_loss: 0.0366, step time: 0.6508\n",
            "660/1001, train_loss: 0.0663, step time: 0.6470\n",
            "661/1001, train_loss: 0.0349, step time: 0.6694\n",
            "662/1001, train_loss: 0.0797, step time: 0.6538\n",
            "663/1001, train_loss: 0.0749, step time: 0.6507\n",
            "664/1001, train_loss: 0.1445, step time: 0.6557\n",
            "665/1001, train_loss: 0.1676, step time: 0.6684\n",
            "666/1001, train_loss: 0.6813, step time: 0.6793\n",
            "667/1001, train_loss: 0.1158, step time: 0.6531\n",
            "668/1001, train_loss: 0.0524, step time: 0.6545\n",
            "669/1001, train_loss: 1.0000, step time: 0.6238\n",
            "670/1001, train_loss: 1.0000, step time: 0.6288\n",
            "671/1001, train_loss: 0.0622, step time: 0.6911\n",
            "672/1001, train_loss: 0.0597, step time: 0.6603\n",
            "673/1001, train_loss: 0.8404, step time: 0.6763\n",
            "674/1001, train_loss: 0.4161, step time: 0.6741\n",
            "675/1001, train_loss: 0.0795, step time: 0.6695\n",
            "676/1001, train_loss: 0.1391, step time: 0.6545\n",
            "677/1001, train_loss: 0.6744, step time: 0.6644\n",
            "678/1001, train_loss: 0.0921, step time: 0.6564\n",
            "679/1001, train_loss: 0.0788, step time: 0.6510\n",
            "680/1001, train_loss: 0.0925, step time: 0.6487\n",
            "681/1001, train_loss: 0.0469, step time: 0.6771\n",
            "682/1001, train_loss: 0.0608, step time: 0.6508\n",
            "683/1001, train_loss: 0.1103, step time: 0.6574\n",
            "684/1001, train_loss: 0.4111, step time: 0.6783\n",
            "685/1001, train_loss: 1.0000, step time: 0.7594\n",
            "686/1001, train_loss: 0.1950, step time: 0.6530\n",
            "687/1001, train_loss: 0.0490, step time: 0.6504\n",
            "688/1001, train_loss: 0.0375, step time: 0.6617\n",
            "689/1001, train_loss: 0.0525, step time: 0.6500\n",
            "690/1001, train_loss: 0.0596, step time: 0.6510\n",
            "691/1001, train_loss: 0.1593, step time: 0.6568\n",
            "692/1001, train_loss: 0.6797, step time: 0.6825\n",
            "693/1001, train_loss: 0.0840, step time: 0.6672\n",
            "694/1001, train_loss: 0.0456, step time: 0.6497\n",
            "695/1001, train_loss: 0.8884, step time: 0.6523\n",
            "696/1001, train_loss: 0.0528, step time: 0.6563\n",
            "697/1001, train_loss: 0.0468, step time: 0.6509\n",
            "698/1001, train_loss: 0.1245, step time: 0.6737\n",
            "699/1001, train_loss: 0.0617, step time: 0.6555\n",
            "700/1001, train_loss: 0.1844, step time: 0.6542\n",
            "701/1001, train_loss: 0.0875, step time: 0.6516\n",
            "702/1001, train_loss: 0.0834, step time: 0.6555\n",
            "703/1001, train_loss: 0.9947, step time: 0.6497\n",
            "704/1001, train_loss: 0.0800, step time: 0.6487\n",
            "705/1001, train_loss: 0.0504, step time: 0.6569\n",
            "706/1001, train_loss: 0.6842, step time: 0.6704\n",
            "707/1001, train_loss: 0.0635, step time: 0.6567\n",
            "708/1001, train_loss: 0.4082, step time: 0.6842\n",
            "709/1001, train_loss: 0.0321, step time: 0.6732\n",
            "710/1001, train_loss: 0.0557, step time: 0.6854\n",
            "711/1001, train_loss: 0.7112, step time: 0.6662\n",
            "712/1001, train_loss: 0.1493, step time: 0.6529\n",
            "713/1001, train_loss: 0.0675, step time: 0.6513\n",
            "714/1001, train_loss: 0.6757, step time: 0.6482\n",
            "715/1001, train_loss: 0.0673, step time: 0.6513\n",
            "716/1001, train_loss: 0.1322, step time: 0.6780\n",
            "717/1001, train_loss: 0.0923, step time: 0.6644\n",
            "718/1001, train_loss: 0.0494, step time: 0.6752\n",
            "719/1001, train_loss: 1.0000, step time: 0.6284\n",
            "720/1001, train_loss: 0.0250, step time: 0.6534\n",
            "721/1001, train_loss: 0.1505, step time: 0.6582\n",
            "722/1001, train_loss: 0.0614, step time: 0.6513\n",
            "723/1001, train_loss: 0.3775, step time: 0.6505\n",
            "724/1001, train_loss: 0.0401, step time: 0.6545\n",
            "725/1001, train_loss: 0.9733, step time: 0.6530\n",
            "726/1001, train_loss: 0.1442, step time: 0.6610\n",
            "727/1001, train_loss: 0.1873, step time: 0.6757\n",
            "728/1001, train_loss: 0.2381, step time: 0.6562\n",
            "729/1001, train_loss: 0.0707, step time: 0.6627\n",
            "730/1001, train_loss: 0.0241, step time: 0.6585\n",
            "731/1001, train_loss: 0.0558, step time: 0.6651\n",
            "732/1001, train_loss: 0.4641, step time: 0.6515\n",
            "733/1001, train_loss: 0.8939, step time: 0.6633\n",
            "734/1001, train_loss: 0.6232, step time: 0.6519\n",
            "735/1001, train_loss: 0.0730, step time: 0.6514\n",
            "736/1001, train_loss: 0.1003, step time: 0.6679\n",
            "737/1001, train_loss: 0.1204, step time: 0.6524\n",
            "738/1001, train_loss: 0.0973, step time: 0.6688\n",
            "739/1001, train_loss: 0.1139, step time: 0.6550\n",
            "740/1001, train_loss: 0.1289, step time: 0.6524\n",
            "741/1001, train_loss: 0.0632, step time: 0.6557\n",
            "742/1001, train_loss: 0.9856, step time: 0.6518\n",
            "743/1001, train_loss: 1.0000, step time: 0.6423\n",
            "744/1001, train_loss: 1.0000, step time: 0.6304\n",
            "745/1001, train_loss: 0.0789, step time: 0.6521\n",
            "746/1001, train_loss: 0.0949, step time: 0.6508\n",
            "747/1001, train_loss: 1.0000, step time: 0.6277\n",
            "748/1001, train_loss: 0.0578, step time: 0.6480\n",
            "749/1001, train_loss: 0.0435, step time: 0.6751\n",
            "750/1001, train_loss: 0.0328, step time: 0.6535\n",
            "751/1001, train_loss: 0.0542, step time: 0.6755\n",
            "752/1001, train_loss: 0.1754, step time: 0.6551\n",
            "753/1001, train_loss: 0.9839, step time: 0.6575\n",
            "754/1001, train_loss: 0.0585, step time: 0.6534\n",
            "755/1001, train_loss: 0.0476, step time: 0.6538\n",
            "756/1001, train_loss: 0.0681, step time: 0.6774\n",
            "757/1001, train_loss: 0.0519, step time: 0.6553\n",
            "758/1001, train_loss: 1.0000, step time: 0.6226\n",
            "759/1001, train_loss: 0.0824, step time: 0.6550\n",
            "760/1001, train_loss: 0.0330, step time: 0.6515\n",
            "761/1001, train_loss: 0.0901, step time: 0.6552\n",
            "762/1001, train_loss: 0.1262, step time: 0.6591\n",
            "763/1001, train_loss: 0.0404, step time: 0.6498\n",
            "764/1001, train_loss: 0.2033, step time: 0.6526\n",
            "765/1001, train_loss: 0.0665, step time: 0.6502\n",
            "766/1001, train_loss: 0.1075, step time: 0.6526\n",
            "767/1001, train_loss: 0.0977, step time: 0.6669\n",
            "768/1001, train_loss: 0.0952, step time: 0.6549\n",
            "769/1001, train_loss: 0.1089, step time: 0.6899\n",
            "770/1001, train_loss: 0.0610, step time: 0.6726\n",
            "771/1001, train_loss: 0.2234, step time: 0.6697\n",
            "772/1001, train_loss: 0.1898, step time: 0.6611\n",
            "773/1001, train_loss: 0.0424, step time: 0.6562\n",
            "774/1001, train_loss: 0.0441, step time: 0.6870\n",
            "775/1001, train_loss: 0.1555, step time: 0.6516\n",
            "776/1001, train_loss: 0.1650, step time: 0.6527\n",
            "777/1001, train_loss: 0.1023, step time: 0.6521\n",
            "778/1001, train_loss: 0.0402, step time: 0.6587\n",
            "779/1001, train_loss: 0.7699, step time: 0.6571\n",
            "780/1001, train_loss: 0.0329, step time: 0.6570\n",
            "781/1001, train_loss: 0.0789, step time: 0.6502\n",
            "782/1001, train_loss: 0.0586, step time: 0.6526\n",
            "783/1001, train_loss: 0.0491, step time: 0.6528\n",
            "784/1001, train_loss: 0.7817, step time: 0.6562\n",
            "785/1001, train_loss: 0.0775, step time: 0.6501\n",
            "786/1001, train_loss: 0.0836, step time: 0.6515\n",
            "787/1001, train_loss: 0.1135, step time: 0.6551\n",
            "788/1001, train_loss: 0.1958, step time: 0.6527\n",
            "789/1001, train_loss: 0.2410, step time: 0.6524\n",
            "790/1001, train_loss: 0.0450, step time: 0.6852\n",
            "791/1001, train_loss: 0.7000, step time: 0.6640\n",
            "792/1001, train_loss: 0.0588, step time: 0.6512\n",
            "793/1001, train_loss: 0.0806, step time: 0.6652\n",
            "794/1001, train_loss: 0.9618, step time: 0.6542\n",
            "795/1001, train_loss: 1.0000, step time: 0.6233\n",
            "796/1001, train_loss: 0.1899, step time: 0.6794\n",
            "797/1001, train_loss: 0.0633, step time: 0.6583\n",
            "798/1001, train_loss: 0.0640, step time: 0.6578\n",
            "799/1001, train_loss: 0.1139, step time: 0.6539\n",
            "800/1001, train_loss: 0.0796, step time: 0.6558\n",
            "801/1001, train_loss: 0.4154, step time: 0.6601\n",
            "802/1001, train_loss: 0.6989, step time: 0.6518\n",
            "803/1001, train_loss: 0.9999, step time: 0.6543\n",
            "804/1001, train_loss: 0.0574, step time: 0.6618\n",
            "805/1001, train_loss: 0.0611, step time: 0.6506\n",
            "806/1001, train_loss: 0.1006, step time: 0.6656\n",
            "807/1001, train_loss: 0.0373, step time: 0.6678\n",
            "808/1001, train_loss: 0.2260, step time: 0.6529\n",
            "809/1001, train_loss: 0.0477, step time: 0.6522\n",
            "810/1001, train_loss: 0.1122, step time: 0.6541\n",
            "811/1001, train_loss: 0.0353, step time: 0.6601\n",
            "812/1001, train_loss: 1.0000, step time: 0.6331\n",
            "813/1001, train_loss: 0.1140, step time: 0.6725\n",
            "814/1001, train_loss: 0.8550, step time: 0.6541\n",
            "815/1001, train_loss: 1.0000, step time: 0.6426\n",
            "816/1001, train_loss: 0.1624, step time: 0.6605\n",
            "817/1001, train_loss: 0.0841, step time: 0.6509\n",
            "818/1001, train_loss: 0.1943, step time: 0.6748\n",
            "819/1001, train_loss: 0.0391, step time: 0.6558\n",
            "820/1001, train_loss: 0.0680, step time: 0.6553\n",
            "821/1001, train_loss: 0.0785, step time: 0.6546\n",
            "822/1001, train_loss: 0.8087, step time: 0.6556\n",
            "823/1001, train_loss: 1.0000, step time: 0.6290\n",
            "824/1001, train_loss: 0.0565, step time: 0.6583\n",
            "825/1001, train_loss: 1.0000, step time: 0.6598\n",
            "826/1001, train_loss: 0.0484, step time: 0.6724\n",
            "827/1001, train_loss: 1.0000, step time: 0.6489\n",
            "828/1001, train_loss: 0.0300, step time: 0.6485\n",
            "829/1001, train_loss: 0.0392, step time: 0.6528\n",
            "830/1001, train_loss: 0.0631, step time: 0.6579\n",
            "831/1001, train_loss: 0.1056, step time: 0.6569\n",
            "832/1001, train_loss: 0.0621, step time: 0.6550\n",
            "833/1001, train_loss: 0.0525, step time: 0.6560\n",
            "834/1001, train_loss: 0.0428, step time: 0.6521\n",
            "835/1001, train_loss: 0.0248, step time: 0.6558\n",
            "836/1001, train_loss: 0.0643, step time: 0.6513\n",
            "837/1001, train_loss: 0.0697, step time: 0.6524\n",
            "838/1001, train_loss: 0.0442, step time: 0.6502\n",
            "839/1001, train_loss: 0.0811, step time: 0.6557\n",
            "840/1001, train_loss: 0.1116, step time: 0.6793\n",
            "841/1001, train_loss: 0.1531, step time: 0.6651\n",
            "842/1001, train_loss: 0.0569, step time: 0.6550\n",
            "843/1001, train_loss: 0.0482, step time: 0.6490\n",
            "844/1001, train_loss: 0.1052, step time: 0.6671\n",
            "845/1001, train_loss: 0.8782, step time: 0.6528\n",
            "846/1001, train_loss: 0.0839, step time: 0.6526\n",
            "847/1001, train_loss: 0.7967, step time: 0.6778\n",
            "848/1001, train_loss: 1.0000, step time: 0.6238\n",
            "849/1001, train_loss: 0.4533, step time: 0.6548\n",
            "850/1001, train_loss: 0.1923, step time: 0.6653\n",
            "851/1001, train_loss: 0.8942, step time: 0.6532\n",
            "852/1001, train_loss: 0.2834, step time: 0.6792\n",
            "853/1001, train_loss: 0.0871, step time: 0.6592\n",
            "854/1001, train_loss: 0.7008, step time: 0.6468\n",
            "855/1001, train_loss: 0.1040, step time: 0.6797\n",
            "856/1001, train_loss: 0.7586, step time: 0.6655\n",
            "857/1001, train_loss: 0.0823, step time: 0.6522\n",
            "858/1001, train_loss: 0.4367, step time: 0.6527\n",
            "859/1001, train_loss: 0.0347, step time: 0.6512\n",
            "860/1001, train_loss: 0.0875, step time: 0.6496\n",
            "861/1001, train_loss: 0.0660, step time: 0.6562\n",
            "862/1001, train_loss: 0.8172, step time: 0.6804\n",
            "863/1001, train_loss: 0.0721, step time: 0.6621\n",
            "864/1001, train_loss: 0.0465, step time: 0.6518\n",
            "865/1001, train_loss: 0.4830, step time: 0.6559\n",
            "866/1001, train_loss: 1.0000, step time: 0.6257\n",
            "867/1001, train_loss: 0.2530, step time: 0.6536\n",
            "868/1001, train_loss: 0.1140, step time: 0.6544\n",
            "869/1001, train_loss: 0.0361, step time: 0.6488\n",
            "870/1001, train_loss: 0.0688, step time: 0.6498\n",
            "871/1001, train_loss: 0.0412, step time: 0.6530\n",
            "872/1001, train_loss: 0.0519, step time: 0.6572\n",
            "873/1001, train_loss: 0.4944, step time: 0.6521\n",
            "874/1001, train_loss: 1.0000, step time: 0.6257\n",
            "875/1001, train_loss: 0.2368, step time: 0.6509\n",
            "876/1001, train_loss: 0.7594, step time: 0.6495\n",
            "877/1001, train_loss: 0.0323, step time: 0.6757\n",
            "878/1001, train_loss: 0.2662, step time: 0.6529\n",
            "879/1001, train_loss: 1.0000, step time: 0.6403\n",
            "880/1001, train_loss: 0.1218, step time: 0.6542\n",
            "881/1001, train_loss: 0.0435, step time: 0.6598\n",
            "882/1001, train_loss: 0.1300, step time: 0.6512\n",
            "883/1001, train_loss: 0.1664, step time: 0.6523\n",
            "884/1001, train_loss: 0.0900, step time: 0.6503\n",
            "885/1001, train_loss: 0.1364, step time: 0.6519\n",
            "886/1001, train_loss: 0.5992, step time: 0.6544\n",
            "887/1001, train_loss: 0.3206, step time: 0.6934\n",
            "888/1001, train_loss: 0.0404, step time: 0.6584\n",
            "889/1001, train_loss: 0.1386, step time: 0.6558\n",
            "890/1001, train_loss: 0.0335, step time: 0.6530\n",
            "891/1001, train_loss: 0.0788, step time: 0.6519\n",
            "892/1001, train_loss: 0.9744, step time: 0.6529\n",
            "893/1001, train_loss: 0.0547, step time: 0.6737\n",
            "894/1001, train_loss: 0.1079, step time: 0.6516\n",
            "895/1001, train_loss: 0.0461, step time: 0.6506\n",
            "896/1001, train_loss: 0.1465, step time: 0.6522\n",
            "897/1001, train_loss: 0.0482, step time: 0.6511\n",
            "898/1001, train_loss: 0.6820, step time: 0.6579\n",
            "899/1001, train_loss: 0.1179, step time: 0.6516\n",
            "900/1001, train_loss: 0.8487, step time: 0.6528\n",
            "901/1001, train_loss: 0.7063, step time: 0.6550\n",
            "902/1001, train_loss: 0.1225, step time: 0.6638\n",
            "903/1001, train_loss: 1.0000, step time: 0.6288\n",
            "904/1001, train_loss: 0.1133, step time: 0.6522\n",
            "905/1001, train_loss: 1.0000, step time: 0.6476\n",
            "906/1001, train_loss: 0.1914, step time: 0.6831\n",
            "907/1001, train_loss: 0.7910, step time: 0.6561\n",
            "908/1001, train_loss: 0.1146, step time: 0.6526\n",
            "909/1001, train_loss: 0.0565, step time: 0.6632\n",
            "910/1001, train_loss: 0.0507, step time: 0.6578\n",
            "911/1001, train_loss: 0.1358, step time: 0.6726\n",
            "912/1001, train_loss: 0.0668, step time: 0.6563\n",
            "913/1001, train_loss: 0.9324, step time: 0.6531\n",
            "914/1001, train_loss: 0.1771, step time: 0.6548\n",
            "915/1001, train_loss: 0.0578, step time: 0.6568\n",
            "916/1001, train_loss: 0.6693, step time: 0.6636\n",
            "917/1001, train_loss: 0.0859, step time: 0.6655\n",
            "918/1001, train_loss: 0.0938, step time: 0.6671\n",
            "919/1001, train_loss: 0.7232, step time: 0.6506\n",
            "920/1001, train_loss: 0.9298, step time: 0.6579\n",
            "921/1001, train_loss: 0.1233, step time: 0.6557\n",
            "922/1001, train_loss: 0.2865, step time: 0.6526\n",
            "923/1001, train_loss: 0.6762, step time: 0.6526\n",
            "924/1001, train_loss: 0.9583, step time: 0.6555\n",
            "925/1001, train_loss: 0.2665, step time: 0.6799\n",
            "926/1001, train_loss: 0.0690, step time: 0.6564\n",
            "927/1001, train_loss: 0.0798, step time: 0.6510\n",
            "928/1001, train_loss: 0.9905, step time: 0.6582\n",
            "929/1001, train_loss: 1.0000, step time: 0.6285\n",
            "930/1001, train_loss: 0.0416, step time: 0.6506\n",
            "931/1001, train_loss: 0.7720, step time: 0.6775\n",
            "932/1001, train_loss: 0.2964, step time: 0.6528\n",
            "933/1001, train_loss: 0.1585, step time: 0.6560\n",
            "934/1001, train_loss: 0.0828, step time: 0.6536\n",
            "935/1001, train_loss: 0.1806, step time: 0.6683\n",
            "936/1001, train_loss: 0.7160, step time: 0.7068\n",
            "937/1001, train_loss: 0.9962, step time: 0.6596\n",
            "938/1001, train_loss: 0.1505, step time: 0.6540\n",
            "939/1001, train_loss: 0.0712, step time: 0.6521\n",
            "940/1001, train_loss: 0.7306, step time: 0.6506\n",
            "941/1001, train_loss: 0.0627, step time: 0.6535\n",
            "942/1001, train_loss: 0.2147, step time: 0.6673\n",
            "943/1001, train_loss: 0.0739, step time: 0.6530\n",
            "944/1001, train_loss: 0.0505, step time: 0.6523\n",
            "945/1001, train_loss: 0.0243, step time: 0.6526\n",
            "946/1001, train_loss: 0.7717, step time: 0.6554\n",
            "947/1001, train_loss: 0.0585, step time: 0.6671\n",
            "948/1001, train_loss: 0.0719, step time: 0.6575\n",
            "949/1001, train_loss: 0.4537, step time: 0.6581\n",
            "950/1001, train_loss: 0.2147, step time: 0.6705\n",
            "951/1001, train_loss: 0.0963, step time: 0.6559\n",
            "952/1001, train_loss: 0.2183, step time: 0.6529\n",
            "953/1001, train_loss: 0.3024, step time: 0.6605\n",
            "954/1001, train_loss: 0.0516, step time: 0.6457\n",
            "955/1001, train_loss: 0.3435, step time: 0.6581\n",
            "956/1001, train_loss: 0.3071, step time: 0.6891\n",
            "957/1001, train_loss: 0.0514, step time: 0.6531\n",
            "958/1001, train_loss: 0.6857, step time: 0.6901\n",
            "959/1001, train_loss: 0.0911, step time: 0.6540\n",
            "960/1001, train_loss: 0.2043, step time: 0.6514\n",
            "961/1001, train_loss: 0.1919, step time: 0.6533\n",
            "962/1001, train_loss: 0.7347, step time: 0.6571\n",
            "963/1001, train_loss: 0.7316, step time: 0.6617\n",
            "964/1001, train_loss: 0.1378, step time: 0.6837\n",
            "965/1001, train_loss: 0.0486, step time: 0.6531\n",
            "966/1001, train_loss: 0.0700, step time: 0.6508\n",
            "967/1001, train_loss: 0.0387, step time: 0.6568\n",
            "968/1001, train_loss: 0.2678, step time: 0.6522\n",
            "969/1001, train_loss: 0.1966, step time: 0.6521\n",
            "970/1001, train_loss: 0.6850, step time: 0.6677\n",
            "971/1001, train_loss: 0.0546, step time: 0.6567\n",
            "972/1001, train_loss: 1.0000, step time: 0.6739\n",
            "973/1001, train_loss: 1.0000, step time: 0.6477\n",
            "974/1001, train_loss: 0.0697, step time: 0.6535\n",
            "975/1001, train_loss: 0.1898, step time: 0.6521\n",
            "976/1001, train_loss: 0.0316, step time: 0.6501\n",
            "977/1001, train_loss: 0.1270, step time: 0.6560\n",
            "978/1001, train_loss: 0.7285, step time: 0.6536\n",
            "979/1001, train_loss: 0.1046, step time: 0.6536\n",
            "980/1001, train_loss: 0.2867, step time: 0.6552\n",
            "981/1001, train_loss: 0.0484, step time: 0.6611\n",
            "982/1001, train_loss: 0.0422, step time: 0.6764\n",
            "983/1001, train_loss: 0.1035, step time: 0.6670\n",
            "984/1001, train_loss: 0.0404, step time: 0.6507\n",
            "985/1001, train_loss: 0.6814, step time: 0.6429\n",
            "986/1001, train_loss: 0.0739, step time: 0.6573\n",
            "987/1001, train_loss: 0.0627, step time: 0.6508\n",
            "988/1001, train_loss: 0.1156, step time: 0.6517\n",
            "989/1001, train_loss: 0.2263, step time: 0.6520\n",
            "990/1001, train_loss: 0.1341, step time: 0.6513\n",
            "991/1001, train_loss: 0.1014, step time: 0.6525\n",
            "992/1001, train_loss: 0.0376, step time: 0.6485\n",
            "993/1001, train_loss: 0.0775, step time: 0.6504\n",
            "994/1001, train_loss: 0.0565, step time: 0.6501\n",
            "995/1001, train_loss: 0.2151, step time: 0.6520\n",
            "996/1001, train_loss: 0.1806, step time: 0.6503\n",
            "997/1001, train_loss: 0.2562, step time: 0.6516\n",
            "998/1001, train_loss: 1.0000, step time: 0.6238\n",
            "999/1001, train_loss: 0.0599, step time: 0.6496\n",
            "1000/1001, train_loss: 0.0352, step time: 0.6486\n",
            "1001/1001, train_loss: 0.0720, step time: 0.6509\n",
            "epoch 18 average loss: 0.2589\n",
            "saved new best metric model\n",
            "current epoch: 18 current mean dice: 0.8707 tc: 0.8628 wt: 0.9072 et: 0.8455\n",
            "best mean dice: 0.8707 at epoch: 18\n",
            "time consuming of epoch 18 is: 833.0049\n",
            "----------\n",
            "epoch 19/20\n",
            "1/1001, train_loss: 0.0460, step time: 0.6956\n",
            "2/1001, train_loss: 0.0483, step time: 0.7394\n",
            "3/1001, train_loss: 0.5507, step time: 0.6582\n",
            "4/1001, train_loss: 0.4017, step time: 0.6589\n",
            "5/1001, train_loss: 0.0367, step time: 0.6587\n",
            "6/1001, train_loss: 0.3262, step time: 0.6742\n",
            "7/1001, train_loss: 0.0561, step time: 0.6532\n",
            "8/1001, train_loss: 0.0592, step time: 0.6498\n",
            "9/1001, train_loss: 0.1145, step time: 0.6757\n",
            "10/1001, train_loss: 0.0495, step time: 0.6637\n",
            "11/1001, train_loss: 0.1021, step time: 0.7110\n",
            "12/1001, train_loss: 0.1092, step time: 0.6854\n",
            "13/1001, train_loss: 0.3096, step time: 0.6544\n",
            "14/1001, train_loss: 0.0688, step time: 0.6618\n",
            "15/1001, train_loss: 0.2632, step time: 0.6523\n",
            "16/1001, train_loss: 0.0507, step time: 0.6495\n",
            "17/1001, train_loss: 1.0000, step time: 0.6286\n",
            "18/1001, train_loss: 0.0747, step time: 0.6514\n",
            "19/1001, train_loss: 0.1613, step time: 0.6770\n",
            "20/1001, train_loss: 0.1135, step time: 0.6515\n",
            "21/1001, train_loss: 0.1023, step time: 0.6506\n",
            "22/1001, train_loss: 0.0574, step time: 0.6485\n",
            "23/1001, train_loss: 0.2852, step time: 0.6518\n",
            "24/1001, train_loss: 0.0807, step time: 0.6519\n",
            "25/1001, train_loss: 0.1817, step time: 0.6522\n",
            "26/1001, train_loss: 0.3302, step time: 0.6524\n",
            "27/1001, train_loss: 0.0487, step time: 0.6476\n",
            "28/1001, train_loss: 0.0614, step time: 0.6629\n",
            "29/1001, train_loss: 0.1115, step time: 0.6515\n",
            "30/1001, train_loss: 0.4793, step time: 0.6521\n",
            "31/1001, train_loss: 0.0781, step time: 0.6484\n",
            "32/1001, train_loss: 0.7185, step time: 0.6628\n",
            "33/1001, train_loss: 1.0000, step time: 0.6227\n",
            "34/1001, train_loss: 0.0521, step time: 0.6635\n",
            "35/1001, train_loss: 0.0232, step time: 0.6486\n",
            "36/1001, train_loss: 0.0443, step time: 0.6793\n",
            "37/1001, train_loss: 0.0387, step time: 0.6828\n",
            "38/1001, train_loss: 0.3606, step time: 0.6834\n",
            "39/1001, train_loss: 0.0922, step time: 0.6860\n",
            "40/1001, train_loss: 0.1814, step time: 0.6520\n",
            "41/1001, train_loss: 1.0000, step time: 0.6726\n",
            "42/1001, train_loss: 0.6506, step time: 0.6543\n",
            "43/1001, train_loss: 0.5687, step time: 0.6539\n",
            "44/1001, train_loss: 0.0666, step time: 0.6502\n",
            "45/1001, train_loss: 0.2776, step time: 0.6530\n",
            "46/1001, train_loss: 0.0616, step time: 0.6506\n",
            "47/1001, train_loss: 0.0567, step time: 0.6495\n",
            "48/1001, train_loss: 0.3640, step time: 0.6517\n",
            "49/1001, train_loss: 0.0469, step time: 0.6653\n",
            "50/1001, train_loss: 0.0937, step time: 0.6525\n",
            "51/1001, train_loss: 0.7008, step time: 0.6520\n",
            "52/1001, train_loss: 0.4359, step time: 0.6530\n",
            "53/1001, train_loss: 0.0555, step time: 0.6623\n",
            "54/1001, train_loss: 0.0820, step time: 0.6527\n",
            "55/1001, train_loss: 0.1176, step time: 0.6519\n",
            "56/1001, train_loss: 0.0696, step time: 0.6517\n",
            "57/1001, train_loss: 0.1414, step time: 0.6521\n",
            "58/1001, train_loss: 0.7775, step time: 0.6674\n",
            "59/1001, train_loss: 0.0685, step time: 0.6563\n",
            "60/1001, train_loss: 0.0880, step time: 0.6495\n",
            "61/1001, train_loss: 0.2798, step time: 0.6527\n",
            "62/1001, train_loss: 0.0566, step time: 0.6507\n",
            "63/1001, train_loss: 0.1139, step time: 0.6495\n",
            "64/1001, train_loss: 0.1105, step time: 0.6478\n",
            "65/1001, train_loss: 0.4524, step time: 0.6520\n",
            "66/1001, train_loss: 0.1748, step time: 0.6608\n",
            "67/1001, train_loss: 0.1837, step time: 0.6593\n",
            "68/1001, train_loss: 1.0000, step time: 0.6238\n",
            "69/1001, train_loss: 0.1587, step time: 0.6534\n",
            "70/1001, train_loss: 0.0946, step time: 0.6577\n",
            "71/1001, train_loss: 0.0675, step time: 0.6518\n",
            "72/1001, train_loss: 0.5772, step time: 0.6467\n",
            "73/1001, train_loss: 0.7013, step time: 0.6509\n",
            "74/1001, train_loss: 0.0641, step time: 0.6645\n",
            "75/1001, train_loss: 0.7428, step time: 0.6794\n",
            "76/1001, train_loss: 0.0833, step time: 0.6601\n",
            "77/1001, train_loss: 0.0523, step time: 0.6521\n",
            "78/1001, train_loss: 0.8705, step time: 0.6756\n",
            "79/1001, train_loss: 0.0644, step time: 0.6517\n",
            "80/1001, train_loss: 0.0975, step time: 0.6523\n",
            "81/1001, train_loss: 0.0333, step time: 0.6536\n",
            "82/1001, train_loss: 0.7939, step time: 0.6469\n",
            "83/1001, train_loss: 0.0656, step time: 0.6457\n",
            "84/1001, train_loss: 0.0931, step time: 0.6505\n",
            "85/1001, train_loss: 0.0398, step time: 0.6685\n",
            "86/1001, train_loss: 0.3925, step time: 0.6496\n",
            "87/1001, train_loss: 0.7011, step time: 0.6485\n",
            "88/1001, train_loss: 0.0256, step time: 0.6464\n",
            "89/1001, train_loss: 0.2244, step time: 0.6614\n",
            "90/1001, train_loss: 0.1213, step time: 0.6513\n",
            "91/1001, train_loss: 0.1023, step time: 0.6489\n",
            "92/1001, train_loss: 0.2398, step time: 0.6517\n",
            "93/1001, train_loss: 0.2048, step time: 0.6729\n",
            "94/1001, train_loss: 0.0473, step time: 0.6496\n",
            "95/1001, train_loss: 0.1919, step time: 0.6557\n",
            "96/1001, train_loss: 0.0381, step time: 0.6495\n",
            "97/1001, train_loss: 0.0635, step time: 0.6499\n",
            "98/1001, train_loss: 0.0279, step time: 0.6741\n",
            "99/1001, train_loss: 0.0717, step time: 0.6717\n",
            "100/1001, train_loss: 0.0468, step time: 0.6571\n",
            "101/1001, train_loss: 0.3324, step time: 0.6657\n",
            "102/1001, train_loss: 0.6826, step time: 0.6463\n",
            "103/1001, train_loss: 1.0000, step time: 0.6239\n",
            "104/1001, train_loss: 0.0907, step time: 0.6484\n",
            "105/1001, train_loss: 0.1898, step time: 0.6483\n",
            "106/1001, train_loss: 0.1778, step time: 0.6686\n",
            "107/1001, train_loss: 0.0576, step time: 0.6516\n",
            "108/1001, train_loss: 0.0589, step time: 0.6540\n",
            "109/1001, train_loss: 0.2273, step time: 0.6560\n",
            "110/1001, train_loss: 0.6945, step time: 0.6507\n",
            "111/1001, train_loss: 0.5398, step time: 0.6562\n",
            "112/1001, train_loss: 0.2204, step time: 0.6546\n",
            "113/1001, train_loss: 0.0995, step time: 0.6605\n",
            "114/1001, train_loss: 0.0879, step time: 0.6850\n",
            "115/1001, train_loss: 0.6809, step time: 0.6436\n",
            "116/1001, train_loss: 0.0858, step time: 0.6514\n",
            "117/1001, train_loss: 0.7463, step time: 0.6506\n",
            "118/1001, train_loss: 0.5952, step time: 0.6511\n",
            "119/1001, train_loss: 0.0408, step time: 0.6466\n",
            "120/1001, train_loss: 0.0455, step time: 0.6587\n",
            "121/1001, train_loss: 0.0391, step time: 0.6500\n",
            "122/1001, train_loss: 0.0426, step time: 0.6779\n",
            "123/1001, train_loss: 0.4635, step time: 0.6595\n",
            "124/1001, train_loss: 0.2534, step time: 0.6534\n",
            "125/1001, train_loss: 0.0612, step time: 0.6593\n",
            "126/1001, train_loss: 0.0720, step time: 0.6508\n",
            "127/1001, train_loss: 0.3033, step time: 0.6513\n",
            "128/1001, train_loss: 0.0333, step time: 0.6453\n",
            "129/1001, train_loss: 0.0614, step time: 0.6493\n",
            "130/1001, train_loss: 0.0406, step time: 0.6459\n",
            "131/1001, train_loss: 0.7276, step time: 0.6656\n",
            "132/1001, train_loss: 0.2066, step time: 0.6537\n",
            "133/1001, train_loss: 0.7116, step time: 0.6533\n",
            "134/1001, train_loss: 0.0364, step time: 0.6505\n",
            "135/1001, train_loss: 1.0000, step time: 0.6395\n",
            "136/1001, train_loss: 1.0000, step time: 0.6301\n",
            "137/1001, train_loss: 0.0427, step time: 0.6844\n",
            "138/1001, train_loss: 0.1057, step time: 0.6582\n",
            "139/1001, train_loss: 0.0702, step time: 0.6579\n",
            "140/1001, train_loss: 0.0610, step time: 0.6530\n",
            "141/1001, train_loss: 0.0714, step time: 0.6517\n",
            "142/1001, train_loss: 0.0625, step time: 0.6811\n",
            "143/1001, train_loss: 0.1040, step time: 0.6528\n",
            "144/1001, train_loss: 0.0923, step time: 0.6757\n",
            "145/1001, train_loss: 0.0720, step time: 0.6514\n",
            "146/1001, train_loss: 0.0398, step time: 0.6459\n",
            "147/1001, train_loss: 0.8659, step time: 0.6531\n",
            "148/1001, train_loss: 0.0479, step time: 0.6457\n",
            "149/1001, train_loss: 0.4759, step time: 0.6505\n",
            "150/1001, train_loss: 0.1785, step time: 0.6532\n",
            "151/1001, train_loss: 0.8079, step time: 0.6540\n",
            "152/1001, train_loss: 0.1577, step time: 0.6501\n",
            "153/1001, train_loss: 0.0608, step time: 0.6503\n",
            "154/1001, train_loss: 1.0000, step time: 0.6291\n",
            "155/1001, train_loss: 0.0412, step time: 0.6505\n",
            "156/1001, train_loss: 1.0000, step time: 0.6259\n",
            "157/1001, train_loss: 0.2952, step time: 0.6512\n",
            "158/1001, train_loss: 0.1696, step time: 0.6514\n",
            "159/1001, train_loss: 0.0444, step time: 0.6536\n",
            "160/1001, train_loss: 0.2300, step time: 0.6522\n",
            "161/1001, train_loss: 0.1586, step time: 0.6496\n",
            "162/1001, train_loss: 0.1160, step time: 0.6514\n",
            "163/1001, train_loss: 0.0380, step time: 0.6812\n",
            "164/1001, train_loss: 0.1785, step time: 0.6525\n",
            "165/1001, train_loss: 0.0494, step time: 0.6516\n",
            "166/1001, train_loss: 0.0467, step time: 0.6574\n",
            "167/1001, train_loss: 0.0353, step time: 0.6596\n",
            "168/1001, train_loss: 0.9414, step time: 0.6771\n",
            "169/1001, train_loss: 0.0441, step time: 0.6470\n",
            "170/1001, train_loss: 0.1373, step time: 0.6535\n",
            "171/1001, train_loss: 0.0959, step time: 0.6565\n",
            "172/1001, train_loss: 0.0281, step time: 0.6585\n",
            "173/1001, train_loss: 0.0294, step time: 0.6481\n",
            "174/1001, train_loss: 0.1780, step time: 0.6587\n",
            "175/1001, train_loss: 0.7666, step time: 0.6579\n",
            "176/1001, train_loss: 0.0441, step time: 0.6477\n",
            "177/1001, train_loss: 0.0452, step time: 0.6503\n",
            "178/1001, train_loss: 0.0342, step time: 0.6510\n",
            "179/1001, train_loss: 0.0845, step time: 0.6503\n",
            "180/1001, train_loss: 0.1050, step time: 0.6530\n",
            "181/1001, train_loss: 0.0926, step time: 0.6570\n",
            "182/1001, train_loss: 0.0676, step time: 0.6562\n",
            "183/1001, train_loss: 0.0414, step time: 0.6679\n",
            "184/1001, train_loss: 0.7539, step time: 0.6528\n",
            "185/1001, train_loss: 0.1789, step time: 0.6609\n",
            "186/1001, train_loss: 0.0796, step time: 0.6802\n",
            "187/1001, train_loss: 0.0387, step time: 0.6507\n",
            "188/1001, train_loss: 0.1302, step time: 0.6514\n",
            "189/1001, train_loss: 0.0676, step time: 0.6508\n",
            "190/1001, train_loss: 0.2162, step time: 0.6555\n",
            "191/1001, train_loss: 0.0344, step time: 0.6590\n",
            "192/1001, train_loss: 0.4737, step time: 0.6589\n",
            "193/1001, train_loss: 0.1215, step time: 0.6527\n",
            "194/1001, train_loss: 0.0537, step time: 0.6653\n",
            "195/1001, train_loss: 0.0525, step time: 0.6512\n",
            "196/1001, train_loss: 0.0619, step time: 0.6721\n",
            "197/1001, train_loss: 0.1234, step time: 0.6749\n",
            "198/1001, train_loss: 0.0580, step time: 0.6553\n",
            "199/1001, train_loss: 0.0803, step time: 0.6490\n",
            "200/1001, train_loss: 0.1775, step time: 0.6507\n",
            "201/1001, train_loss: 0.2855, step time: 0.6512\n",
            "202/1001, train_loss: 0.3079, step time: 0.6783\n",
            "203/1001, train_loss: 0.0472, step time: 0.6509\n",
            "204/1001, train_loss: 0.1313, step time: 0.6492\n",
            "205/1001, train_loss: 0.4555, step time: 0.6511\n",
            "206/1001, train_loss: 0.2110, step time: 0.6510\n",
            "207/1001, train_loss: 0.1312, step time: 0.6731\n",
            "208/1001, train_loss: 0.8001, step time: 0.6526\n",
            "209/1001, train_loss: 0.0821, step time: 0.6501\n",
            "210/1001, train_loss: 0.0295, step time: 0.6559\n",
            "211/1001, train_loss: 0.0675, step time: 0.6494\n",
            "212/1001, train_loss: 0.0554, step time: 0.6551\n",
            "213/1001, train_loss: 0.0334, step time: 0.6855\n",
            "214/1001, train_loss: 0.6762, step time: 0.6484\n",
            "215/1001, train_loss: 0.0382, step time: 0.6450\n",
            "216/1001, train_loss: 0.6853, step time: 0.6502\n",
            "217/1001, train_loss: 0.0541, step time: 0.6471\n",
            "218/1001, train_loss: 0.0946, step time: 0.6490\n",
            "219/1001, train_loss: 0.0883, step time: 0.6503\n",
            "220/1001, train_loss: 0.1363, step time: 0.6516\n",
            "221/1001, train_loss: 0.1586, step time: 0.6573\n",
            "222/1001, train_loss: 0.0300, step time: 0.6441\n",
            "223/1001, train_loss: 0.6791, step time: 0.6536\n",
            "224/1001, train_loss: 0.0650, step time: 0.6709\n",
            "225/1001, train_loss: 0.0710, step time: 0.6499\n",
            "226/1001, train_loss: 0.0925, step time: 0.6499\n",
            "227/1001, train_loss: 0.4523, step time: 0.6519\n",
            "228/1001, train_loss: 0.0533, step time: 0.6459\n",
            "229/1001, train_loss: 0.1153, step time: 0.6763\n",
            "230/1001, train_loss: 0.0271, step time: 0.6499\n",
            "231/1001, train_loss: 0.0807, step time: 0.6503\n",
            "232/1001, train_loss: 0.0794, step time: 0.6722\n",
            "233/1001, train_loss: 0.0418, step time: 0.6569\n",
            "234/1001, train_loss: 0.1906, step time: 0.6711\n",
            "235/1001, train_loss: 0.0445, step time: 0.6567\n",
            "236/1001, train_loss: 0.1687, step time: 0.6506\n",
            "237/1001, train_loss: 0.6828, step time: 0.6447\n",
            "238/1001, train_loss: 0.0428, step time: 0.6601\n",
            "239/1001, train_loss: 0.0375, step time: 0.6466\n",
            "240/1001, train_loss: 0.1037, step time: 0.6544\n",
            "241/1001, train_loss: 0.5535, step time: 0.6562\n",
            "242/1001, train_loss: 0.4580, step time: 0.6545\n",
            "243/1001, train_loss: 0.0402, step time: 0.6520\n",
            "244/1001, train_loss: 0.0648, step time: 0.6514\n",
            "245/1001, train_loss: 0.1881, step time: 0.6506\n",
            "246/1001, train_loss: 0.4691, step time: 0.6523\n",
            "247/1001, train_loss: 0.1423, step time: 0.6514\n",
            "248/1001, train_loss: 0.0821, step time: 0.6530\n",
            "249/1001, train_loss: 0.7121, step time: 0.6496\n",
            "250/1001, train_loss: 0.2902, step time: 0.6775\n",
            "251/1001, train_loss: 0.0444, step time: 0.6508\n",
            "252/1001, train_loss: 0.1740, step time: 0.6511\n",
            "253/1001, train_loss: 0.0539, step time: 0.6537\n",
            "254/1001, train_loss: 0.0636, step time: 0.6473\n",
            "255/1001, train_loss: 0.0457, step time: 0.6480\n",
            "256/1001, train_loss: 0.0290, step time: 0.6480\n",
            "257/1001, train_loss: 0.0516, step time: 0.6456\n",
            "258/1001, train_loss: 0.8413, step time: 0.6522\n",
            "259/1001, train_loss: 0.0978, step time: 0.6678\n",
            "260/1001, train_loss: 0.2275, step time: 0.6527\n",
            "261/1001, train_loss: 0.1090, step time: 0.6636\n",
            "262/1001, train_loss: 0.9947, step time: 0.6413\n",
            "263/1001, train_loss: 0.1101, step time: 0.6519\n",
            "264/1001, train_loss: 0.0375, step time: 0.6626\n",
            "265/1001, train_loss: 0.1254, step time: 0.6485\n",
            "266/1001, train_loss: 0.0978, step time: 0.6620\n",
            "267/1001, train_loss: 0.2769, step time: 0.6523\n",
            "268/1001, train_loss: 1.0000, step time: 0.6482\n",
            "269/1001, train_loss: 1.0000, step time: 0.6423\n",
            "270/1001, train_loss: 0.0999, step time: 0.6548\n",
            "271/1001, train_loss: 0.5194, step time: 0.6513\n",
            "272/1001, train_loss: 0.6968, step time: 0.6716\n",
            "273/1001, train_loss: 0.0537, step time: 0.6706\n",
            "274/1001, train_loss: 0.5526, step time: 0.6526\n",
            "275/1001, train_loss: 0.1508, step time: 0.6525\n",
            "276/1001, train_loss: 0.1896, step time: 0.6505\n",
            "277/1001, train_loss: 0.9805, step time: 0.6522\n",
            "278/1001, train_loss: 0.6745, step time: 0.6626\n",
            "279/1001, train_loss: 0.0990, step time: 0.6480\n",
            "280/1001, train_loss: 0.0498, step time: 0.6493\n",
            "281/1001, train_loss: 0.0456, step time: 0.6755\n",
            "282/1001, train_loss: 0.1867, step time: 0.6599\n",
            "283/1001, train_loss: 0.0719, step time: 0.6509\n",
            "284/1001, train_loss: 0.7078, step time: 0.6560\n",
            "285/1001, train_loss: 1.0000, step time: 0.6265\n",
            "286/1001, train_loss: 0.0731, step time: 0.6734\n",
            "287/1001, train_loss: 0.0364, step time: 0.6517\n",
            "288/1001, train_loss: 0.0398, step time: 0.6694\n",
            "289/1001, train_loss: 0.1035, step time: 0.6531\n",
            "290/1001, train_loss: 0.1500, step time: 0.6554\n",
            "291/1001, train_loss: 0.0601, step time: 0.6540\n",
            "292/1001, train_loss: 0.0442, step time: 0.6619\n",
            "293/1001, train_loss: 1.0000, step time: 0.6496\n",
            "294/1001, train_loss: 0.0789, step time: 0.6846\n",
            "295/1001, train_loss: 0.0914, step time: 0.6503\n",
            "296/1001, train_loss: 0.1577, step time: 0.6545\n",
            "297/1001, train_loss: 0.1330, step time: 0.6495\n",
            "298/1001, train_loss: 1.0000, step time: 0.6226\n",
            "299/1001, train_loss: 0.9512, step time: 0.6542\n",
            "300/1001, train_loss: 0.0534, step time: 0.6680\n",
            "301/1001, train_loss: 0.4223, step time: 0.6567\n",
            "302/1001, train_loss: 0.0477, step time: 0.6547\n",
            "303/1001, train_loss: 0.2430, step time: 0.6670\n",
            "304/1001, train_loss: 0.7068, step time: 0.6525\n",
            "305/1001, train_loss: 0.0272, step time: 0.6530\n",
            "306/1001, train_loss: 0.4261, step time: 0.6511\n",
            "307/1001, train_loss: 0.1913, step time: 0.6515\n",
            "308/1001, train_loss: 0.0348, step time: 0.6727\n",
            "309/1001, train_loss: 0.1162, step time: 0.6850\n",
            "310/1001, train_loss: 0.0461, step time: 0.6529\n",
            "311/1001, train_loss: 0.1381, step time: 0.6495\n",
            "312/1001, train_loss: 0.0958, step time: 0.6498\n",
            "313/1001, train_loss: 0.6917, step time: 0.6526\n",
            "314/1001, train_loss: 0.7187, step time: 0.6691\n",
            "315/1001, train_loss: 0.1081, step time: 0.6507\n",
            "316/1001, train_loss: 0.0617, step time: 0.6733\n",
            "317/1001, train_loss: 0.1218, step time: 0.6538\n",
            "318/1001, train_loss: 0.4276, step time: 0.6711\n",
            "319/1001, train_loss: 0.0398, step time: 0.6504\n",
            "320/1001, train_loss: 0.9979, step time: 0.6414\n",
            "321/1001, train_loss: 0.4030, step time: 0.6529\n",
            "322/1001, train_loss: 0.3944, step time: 0.6523\n",
            "323/1001, train_loss: 0.0990, step time: 0.6562\n",
            "324/1001, train_loss: 0.2848, step time: 0.6802\n",
            "325/1001, train_loss: 0.0771, step time: 0.6545\n",
            "326/1001, train_loss: 0.0685, step time: 0.6530\n",
            "327/1001, train_loss: 0.3271, step time: 0.6516\n",
            "328/1001, train_loss: 0.0837, step time: 0.6497\n",
            "329/1001, train_loss: 0.6880, step time: 0.6489\n",
            "330/1001, train_loss: 0.0770, step time: 0.6514\n",
            "331/1001, train_loss: 0.0676, step time: 0.6541\n",
            "332/1001, train_loss: 0.7817, step time: 0.6550\n",
            "333/1001, train_loss: 0.4087, step time: 0.6872\n",
            "334/1001, train_loss: 0.9135, step time: 0.6588\n",
            "335/1001, train_loss: 0.3543, step time: 0.6494\n",
            "336/1001, train_loss: 0.1040, step time: 0.6835\n",
            "337/1001, train_loss: 0.0415, step time: 0.6642\n",
            "338/1001, train_loss: 0.0765, step time: 0.6845\n",
            "339/1001, train_loss: 1.0000, step time: 0.6400\n",
            "340/1001, train_loss: 0.0564, step time: 0.6535\n",
            "341/1001, train_loss: 0.0669, step time: 0.6596\n",
            "342/1001, train_loss: 0.0337, step time: 0.6491\n",
            "343/1001, train_loss: 0.0541, step time: 0.6821\n",
            "344/1001, train_loss: 0.0514, step time: 0.6581\n",
            "345/1001, train_loss: 0.0507, step time: 0.6468\n",
            "346/1001, train_loss: 0.0459, step time: 0.6510\n",
            "347/1001, train_loss: 0.0929, step time: 0.6511\n",
            "348/1001, train_loss: 0.9250, step time: 0.6841\n",
            "349/1001, train_loss: 0.0409, step time: 0.6563\n",
            "350/1001, train_loss: 0.0906, step time: 0.6482\n",
            "351/1001, train_loss: 0.7246, step time: 0.6476\n",
            "352/1001, train_loss: 0.1459, step time: 0.6477\n",
            "353/1001, train_loss: 0.6808, step time: 0.6402\n",
            "354/1001, train_loss: 0.7362, step time: 0.6537\n",
            "355/1001, train_loss: 0.1360, step time: 0.6504\n",
            "356/1001, train_loss: 0.7195, step time: 0.6652\n",
            "357/1001, train_loss: 0.0489, step time: 0.6684\n",
            "358/1001, train_loss: 0.0848, step time: 0.6855\n",
            "359/1001, train_loss: 0.0430, step time: 0.6600\n",
            "360/1001, train_loss: 0.0388, step time: 0.6489\n",
            "361/1001, train_loss: 0.0478, step time: 0.6505\n",
            "362/1001, train_loss: 0.0492, step time: 0.6475\n",
            "363/1001, train_loss: 0.1081, step time: 0.6507\n",
            "364/1001, train_loss: 0.1033, step time: 0.6558\n",
            "365/1001, train_loss: 0.7608, step time: 0.6560\n",
            "366/1001, train_loss: 0.0707, step time: 0.6513\n",
            "367/1001, train_loss: 0.4305, step time: 0.6529\n",
            "368/1001, train_loss: 0.0423, step time: 0.6505\n",
            "369/1001, train_loss: 0.0348, step time: 0.6494\n",
            "370/1001, train_loss: 0.1267, step time: 0.6544\n",
            "371/1001, train_loss: 0.7308, step time: 0.6492\n",
            "372/1001, train_loss: 0.1254, step time: 0.6515\n",
            "373/1001, train_loss: 0.0771, step time: 0.6687\n",
            "374/1001, train_loss: 0.2469, step time: 0.6565\n",
            "375/1001, train_loss: 0.0333, step time: 0.6747\n",
            "376/1001, train_loss: 1.0000, step time: 0.6465\n",
            "377/1001, train_loss: 0.0431, step time: 0.6540\n",
            "378/1001, train_loss: 0.0537, step time: 0.6677\n",
            "379/1001, train_loss: 1.0000, step time: 0.6339\n",
            "380/1001, train_loss: 0.7933, step time: 0.6843\n",
            "381/1001, train_loss: 0.8662, step time: 0.6835\n",
            "382/1001, train_loss: 0.0601, step time: 0.6526\n",
            "383/1001, train_loss: 0.0312, step time: 0.6503\n",
            "384/1001, train_loss: 0.6607, step time: 0.6545\n",
            "385/1001, train_loss: 0.0269, step time: 0.6468\n",
            "386/1001, train_loss: 0.1031, step time: 0.6491\n",
            "387/1001, train_loss: 0.0871, step time: 0.6733\n",
            "388/1001, train_loss: 0.3032, step time: 0.6622\n",
            "389/1001, train_loss: 0.4374, step time: 0.6559\n",
            "390/1001, train_loss: 0.0600, step time: 0.6504\n",
            "391/1001, train_loss: 0.7273, step time: 0.6813\n",
            "392/1001, train_loss: 0.7054, step time: 0.6543\n",
            "393/1001, train_loss: 0.0655, step time: 0.6679\n",
            "394/1001, train_loss: 0.0316, step time: 0.6602\n",
            "395/1001, train_loss: 0.0457, step time: 0.6513\n",
            "396/1001, train_loss: 0.2503, step time: 0.6519\n",
            "397/1001, train_loss: 0.1477, step time: 0.6864\n",
            "398/1001, train_loss: 0.0270, step time: 0.6793\n",
            "399/1001, train_loss: 0.0513, step time: 0.6517\n",
            "400/1001, train_loss: 0.3040, step time: 0.6680\n",
            "401/1001, train_loss: 0.1508, step time: 0.6545\n",
            "402/1001, train_loss: 0.0840, step time: 0.6519\n",
            "403/1001, train_loss: 0.0336, step time: 0.6443\n",
            "404/1001, train_loss: 0.0423, step time: 0.6715\n",
            "405/1001, train_loss: 0.0239, step time: 0.6428\n",
            "406/1001, train_loss: 0.0402, step time: 0.6761\n",
            "407/1001, train_loss: 0.5571, step time: 0.6567\n",
            "408/1001, train_loss: 0.0872, step time: 0.6482\n",
            "409/1001, train_loss: 0.0384, step time: 0.6809\n",
            "410/1001, train_loss: 0.0480, step time: 0.6780\n",
            "411/1001, train_loss: 0.3957, step time: 0.6752\n",
            "412/1001, train_loss: 0.0722, step time: 0.6499\n",
            "413/1001, train_loss: 0.0750, step time: 0.6498\n",
            "414/1001, train_loss: 0.0425, step time: 0.6693\n",
            "415/1001, train_loss: 0.0534, step time: 0.6714\n",
            "416/1001, train_loss: 0.0493, step time: 0.6541\n",
            "417/1001, train_loss: 0.0698, step time: 0.6525\n",
            "418/1001, train_loss: 0.0792, step time: 0.6592\n",
            "419/1001, train_loss: 0.8577, step time: 0.6866\n",
            "420/1001, train_loss: 0.3354, step time: 0.6544\n",
            "421/1001, train_loss: 0.0627, step time: 0.6530\n",
            "422/1001, train_loss: 0.0502, step time: 0.6491\n",
            "423/1001, train_loss: 1.0000, step time: 0.6248\n",
            "424/1001, train_loss: 0.0436, step time: 0.6491\n",
            "425/1001, train_loss: 0.0283, step time: 0.6548\n",
            "426/1001, train_loss: 0.0450, step time: 0.6494\n",
            "427/1001, train_loss: 0.0711, step time: 0.6627\n",
            "428/1001, train_loss: 0.0635, step time: 0.6585\n",
            "429/1001, train_loss: 0.0329, step time: 0.6425\n",
            "430/1001, train_loss: 0.0512, step time: 0.6519\n",
            "431/1001, train_loss: 0.0579, step time: 0.6505\n",
            "432/1001, train_loss: 0.0687, step time: 0.6504\n",
            "433/1001, train_loss: 0.3557, step time: 0.6516\n",
            "434/1001, train_loss: 0.6795, step time: 0.6387\n",
            "435/1001, train_loss: 1.0000, step time: 0.6230\n",
            "436/1001, train_loss: 0.0338, step time: 0.6488\n",
            "437/1001, train_loss: 0.0452, step time: 0.6566\n",
            "438/1001, train_loss: 0.0662, step time: 0.6517\n",
            "439/1001, train_loss: 0.7136, step time: 0.6614\n",
            "440/1001, train_loss: 0.0435, step time: 0.6516\n",
            "441/1001, train_loss: 0.0539, step time: 0.6544\n",
            "442/1001, train_loss: 0.0403, step time: 0.6515\n",
            "443/1001, train_loss: 1.0000, step time: 0.6232\n",
            "444/1001, train_loss: 0.0577, step time: 0.6491\n",
            "445/1001, train_loss: 0.0394, step time: 0.6562\n",
            "446/1001, train_loss: 0.0764, step time: 0.6628\n",
            "447/1001, train_loss: 0.0392, step time: 0.6485\n",
            "448/1001, train_loss: 1.0000, step time: 0.6299\n",
            "449/1001, train_loss: 0.2349, step time: 0.6527\n",
            "450/1001, train_loss: 0.0587, step time: 0.6449\n",
            "451/1001, train_loss: 0.9983, step time: 0.6383\n",
            "452/1001, train_loss: 0.0459, step time: 0.6491\n",
            "453/1001, train_loss: 0.0748, step time: 0.6544\n",
            "454/1001, train_loss: 0.9999, step time: 0.6254\n",
            "455/1001, train_loss: 0.0379, step time: 0.6543\n",
            "456/1001, train_loss: 1.0000, step time: 0.6286\n",
            "457/1001, train_loss: 0.8535, step time: 0.6506\n",
            "458/1001, train_loss: 0.0772, step time: 0.6821\n",
            "459/1001, train_loss: 0.3748, step time: 0.6558\n",
            "460/1001, train_loss: 1.0000, step time: 0.6242\n",
            "461/1001, train_loss: 0.1123, step time: 0.6530\n",
            "462/1001, train_loss: 1.0000, step time: 0.6242\n",
            "463/1001, train_loss: 0.0348, step time: 0.6483\n",
            "464/1001, train_loss: 0.2547, step time: 0.7227\n",
            "465/1001, train_loss: 0.7111, step time: 0.6567\n",
            "466/1001, train_loss: 0.2375, step time: 0.6525\n",
            "467/1001, train_loss: 0.3283, step time: 0.6657\n",
            "468/1001, train_loss: 0.0360, step time: 0.6616\n",
            "469/1001, train_loss: 0.2071, step time: 0.6531\n",
            "470/1001, train_loss: 1.0000, step time: 0.6385\n",
            "471/1001, train_loss: 0.1163, step time: 0.6840\n",
            "472/1001, train_loss: 0.0448, step time: 0.6609\n",
            "473/1001, train_loss: 0.1499, step time: 0.6777\n",
            "474/1001, train_loss: 0.3686, step time: 0.6759\n",
            "475/1001, train_loss: 0.0653, step time: 0.6761\n",
            "476/1001, train_loss: 0.1046, step time: 0.6517\n",
            "477/1001, train_loss: 1.0000, step time: 0.6491\n",
            "478/1001, train_loss: 0.0396, step time: 0.6508\n",
            "479/1001, train_loss: 0.1892, step time: 0.6516\n",
            "480/1001, train_loss: 0.0588, step time: 0.6749\n",
            "481/1001, train_loss: 0.0538, step time: 0.6588\n",
            "482/1001, train_loss: 0.0559, step time: 0.6693\n",
            "483/1001, train_loss: 0.7401, step time: 0.6703\n",
            "484/1001, train_loss: 0.0520, step time: 0.6493\n",
            "485/1001, train_loss: 0.0602, step time: 0.6469\n",
            "486/1001, train_loss: 0.1898, step time: 0.6533\n",
            "487/1001, train_loss: 0.1457, step time: 0.6530\n",
            "488/1001, train_loss: 0.1894, step time: 0.6547\n",
            "489/1001, train_loss: 1.0000, step time: 0.6355\n",
            "490/1001, train_loss: 0.0391, step time: 0.6537\n",
            "491/1001, train_loss: 0.0845, step time: 0.6498\n",
            "492/1001, train_loss: 0.4481, step time: 0.6516\n",
            "493/1001, train_loss: 0.1040, step time: 0.6615\n",
            "494/1001, train_loss: 1.0000, step time: 0.6246\n",
            "495/1001, train_loss: 0.0633, step time: 0.6507\n",
            "496/1001, train_loss: 0.0971, step time: 0.6495\n",
            "497/1001, train_loss: 0.3914, step time: 0.6525\n",
            "498/1001, train_loss: 0.0917, step time: 0.6549\n",
            "499/1001, train_loss: 0.0319, step time: 0.6488\n",
            "500/1001, train_loss: 0.0385, step time: 0.6485\n",
            "501/1001, train_loss: 0.0425, step time: 0.6734\n",
            "502/1001, train_loss: 0.7215, step time: 0.6473\n",
            "503/1001, train_loss: 0.0482, step time: 0.6459\n",
            "504/1001, train_loss: 0.0673, step time: 0.6690\n",
            "505/1001, train_loss: 0.7178, step time: 0.6849\n",
            "506/1001, train_loss: 0.0529, step time: 0.6642\n",
            "507/1001, train_loss: 0.0944, step time: 0.6759\n",
            "508/1001, train_loss: 1.0000, step time: 0.6255\n",
            "509/1001, train_loss: 1.0000, step time: 0.6280\n",
            "510/1001, train_loss: 0.6792, step time: 0.7062\n",
            "511/1001, train_loss: 0.0542, step time: 0.6506\n",
            "512/1001, train_loss: 0.2418, step time: 0.6521\n",
            "513/1001, train_loss: 0.0464, step time: 0.6472\n",
            "514/1001, train_loss: 0.3469, step time: 0.6563\n",
            "515/1001, train_loss: 0.1121, step time: 0.6614\n",
            "516/1001, train_loss: 0.8942, step time: 0.6568\n",
            "517/1001, train_loss: 0.1296, step time: 0.6493\n",
            "518/1001, train_loss: 1.0000, step time: 0.6293\n",
            "519/1001, train_loss: 0.7041, step time: 0.6534\n",
            "520/1001, train_loss: 0.7250, step time: 0.6768\n",
            "521/1001, train_loss: 0.0849, step time: 0.6524\n",
            "522/1001, train_loss: 0.7011, step time: 0.6477\n",
            "523/1001, train_loss: 0.0605, step time: 0.6485\n",
            "524/1001, train_loss: 0.9999, step time: 0.6272\n",
            "525/1001, train_loss: 0.0269, step time: 0.6803\n",
            "526/1001, train_loss: 0.2510, step time: 0.6534\n",
            "527/1001, train_loss: 0.0431, step time: 0.6469\n",
            "528/1001, train_loss: 1.0000, step time: 0.6231\n",
            "529/1001, train_loss: 0.3985, step time: 0.6549\n",
            "530/1001, train_loss: 0.1112, step time: 0.6531\n",
            "531/1001, train_loss: 1.0000, step time: 0.6252\n",
            "532/1001, train_loss: 0.1683, step time: 0.6556\n",
            "533/1001, train_loss: 1.0000, step time: 0.6325\n",
            "534/1001, train_loss: 0.6851, step time: 0.6465\n",
            "535/1001, train_loss: 0.1752, step time: 0.6594\n",
            "536/1001, train_loss: 0.7390, step time: 0.6519\n",
            "537/1001, train_loss: 0.0519, step time: 0.6525\n",
            "538/1001, train_loss: 0.0972, step time: 0.6793\n",
            "539/1001, train_loss: 0.0756, step time: 0.6490\n",
            "540/1001, train_loss: 1.0000, step time: 0.6492\n",
            "541/1001, train_loss: 0.0659, step time: 0.6631\n",
            "542/1001, train_loss: 0.1157, step time: 0.6494\n",
            "543/1001, train_loss: 1.0000, step time: 0.6285\n",
            "544/1001, train_loss: 0.0985, step time: 0.6699\n",
            "545/1001, train_loss: 0.0815, step time: 0.6463\n",
            "546/1001, train_loss: 0.2008, step time: 0.6519\n",
            "547/1001, train_loss: 0.7359, step time: 0.6565\n",
            "548/1001, train_loss: 0.1012, step time: 0.6515\n",
            "549/1001, train_loss: 0.1311, step time: 0.6514\n",
            "550/1001, train_loss: 1.0000, step time: 0.6285\n",
            "551/1001, train_loss: 0.0957, step time: 0.6519\n",
            "552/1001, train_loss: 0.0393, step time: 0.6747\n",
            "553/1001, train_loss: 0.5663, step time: 0.6849\n",
            "554/1001, train_loss: 0.0347, step time: 0.6505\n",
            "555/1001, train_loss: 0.1832, step time: 0.6759\n",
            "556/1001, train_loss: 0.0728, step time: 0.6508\n",
            "557/1001, train_loss: 0.0544, step time: 0.6491\n",
            "558/1001, train_loss: 0.6780, step time: 0.6828\n",
            "559/1001, train_loss: 0.0984, step time: 0.6504\n",
            "560/1001, train_loss: 0.3316, step time: 0.6774\n",
            "561/1001, train_loss: 0.6080, step time: 0.6687\n",
            "562/1001, train_loss: 0.6880, step time: 0.6605\n",
            "563/1001, train_loss: 0.9419, step time: 0.6530\n",
            "564/1001, train_loss: 0.7608, step time: 0.6528\n",
            "565/1001, train_loss: 0.3989, step time: 0.6543\n",
            "566/1001, train_loss: 0.0348, step time: 0.6407\n",
            "567/1001, train_loss: 0.0590, step time: 0.6568\n",
            "568/1001, train_loss: 0.1789, step time: 0.6596\n",
            "569/1001, train_loss: 0.0783, step time: 0.6729\n",
            "570/1001, train_loss: 0.0691, step time: 0.6464\n",
            "571/1001, train_loss: 0.0578, step time: 0.6522\n",
            "572/1001, train_loss: 0.4094, step time: 0.6543\n",
            "573/1001, train_loss: 0.0924, step time: 0.6508\n",
            "574/1001, train_loss: 0.0570, step time: 0.6531\n",
            "575/1001, train_loss: 0.1908, step time: 0.6534\n",
            "576/1001, train_loss: 1.0000, step time: 0.6467\n",
            "577/1001, train_loss: 0.8472, step time: 0.6503\n",
            "578/1001, train_loss: 0.0665, step time: 0.6478\n",
            "579/1001, train_loss: 0.0381, step time: 0.6703\n",
            "580/1001, train_loss: 0.6799, step time: 0.6701\n",
            "581/1001, train_loss: 0.0686, step time: 0.6885\n",
            "582/1001, train_loss: 0.0582, step time: 0.6568\n",
            "583/1001, train_loss: 0.1433, step time: 0.6514\n",
            "584/1001, train_loss: 0.0634, step time: 0.6560\n",
            "585/1001, train_loss: 0.0781, step time: 0.6540\n",
            "586/1001, train_loss: 0.1455, step time: 0.6516\n",
            "587/1001, train_loss: 0.0307, step time: 0.6506\n",
            "588/1001, train_loss: 0.0582, step time: 0.6516\n",
            "589/1001, train_loss: 0.9755, step time: 0.6525\n",
            "590/1001, train_loss: 0.1184, step time: 0.6606\n",
            "591/1001, train_loss: 1.0000, step time: 0.6536\n",
            "592/1001, train_loss: 0.0930, step time: 0.6537\n",
            "593/1001, train_loss: 1.0000, step time: 0.6317\n",
            "594/1001, train_loss: 0.0423, step time: 0.6618\n",
            "595/1001, train_loss: 0.1040, step time: 0.6741\n",
            "596/1001, train_loss: 0.0554, step time: 0.6653\n",
            "597/1001, train_loss: 0.0313, step time: 0.6615\n",
            "598/1001, train_loss: 0.4891, step time: 0.7018\n",
            "599/1001, train_loss: 0.0689, step time: 0.6507\n",
            "600/1001, train_loss: 0.0438, step time: 0.6488\n",
            "601/1001, train_loss: 0.7562, step time: 0.6488\n",
            "602/1001, train_loss: 0.9014, step time: 0.6540\n",
            "603/1001, train_loss: 0.0775, step time: 0.6655\n",
            "604/1001, train_loss: 0.0600, step time: 0.6535\n",
            "605/1001, train_loss: 0.0279, step time: 0.6462\n",
            "606/1001, train_loss: 1.0000, step time: 0.6252\n",
            "607/1001, train_loss: 0.5068, step time: 0.6503\n",
            "608/1001, train_loss: 1.0000, step time: 0.6357\n",
            "609/1001, train_loss: 0.7350, step time: 0.6525\n",
            "610/1001, train_loss: 0.1990, step time: 0.6515\n",
            "611/1001, train_loss: 0.0674, step time: 0.6570\n",
            "612/1001, train_loss: 0.0397, step time: 0.6625\n",
            "613/1001, train_loss: 0.3045, step time: 0.6798\n",
            "614/1001, train_loss: 0.0915, step time: 0.6658\n",
            "615/1001, train_loss: 0.0634, step time: 0.6594\n",
            "616/1001, train_loss: 0.0638, step time: 0.6843\n",
            "617/1001, train_loss: 0.0790, step time: 0.6557\n",
            "618/1001, train_loss: 0.0586, step time: 0.6502\n",
            "619/1001, train_loss: 0.4514, step time: 0.6514\n",
            "620/1001, train_loss: 0.9614, step time: 0.6518\n",
            "621/1001, train_loss: 0.4465, step time: 0.6573\n",
            "622/1001, train_loss: 0.7746, step time: 0.6532\n",
            "623/1001, train_loss: 0.1106, step time: 0.6598\n",
            "624/1001, train_loss: 0.1250, step time: 0.6582\n",
            "625/1001, train_loss: 0.0206, step time: 0.6445\n",
            "626/1001, train_loss: 0.3087, step time: 0.6526\n",
            "627/1001, train_loss: 1.0000, step time: 0.6262\n",
            "628/1001, train_loss: 0.9818, step time: 0.6498\n",
            "629/1001, train_loss: 0.0967, step time: 0.6505\n",
            "630/1001, train_loss: 0.0448, step time: 0.6783\n",
            "631/1001, train_loss: 0.1123, step time: 0.6531\n",
            "632/1001, train_loss: 0.0281, step time: 0.6471\n",
            "633/1001, train_loss: 0.7225, step time: 0.6561\n",
            "634/1001, train_loss: 1.0000, step time: 0.6277\n",
            "635/1001, train_loss: 0.0933, step time: 0.6513\n",
            "636/1001, train_loss: 0.1226, step time: 0.6530\n",
            "637/1001, train_loss: 0.0713, step time: 0.6520\n",
            "638/1001, train_loss: 0.0479, step time: 0.6804\n",
            "639/1001, train_loss: 0.0314, step time: 0.6838\n",
            "640/1001, train_loss: 0.0749, step time: 0.6548\n",
            "641/1001, train_loss: 0.7093, step time: 0.6600\n",
            "642/1001, train_loss: 0.0735, step time: 0.6493\n",
            "643/1001, train_loss: 0.0349, step time: 0.6482\n",
            "644/1001, train_loss: 0.3863, step time: 0.6516\n",
            "645/1001, train_loss: 0.7507, step time: 0.6495\n",
            "646/1001, train_loss: 0.6771, step time: 0.6339\n",
            "647/1001, train_loss: 0.0656, step time: 0.6442\n",
            "648/1001, train_loss: 0.0450, step time: 0.6598\n",
            "649/1001, train_loss: 0.0543, step time: 0.6545\n",
            "650/1001, train_loss: 0.0922, step time: 0.6554\n",
            "651/1001, train_loss: 1.0000, step time: 0.6226\n",
            "652/1001, train_loss: 0.0667, step time: 0.6703\n",
            "653/1001, train_loss: 0.1517, step time: 0.6658\n",
            "654/1001, train_loss: 0.0542, step time: 0.6554\n",
            "655/1001, train_loss: 0.2683, step time: 0.6513\n",
            "656/1001, train_loss: 0.0229, step time: 0.6448\n",
            "657/1001, train_loss: 0.0396, step time: 0.6484\n",
            "658/1001, train_loss: 0.0432, step time: 0.6655\n",
            "659/1001, train_loss: 1.0000, step time: 0.6299\n",
            "660/1001, train_loss: 0.4159, step time: 0.6726\n",
            "661/1001, train_loss: 0.1286, step time: 0.6580\n",
            "662/1001, train_loss: 0.0551, step time: 0.6784\n",
            "663/1001, train_loss: 0.4525, step time: 0.6716\n",
            "664/1001, train_loss: 0.0353, step time: 0.6490\n",
            "665/1001, train_loss: 0.1442, step time: 0.6513\n",
            "666/1001, train_loss: 0.2515, step time: 0.6513\n",
            "667/1001, train_loss: 0.2154, step time: 0.6522\n",
            "668/1001, train_loss: 0.1851, step time: 0.6517\n",
            "669/1001, train_loss: 0.0911, step time: 0.6587\n",
            "670/1001, train_loss: 0.1035, step time: 0.6586\n",
            "671/1001, train_loss: 0.0561, step time: 0.6445\n",
            "672/1001, train_loss: 0.1108, step time: 0.6502\n",
            "673/1001, train_loss: 0.4370, step time: 0.6648\n",
            "674/1001, train_loss: 0.0582, step time: 0.6467\n",
            "675/1001, train_loss: 0.0529, step time: 0.6518\n",
            "676/1001, train_loss: 0.0418, step time: 0.6474\n",
            "677/1001, train_loss: 0.0463, step time: 0.6511\n",
            "678/1001, train_loss: 0.3438, step time: 0.6677\n",
            "679/1001, train_loss: 0.0859, step time: 0.6551\n",
            "680/1001, train_loss: 0.0371, step time: 0.6501\n",
            "681/1001, train_loss: 0.1050, step time: 0.6550\n",
            "682/1001, train_loss: 0.0755, step time: 0.6497\n",
            "683/1001, train_loss: 1.0000, step time: 0.6250\n",
            "684/1001, train_loss: 0.1015, step time: 0.6501\n",
            "685/1001, train_loss: 0.0380, step time: 0.6537\n",
            "686/1001, train_loss: 0.0672, step time: 0.6465\n",
            "687/1001, train_loss: 0.1136, step time: 0.6504\n",
            "688/1001, train_loss: 0.0599, step time: 0.6501\n",
            "689/1001, train_loss: 0.0547, step time: 0.6512\n",
            "690/1001, train_loss: 0.0447, step time: 0.6536\n",
            "691/1001, train_loss: 0.9953, step time: 0.6499\n",
            "692/1001, train_loss: 0.6240, step time: 0.6622\n",
            "693/1001, train_loss: 0.0792, step time: 0.6599\n",
            "694/1001, train_loss: 0.0442, step time: 0.6535\n",
            "695/1001, train_loss: 0.0678, step time: 0.6746\n",
            "696/1001, train_loss: 0.0769, step time: 0.6642\n",
            "697/1001, train_loss: 0.2315, step time: 0.6695\n",
            "698/1001, train_loss: 0.0349, step time: 0.6483\n",
            "699/1001, train_loss: 0.1674, step time: 0.6510\n",
            "700/1001, train_loss: 0.2155, step time: 0.6547\n",
            "701/1001, train_loss: 0.0496, step time: 0.6823\n",
            "702/1001, train_loss: 0.0327, step time: 0.6750\n",
            "703/1001, train_loss: 0.0480, step time: 0.6504\n",
            "704/1001, train_loss: 0.0340, step time: 0.6464\n",
            "705/1001, train_loss: 0.1393, step time: 0.6492\n",
            "706/1001, train_loss: 0.0417, step time: 0.6483\n",
            "707/1001, train_loss: 0.0541, step time: 0.6465\n",
            "708/1001, train_loss: 1.0000, step time: 0.6257\n",
            "709/1001, train_loss: 0.2987, step time: 0.6559\n",
            "710/1001, train_loss: 0.4159, step time: 0.6588\n",
            "711/1001, train_loss: 1.0000, step time: 0.6296\n",
            "712/1001, train_loss: 0.9316, step time: 0.6525\n",
            "713/1001, train_loss: 0.0593, step time: 0.6490\n",
            "714/1001, train_loss: 0.5914, step time: 0.6546\n",
            "715/1001, train_loss: 0.3774, step time: 0.6516\n",
            "716/1001, train_loss: 1.0000, step time: 0.6254\n",
            "717/1001, train_loss: 0.4632, step time: 0.6492\n",
            "718/1001, train_loss: 0.0517, step time: 0.6671\n",
            "719/1001, train_loss: 0.4725, step time: 0.6514\n",
            "720/1001, train_loss: 0.1002, step time: 0.6764\n",
            "721/1001, train_loss: 0.0861, step time: 0.6859\n",
            "722/1001, train_loss: 0.5175, step time: 0.6580\n",
            "723/1001, train_loss: 0.2080, step time: 0.6503\n",
            "724/1001, train_loss: 1.0000, step time: 0.6375\n",
            "725/1001, train_loss: 0.0664, step time: 0.6620\n",
            "726/1001, train_loss: 0.1280, step time: 0.6602\n",
            "727/1001, train_loss: 0.0794, step time: 0.6555\n",
            "728/1001, train_loss: 1.0000, step time: 0.6241\n",
            "729/1001, train_loss: 0.0661, step time: 0.6455\n",
            "730/1001, train_loss: 0.8249, step time: 0.6558\n",
            "731/1001, train_loss: 0.0607, step time: 0.6540\n",
            "732/1001, train_loss: 0.0439, step time: 0.6712\n",
            "733/1001, train_loss: 1.0000, step time: 0.6262\n",
            "734/1001, train_loss: 0.9585, step time: 0.6554\n",
            "735/1001, train_loss: 0.0508, step time: 0.6604\n",
            "736/1001, train_loss: 0.0393, step time: 0.6456\n",
            "737/1001, train_loss: 0.1142, step time: 0.6571\n",
            "738/1001, train_loss: 0.0536, step time: 0.6605\n",
            "739/1001, train_loss: 0.0558, step time: 0.6518\n",
            "740/1001, train_loss: 0.0747, step time: 0.6512\n",
            "741/1001, train_loss: 0.1286, step time: 0.6529\n",
            "742/1001, train_loss: 0.0525, step time: 0.6501\n",
            "743/1001, train_loss: 0.0306, step time: 0.6703\n",
            "744/1001, train_loss: 0.0826, step time: 0.7100\n",
            "745/1001, train_loss: 0.0479, step time: 0.6543\n",
            "746/1001, train_loss: 0.0675, step time: 0.6510\n",
            "747/1001, train_loss: 0.3682, step time: 0.6518\n",
            "748/1001, train_loss: 0.0627, step time: 0.6482\n",
            "749/1001, train_loss: 0.0352, step time: 0.6488\n",
            "750/1001, train_loss: 0.0958, step time: 0.6513\n",
            "751/1001, train_loss: 0.9998, step time: 0.6313\n",
            "752/1001, train_loss: 0.1996, step time: 0.6707\n",
            "753/1001, train_loss: 0.0518, step time: 0.6616\n",
            "754/1001, train_loss: 0.0528, step time: 0.6551\n",
            "755/1001, train_loss: 0.0945, step time: 0.6520\n",
            "756/1001, train_loss: 0.4342, step time: 0.6667\n",
            "757/1001, train_loss: 0.2126, step time: 0.6519\n",
            "758/1001, train_loss: 0.3042, step time: 0.6569\n",
            "759/1001, train_loss: 0.0490, step time: 0.6581\n",
            "760/1001, train_loss: 0.0714, step time: 0.6509\n",
            "761/1001, train_loss: 0.4491, step time: 0.6734\n",
            "762/1001, train_loss: 0.1130, step time: 0.6866\n",
            "763/1001, train_loss: 0.1122, step time: 0.6511\n",
            "764/1001, train_loss: 0.0533, step time: 0.6772\n",
            "765/1001, train_loss: 0.2044, step time: 0.6554\n",
            "766/1001, train_loss: 0.2348, step time: 0.6643\n",
            "767/1001, train_loss: 0.9997, step time: 0.6440\n",
            "768/1001, train_loss: 0.0813, step time: 0.6510\n",
            "769/1001, train_loss: 0.7385, step time: 0.6579\n",
            "770/1001, train_loss: 1.0000, step time: 0.6271\n",
            "771/1001, train_loss: 0.1817, step time: 0.6509\n",
            "772/1001, train_loss: 0.0734, step time: 0.6515\n",
            "773/1001, train_loss: 0.1041, step time: 0.6522\n",
            "774/1001, train_loss: 0.0622, step time: 0.6498\n",
            "775/1001, train_loss: 0.0423, step time: 0.6746\n",
            "776/1001, train_loss: 1.0000, step time: 0.6245\n",
            "777/1001, train_loss: 0.0781, step time: 0.6740\n",
            "778/1001, train_loss: 0.0620, step time: 0.6592\n",
            "779/1001, train_loss: 0.8973, step time: 0.6552\n",
            "780/1001, train_loss: 0.1998, step time: 0.6513\n",
            "781/1001, train_loss: 0.0444, step time: 0.6720\n",
            "782/1001, train_loss: 0.1388, step time: 0.6729\n",
            "783/1001, train_loss: 0.0933, step time: 0.6612\n",
            "784/1001, train_loss: 0.0710, step time: 0.6474\n",
            "785/1001, train_loss: 0.0562, step time: 0.6498\n",
            "786/1001, train_loss: 0.0553, step time: 0.6546\n",
            "787/1001, train_loss: 0.7515, step time: 0.6774\n",
            "788/1001, train_loss: 0.9939, step time: 0.6523\n",
            "789/1001, train_loss: 0.0396, step time: 0.6473\n",
            "790/1001, train_loss: 1.0000, step time: 0.6267\n",
            "791/1001, train_loss: 0.6806, step time: 0.6467\n",
            "792/1001, train_loss: 0.0914, step time: 0.6534\n",
            "793/1001, train_loss: 0.1345, step time: 0.6525\n",
            "794/1001, train_loss: 0.8132, step time: 0.6592\n",
            "795/1001, train_loss: 0.0629, step time: 0.6869\n",
            "796/1001, train_loss: 0.1664, step time: 0.6506\n",
            "797/1001, train_loss: 0.0472, step time: 0.6811\n",
            "798/1001, train_loss: 0.0603, step time: 0.6596\n",
            "799/1001, train_loss: 0.0844, step time: 0.6736\n",
            "800/1001, train_loss: 0.0669, step time: 0.6790\n",
            "801/1001, train_loss: 1.0000, step time: 0.6519\n",
            "802/1001, train_loss: 0.0446, step time: 0.6609\n",
            "803/1001, train_loss: 0.0427, step time: 0.6848\n",
            "804/1001, train_loss: 0.0312, step time: 0.6659\n",
            "805/1001, train_loss: 0.2001, step time: 0.6843\n",
            "806/1001, train_loss: 0.0385, step time: 0.6789\n",
            "807/1001, train_loss: 0.3028, step time: 0.6722\n",
            "808/1001, train_loss: 0.0575, step time: 0.6475\n",
            "809/1001, train_loss: 0.0401, step time: 0.6475\n",
            "810/1001, train_loss: 0.0512, step time: 0.6492\n",
            "811/1001, train_loss: 1.0000, step time: 0.6232\n",
            "812/1001, train_loss: 0.0496, step time: 0.6507\n",
            "813/1001, train_loss: 0.0975, step time: 0.6495\n",
            "814/1001, train_loss: 0.0405, step time: 0.6522\n",
            "815/1001, train_loss: 0.1083, step time: 0.6851\n",
            "816/1001, train_loss: 0.0332, step time: 0.6714\n",
            "817/1001, train_loss: 1.0000, step time: 0.6246\n",
            "818/1001, train_loss: 0.0436, step time: 0.6470\n",
            "819/1001, train_loss: 0.0460, step time: 0.6470\n",
            "820/1001, train_loss: 0.0497, step time: 0.6652\n",
            "821/1001, train_loss: 0.0445, step time: 0.6510\n",
            "822/1001, train_loss: 0.0864, step time: 0.6800\n",
            "823/1001, train_loss: 0.1181, step time: 0.6752\n",
            "824/1001, train_loss: 0.8379, step time: 0.6586\n",
            "825/1001, train_loss: 0.1007, step time: 0.6538\n",
            "826/1001, train_loss: 0.1502, step time: 0.6685\n",
            "827/1001, train_loss: 1.0000, step time: 0.6252\n",
            "828/1001, train_loss: 0.2047, step time: 0.6866\n",
            "829/1001, train_loss: 0.0886, step time: 0.6714\n",
            "830/1001, train_loss: 0.0427, step time: 0.6910\n",
            "831/1001, train_loss: 0.0898, step time: 0.6503\n",
            "832/1001, train_loss: 0.1239, step time: 0.6549\n",
            "833/1001, train_loss: 0.0960, step time: 0.6501\n",
            "834/1001, train_loss: 0.1539, step time: 0.6509\n",
            "835/1001, train_loss: 0.7253, step time: 0.6496\n",
            "836/1001, train_loss: 0.0900, step time: 0.6556\n",
            "837/1001, train_loss: 0.1037, step time: 0.6599\n",
            "838/1001, train_loss: 0.0676, step time: 0.6465\n",
            "839/1001, train_loss: 0.7582, step time: 0.6519\n",
            "840/1001, train_loss: 0.6981, step time: 0.6501\n",
            "841/1001, train_loss: 0.0763, step time: 0.6546\n",
            "842/1001, train_loss: 0.6361, step time: 0.6547\n",
            "843/1001, train_loss: 1.0000, step time: 0.6242\n",
            "844/1001, train_loss: 0.2404, step time: 0.6746\n",
            "845/1001, train_loss: 0.6531, step time: 0.6552\n",
            "846/1001, train_loss: 0.0647, step time: 0.6492\n",
            "847/1001, train_loss: 0.0431, step time: 0.6474\n",
            "848/1001, train_loss: 1.0000, step time: 0.6269\n",
            "849/1001, train_loss: 0.1999, step time: 0.6609\n",
            "850/1001, train_loss: 0.4555, step time: 0.7009\n",
            "851/1001, train_loss: 0.7647, step time: 0.6520\n",
            "852/1001, train_loss: 0.1033, step time: 0.6495\n",
            "853/1001, train_loss: 0.2260, step time: 0.6521\n",
            "854/1001, train_loss: 0.9821, step time: 0.6477\n",
            "855/1001, train_loss: 0.0581, step time: 0.6558\n",
            "856/1001, train_loss: 0.1509, step time: 0.6567\n",
            "857/1001, train_loss: 0.0470, step time: 0.6486\n",
            "858/1001, train_loss: 0.1282, step time: 0.6595\n",
            "859/1001, train_loss: 0.1634, step time: 0.6525\n",
            "860/1001, train_loss: 0.0744, step time: 0.6672\n",
            "861/1001, train_loss: 0.6764, step time: 0.6821\n",
            "862/1001, train_loss: 0.1150, step time: 0.6499\n",
            "863/1001, train_loss: 0.0832, step time: 0.6495\n",
            "864/1001, train_loss: 1.0000, step time: 0.6282\n",
            "865/1001, train_loss: 1.0000, step time: 0.6227\n",
            "866/1001, train_loss: 0.0683, step time: 0.6531\n",
            "867/1001, train_loss: 0.0988, step time: 0.6608\n",
            "868/1001, train_loss: 0.7319, step time: 0.6517\n",
            "869/1001, train_loss: 0.7544, step time: 0.6561\n",
            "870/1001, train_loss: 0.1215, step time: 0.6513\n",
            "871/1001, train_loss: 0.0210, step time: 0.6454\n",
            "872/1001, train_loss: 0.0651, step time: 0.6467\n",
            "873/1001, train_loss: 0.0440, step time: 0.6580\n",
            "874/1001, train_loss: 0.1152, step time: 0.6586\n",
            "875/1001, train_loss: 0.1072, step time: 0.6803\n",
            "876/1001, train_loss: 0.6831, step time: 0.6525\n",
            "877/1001, train_loss: 0.0629, step time: 0.6508\n",
            "878/1001, train_loss: 0.3409, step time: 0.6579\n",
            "879/1001, train_loss: 0.0808, step time: 0.6486\n",
            "880/1001, train_loss: 0.7536, step time: 0.6557\n",
            "881/1001, train_loss: 0.0433, step time: 0.6518\n",
            "882/1001, train_loss: 1.0000, step time: 0.6248\n",
            "883/1001, train_loss: 0.9777, step time: 0.6548\n",
            "884/1001, train_loss: 0.0486, step time: 0.6535\n",
            "885/1001, train_loss: 0.9148, step time: 0.6683\n",
            "886/1001, train_loss: 0.0450, step time: 0.7017\n",
            "887/1001, train_loss: 0.0685, step time: 0.6524\n",
            "888/1001, train_loss: 0.0453, step time: 0.6476\n",
            "889/1001, train_loss: 0.2011, step time: 0.6513\n",
            "890/1001, train_loss: 0.1064, step time: 0.6530\n",
            "891/1001, train_loss: 0.0506, step time: 0.6826\n",
            "892/1001, train_loss: 0.7058, step time: 0.6559\n",
            "893/1001, train_loss: 1.0000, step time: 0.6448\n",
            "894/1001, train_loss: 0.0443, step time: 0.6642\n",
            "895/1001, train_loss: 0.0588, step time: 0.6555\n",
            "896/1001, train_loss: 0.0393, step time: 0.6494\n",
            "897/1001, train_loss: 0.1136, step time: 0.6550\n",
            "898/1001, train_loss: 0.9399, step time: 0.6577\n",
            "899/1001, train_loss: 0.5060, step time: 0.6635\n",
            "900/1001, train_loss: 0.1525, step time: 0.6568\n",
            "901/1001, train_loss: 0.0626, step time: 0.6750\n",
            "902/1001, train_loss: 0.6906, step time: 0.6712\n",
            "903/1001, train_loss: 0.6845, step time: 0.6471\n",
            "904/1001, train_loss: 0.0422, step time: 0.6475\n",
            "905/1001, train_loss: 0.0934, step time: 0.6540\n",
            "906/1001, train_loss: 0.7385, step time: 0.6763\n",
            "907/1001, train_loss: 0.0823, step time: 0.6686\n",
            "908/1001, train_loss: 0.7535, step time: 0.6792\n",
            "909/1001, train_loss: 0.0461, step time: 0.6807\n",
            "910/1001, train_loss: 0.0345, step time: 0.6606\n",
            "911/1001, train_loss: 0.7901, step time: 0.6681\n",
            "912/1001, train_loss: 0.1517, step time: 0.6818\n",
            "913/1001, train_loss: 0.0445, step time: 0.6471\n",
            "914/1001, train_loss: 0.0455, step time: 0.7062\n",
            "915/1001, train_loss: 0.4829, step time: 0.6574\n",
            "916/1001, train_loss: 0.1263, step time: 0.6520\n",
            "917/1001, train_loss: 0.0604, step time: 0.6514\n",
            "918/1001, train_loss: 0.7419, step time: 0.6514\n",
            "919/1001, train_loss: 0.6744, step time: 0.6440\n",
            "920/1001, train_loss: 0.1915, step time: 0.6530\n",
            "921/1001, train_loss: 0.9975, step time: 0.6696\n",
            "922/1001, train_loss: 0.0656, step time: 0.6536\n",
            "923/1001, train_loss: 0.0577, step time: 0.6718\n",
            "924/1001, train_loss: 1.0000, step time: 0.6273\n",
            "925/1001, train_loss: 0.0520, step time: 0.6483\n",
            "926/1001, train_loss: 0.0397, step time: 0.6512\n",
            "927/1001, train_loss: 0.1158, step time: 0.6639\n",
            "928/1001, train_loss: 0.0467, step time: 0.6496\n",
            "929/1001, train_loss: 0.1773, step time: 0.6553\n",
            "930/1001, train_loss: 0.7295, step time: 0.6521\n",
            "931/1001, train_loss: 0.1196, step time: 0.6556\n",
            "932/1001, train_loss: 0.0512, step time: 0.6504\n",
            "933/1001, train_loss: 0.2754, step time: 0.6541\n",
            "934/1001, train_loss: 0.4025, step time: 0.6559\n",
            "935/1001, train_loss: 0.0580, step time: 0.6508\n",
            "936/1001, train_loss: 0.4096, step time: 0.6573\n",
            "937/1001, train_loss: 0.0466, step time: 0.6514\n",
            "938/1001, train_loss: 0.3514, step time: 0.6579\n",
            "939/1001, train_loss: 0.0645, step time: 0.6544\n",
            "940/1001, train_loss: 0.0716, step time: 0.6540\n",
            "941/1001, train_loss: 0.0388, step time: 0.6566\n",
            "942/1001, train_loss: 0.0535, step time: 0.6469\n",
            "943/1001, train_loss: 0.7913, step time: 0.6549\n",
            "944/1001, train_loss: 0.6733, step time: 0.6371\n",
            "945/1001, train_loss: 0.0449, step time: 0.6813\n",
            "946/1001, train_loss: 0.2372, step time: 0.6591\n",
            "947/1001, train_loss: 0.0483, step time: 0.6491\n",
            "948/1001, train_loss: 0.3195, step time: 0.6506\n",
            "949/1001, train_loss: 1.0000, step time: 0.6265\n",
            "950/1001, train_loss: 0.0596, step time: 0.6491\n",
            "951/1001, train_loss: 0.6985, step time: 0.6515\n",
            "952/1001, train_loss: 0.3795, step time: 0.6742\n",
            "953/1001, train_loss: 0.0555, step time: 0.6498\n",
            "954/1001, train_loss: 0.0689, step time: 0.6512\n",
            "955/1001, train_loss: 1.0000, step time: 0.6284\n",
            "956/1001, train_loss: 0.3908, step time: 0.6875\n",
            "957/1001, train_loss: 0.0460, step time: 0.6498\n",
            "958/1001, train_loss: 0.1090, step time: 0.6500\n",
            "959/1001, train_loss: 0.1104, step time: 0.6556\n",
            "960/1001, train_loss: 0.0571, step time: 0.6470\n",
            "961/1001, train_loss: 0.0538, step time: 0.6530\n",
            "962/1001, train_loss: 0.0799, step time: 0.6741\n",
            "963/1001, train_loss: 0.6922, step time: 0.6561\n",
            "964/1001, train_loss: 0.0419, step time: 0.6513\n",
            "965/1001, train_loss: 0.3043, step time: 0.6514\n",
            "966/1001, train_loss: 0.1119, step time: 0.6655\n",
            "967/1001, train_loss: 0.0440, step time: 0.6650\n",
            "968/1001, train_loss: 0.0382, step time: 0.6543\n",
            "969/1001, train_loss: 0.0881, step time: 0.6550\n",
            "970/1001, train_loss: 0.0463, step time: 0.6505\n",
            "971/1001, train_loss: 0.0866, step time: 0.6681\n",
            "972/1001, train_loss: 0.0813, step time: 0.6496\n",
            "973/1001, train_loss: 0.0641, step time: 0.6528\n",
            "974/1001, train_loss: 0.4183, step time: 0.6471\n",
            "975/1001, train_loss: 0.1436, step time: 0.6565\n",
            "976/1001, train_loss: 0.0504, step time: 0.6505\n",
            "977/1001, train_loss: 0.8052, step time: 0.6545\n",
            "978/1001, train_loss: 0.7763, step time: 0.6519\n",
            "979/1001, train_loss: 0.9986, step time: 0.6421\n",
            "980/1001, train_loss: 0.0999, step time: 0.6522\n",
            "981/1001, train_loss: 0.7730, step time: 0.6620\n",
            "982/1001, train_loss: 0.0337, step time: 0.6526\n",
            "983/1001, train_loss: 1.0000, step time: 0.6284\n",
            "984/1001, train_loss: 0.6647, step time: 0.6593\n",
            "985/1001, train_loss: 0.1110, step time: 0.6555\n",
            "986/1001, train_loss: 0.1309, step time: 0.6494\n",
            "987/1001, train_loss: 0.1209, step time: 0.6495\n",
            "988/1001, train_loss: 0.1168, step time: 0.6467\n",
            "989/1001, train_loss: 0.0680, step time: 0.6475\n",
            "990/1001, train_loss: 0.7721, step time: 0.6513\n",
            "991/1001, train_loss: 0.0519, step time: 0.6470\n",
            "992/1001, train_loss: 0.9909, step time: 0.6444\n",
            "993/1001, train_loss: 0.4248, step time: 0.6514\n",
            "994/1001, train_loss: 0.1409, step time: 0.6504\n",
            "995/1001, train_loss: 0.2168, step time: 0.6527\n",
            "996/1001, train_loss: 0.0966, step time: 0.6492\n",
            "997/1001, train_loss: 0.0288, step time: 0.6430\n",
            "998/1001, train_loss: 0.1480, step time: 0.6483\n",
            "999/1001, train_loss: 0.5068, step time: 0.6514\n",
            "1000/1001, train_loss: 0.1707, step time: 0.6491\n",
            "1001/1001, train_loss: 0.0658, step time: 0.6467\n",
            "epoch 19 average loss: 0.2787\n",
            "saved new best metric model\n",
            "current epoch: 19 current mean dice: 0.8719 tc: 0.8627 wt: 0.9110 et: 0.8455\n",
            "best mean dice: 0.8719 at epoch: 19\n",
            "time consuming of epoch 19 is: 839.2551\n",
            "----------\n",
            "epoch 20/20\n",
            "1/1001, train_loss: 0.3559, step time: 0.7271\n",
            "2/1001, train_loss: 0.4909, step time: 0.7037\n",
            "3/1001, train_loss: 0.0565, step time: 0.7193\n",
            "4/1001, train_loss: 0.0855, step time: 0.6638\n",
            "5/1001, train_loss: 0.1973, step time: 0.6573\n",
            "6/1001, train_loss: 0.0400, step time: 0.6586\n",
            "7/1001, train_loss: 0.0801, step time: 0.6486\n",
            "8/1001, train_loss: 0.1070, step time: 0.6517\n",
            "9/1001, train_loss: 0.6301, step time: 0.6521\n",
            "10/1001, train_loss: 0.0597, step time: 0.6593\n",
            "11/1001, train_loss: 0.6162, step time: 0.6780\n",
            "12/1001, train_loss: 0.0515, step time: 0.6641\n",
            "13/1001, train_loss: 0.0957, step time: 0.6519\n",
            "14/1001, train_loss: 0.0553, step time: 0.6502\n",
            "15/1001, train_loss: 0.0420, step time: 0.6475\n",
            "16/1001, train_loss: 0.0450, step time: 0.6500\n",
            "17/1001, train_loss: 0.9138, step time: 0.6515\n",
            "18/1001, train_loss: 0.1288, step time: 0.6521\n",
            "19/1001, train_loss: 0.1001, step time: 0.6501\n",
            "20/1001, train_loss: 0.1340, step time: 0.6527\n",
            "21/1001, train_loss: 0.1534, step time: 0.6509\n",
            "22/1001, train_loss: 0.1887, step time: 0.6508\n",
            "23/1001, train_loss: 0.0664, step time: 0.6475\n",
            "24/1001, train_loss: 0.0469, step time: 0.6489\n",
            "25/1001, train_loss: 0.0362, step time: 0.6693\n",
            "26/1001, train_loss: 0.0772, step time: 0.6518\n",
            "27/1001, train_loss: 0.0553, step time: 0.6504\n",
            "28/1001, train_loss: 0.0513, step time: 0.6517\n",
            "29/1001, train_loss: 0.2410, step time: 0.6763\n",
            "30/1001, train_loss: 0.9905, step time: 0.6474\n",
            "31/1001, train_loss: 0.0735, step time: 0.6693\n",
            "32/1001, train_loss: 0.0501, step time: 0.6490\n",
            "33/1001, train_loss: 0.0443, step time: 0.6478\n",
            "34/1001, train_loss: 0.7488, step time: 0.6778\n",
            "35/1001, train_loss: 0.5384, step time: 0.6568\n",
            "36/1001, train_loss: 0.0494, step time: 0.6518\n",
            "37/1001, train_loss: 0.0597, step time: 0.6564\n",
            "38/1001, train_loss: 0.2204, step time: 0.6718\n",
            "39/1001, train_loss: 0.0723, step time: 0.6528\n",
            "40/1001, train_loss: 0.0407, step time: 0.6461\n",
            "41/1001, train_loss: 0.2588, step time: 0.6500\n",
            "42/1001, train_loss: 0.1441, step time: 0.6522\n",
            "43/1001, train_loss: 0.2580, step time: 0.6533\n",
            "44/1001, train_loss: 0.6818, step time: 0.7007\n",
            "45/1001, train_loss: 1.0000, step time: 0.6272\n",
            "46/1001, train_loss: 0.0791, step time: 0.6538\n",
            "47/1001, train_loss: 0.7477, step time: 0.6503\n",
            "48/1001, train_loss: 0.1311, step time: 0.6648\n",
            "49/1001, train_loss: 0.0379, step time: 0.6826\n",
            "50/1001, train_loss: 0.7093, step time: 0.6703\n",
            "51/1001, train_loss: 0.1583, step time: 0.6518\n",
            "52/1001, train_loss: 0.0349, step time: 0.6514\n",
            "53/1001, train_loss: 0.3375, step time: 0.6826\n",
            "54/1001, train_loss: 0.1542, step time: 0.6857\n",
            "55/1001, train_loss: 0.0490, step time: 0.6838\n",
            "56/1001, train_loss: 0.0701, step time: 0.6532\n",
            "57/1001, train_loss: 0.0834, step time: 0.6636\n",
            "58/1001, train_loss: 0.9966, step time: 0.6427\n",
            "59/1001, train_loss: 0.2015, step time: 0.6498\n",
            "60/1001, train_loss: 0.0456, step time: 0.6493\n",
            "61/1001, train_loss: 0.1377, step time: 0.6552\n",
            "62/1001, train_loss: 0.7772, step time: 0.6616\n",
            "63/1001, train_loss: 0.4569, step time: 0.6504\n",
            "64/1001, train_loss: 0.0728, step time: 0.6542\n",
            "65/1001, train_loss: 0.2965, step time: 0.6612\n",
            "66/1001, train_loss: 0.6817, step time: 0.6430\n",
            "67/1001, train_loss: 0.0394, step time: 0.6562\n",
            "68/1001, train_loss: 0.0359, step time: 0.6582\n",
            "69/1001, train_loss: 0.2006, step time: 0.6565\n",
            "70/1001, train_loss: 0.0795, step time: 0.6584\n",
            "71/1001, train_loss: 1.0000, step time: 0.6243\n",
            "72/1001, train_loss: 0.0396, step time: 0.6559\n",
            "73/1001, train_loss: 0.0299, step time: 0.6448\n",
            "74/1001, train_loss: 0.0541, step time: 0.6688\n",
            "75/1001, train_loss: 0.0629, step time: 0.6490\n",
            "76/1001, train_loss: 0.1382, step time: 0.6774\n",
            "77/1001, train_loss: 0.0519, step time: 0.6532\n",
            "78/1001, train_loss: 0.0835, step time: 0.6500\n",
            "79/1001, train_loss: 0.0550, step time: 0.6497\n",
            "80/1001, train_loss: 0.2173, step time: 0.6492\n",
            "81/1001, train_loss: 0.1157, step time: 0.6695\n",
            "82/1001, train_loss: 0.0505, step time: 0.6490\n",
            "83/1001, train_loss: 0.0530, step time: 0.6665\n",
            "84/1001, train_loss: 0.0876, step time: 0.6488\n",
            "85/1001, train_loss: 0.2553, step time: 0.6532\n",
            "86/1001, train_loss: 0.6968, step time: 0.6516\n",
            "87/1001, train_loss: 0.0700, step time: 0.6510\n",
            "88/1001, train_loss: 0.0823, step time: 0.6503\n",
            "89/1001, train_loss: 0.0739, step time: 0.6524\n",
            "90/1001, train_loss: 0.0490, step time: 0.6810\n",
            "91/1001, train_loss: 0.0587, step time: 0.6494\n",
            "92/1001, train_loss: 0.0523, step time: 0.6786\n",
            "93/1001, train_loss: 0.0485, step time: 0.6504\n",
            "94/1001, train_loss: 0.5630, step time: 0.6527\n",
            "95/1001, train_loss: 1.0000, step time: 0.6231\n",
            "96/1001, train_loss: 1.0000, step time: 0.6302\n",
            "97/1001, train_loss: 0.8957, step time: 0.6685\n",
            "98/1001, train_loss: 0.1164, step time: 0.6772\n",
            "99/1001, train_loss: 1.0000, step time: 0.6567\n",
            "100/1001, train_loss: 0.4246, step time: 0.6695\n",
            "101/1001, train_loss: 0.0419, step time: 0.6496\n",
            "102/1001, train_loss: 0.0463, step time: 0.6482\n",
            "103/1001, train_loss: 0.7544, step time: 0.6545\n",
            "104/1001, train_loss: 0.0583, step time: 0.6564\n",
            "105/1001, train_loss: 0.2019, step time: 0.6544\n",
            "106/1001, train_loss: 0.9475, step time: 0.6519\n",
            "107/1001, train_loss: 1.0000, step time: 0.6300\n",
            "108/1001, train_loss: 0.2676, step time: 0.6525\n",
            "109/1001, train_loss: 0.0632, step time: 0.6720\n",
            "110/1001, train_loss: 0.3201, step time: 0.6832\n",
            "111/1001, train_loss: 0.0387, step time: 0.6738\n",
            "112/1001, train_loss: 0.0345, step time: 0.6458\n",
            "113/1001, train_loss: 0.0431, step time: 0.6466\n",
            "114/1001, train_loss: 0.1953, step time: 0.6789\n",
            "115/1001, train_loss: 0.4511, step time: 0.6898\n",
            "116/1001, train_loss: 0.0457, step time: 0.6511\n",
            "117/1001, train_loss: 0.2555, step time: 0.6519\n",
            "118/1001, train_loss: 0.5273, step time: 0.6534\n",
            "119/1001, train_loss: 0.4170, step time: 0.6585\n",
            "120/1001, train_loss: 0.0665, step time: 0.6507\n",
            "121/1001, train_loss: 0.0343, step time: 0.6493\n",
            "122/1001, train_loss: 0.0481, step time: 0.6482\n",
            "123/1001, train_loss: 0.8871, step time: 0.6517\n",
            "124/1001, train_loss: 0.2904, step time: 0.6518\n",
            "125/1001, train_loss: 0.0800, step time: 0.6499\n",
            "126/1001, train_loss: 0.9723, step time: 0.6503\n",
            "127/1001, train_loss: 0.3108, step time: 0.6646\n",
            "128/1001, train_loss: 0.1098, step time: 0.6592\n",
            "129/1001, train_loss: 0.0716, step time: 0.6479\n",
            "130/1001, train_loss: 1.0000, step time: 0.6230\n",
            "131/1001, train_loss: 0.0598, step time: 0.6498\n",
            "132/1001, train_loss: 0.0533, step time: 0.6495\n",
            "133/1001, train_loss: 0.0853, step time: 0.6531\n",
            "134/1001, train_loss: 0.1745, step time: 0.6689\n",
            "135/1001, train_loss: 0.0853, step time: 0.6489\n",
            "136/1001, train_loss: 0.4813, step time: 0.6521\n",
            "137/1001, train_loss: 0.3488, step time: 0.6529\n",
            "138/1001, train_loss: 0.1044, step time: 0.6560\n",
            "139/1001, train_loss: 0.0531, step time: 0.6505\n",
            "140/1001, train_loss: 0.0596, step time: 0.6480\n",
            "141/1001, train_loss: 0.0493, step time: 0.6693\n",
            "142/1001, train_loss: 1.0000, step time: 0.6266\n",
            "143/1001, train_loss: 0.4709, step time: 0.6569\n",
            "144/1001, train_loss: 0.1372, step time: 0.6845\n",
            "145/1001, train_loss: 0.5665, step time: 0.6612\n",
            "146/1001, train_loss: 0.6818, step time: 0.6427\n",
            "147/1001, train_loss: 0.0596, step time: 0.6502\n",
            "148/1001, train_loss: 0.2002, step time: 0.6784\n",
            "149/1001, train_loss: 0.0700, step time: 0.6536\n",
            "150/1001, train_loss: 0.0247, step time: 0.6529\n",
            "151/1001, train_loss: 0.2529, step time: 0.6722\n",
            "152/1001, train_loss: 1.0000, step time: 0.6281\n",
            "153/1001, train_loss: 0.6234, step time: 0.6507\n",
            "154/1001, train_loss: 0.1300, step time: 0.6512\n",
            "155/1001, train_loss: 0.1160, step time: 0.6670\n",
            "156/1001, train_loss: 0.0790, step time: 0.6515\n",
            "157/1001, train_loss: 0.0329, step time: 0.6467\n",
            "158/1001, train_loss: 0.0515, step time: 0.6580\n",
            "159/1001, train_loss: 0.1033, step time: 0.6572\n",
            "160/1001, train_loss: 0.2750, step time: 0.6520\n",
            "161/1001, train_loss: 0.1682, step time: 0.6511\n",
            "162/1001, train_loss: 0.0672, step time: 0.6482\n",
            "163/1001, train_loss: 0.4124, step time: 0.6482\n",
            "164/1001, train_loss: 0.0260, step time: 0.6840\n",
            "165/1001, train_loss: 0.0691, step time: 0.6506\n",
            "166/1001, train_loss: 0.2045, step time: 0.6563\n",
            "167/1001, train_loss: 0.0799, step time: 0.6789\n",
            "168/1001, train_loss: 0.0740, step time: 0.6617\n",
            "169/1001, train_loss: 0.0606, step time: 0.6531\n",
            "170/1001, train_loss: 0.0807, step time: 0.6493\n",
            "171/1001, train_loss: 0.0420, step time: 0.6829\n",
            "172/1001, train_loss: 0.1377, step time: 0.7621\n",
            "173/1001, train_loss: 0.4244, step time: 0.6564\n",
            "174/1001, train_loss: 0.1299, step time: 0.6514\n",
            "175/1001, train_loss: 0.1002, step time: 0.6551\n",
            "176/1001, train_loss: 0.4115, step time: 0.6520\n",
            "177/1001, train_loss: 0.0379, step time: 0.6851\n",
            "178/1001, train_loss: 0.0629, step time: 0.6620\n",
            "179/1001, train_loss: 0.0746, step time: 0.6746\n",
            "180/1001, train_loss: 0.1422, step time: 0.6519\n",
            "181/1001, train_loss: 0.7562, step time: 0.6586\n",
            "182/1001, train_loss: 0.0998, step time: 0.6507\n",
            "183/1001, train_loss: 0.1733, step time: 0.6516\n",
            "184/1001, train_loss: 0.1745, step time: 0.6504\n",
            "185/1001, train_loss: 0.0482, step time: 0.6451\n",
            "186/1001, train_loss: 0.6775, step time: 0.6531\n",
            "187/1001, train_loss: 0.0741, step time: 0.6872\n",
            "188/1001, train_loss: 0.0423, step time: 0.6828\n",
            "189/1001, train_loss: 0.3063, step time: 0.6505\n",
            "190/1001, train_loss: 0.0875, step time: 0.6514\n",
            "191/1001, train_loss: 0.1131, step time: 0.6498\n",
            "192/1001, train_loss: 0.0506, step time: 0.6616\n",
            "193/1001, train_loss: 0.7782, step time: 0.6551\n",
            "194/1001, train_loss: 0.0871, step time: 0.6514\n",
            "195/1001, train_loss: 0.1578, step time: 0.6766\n",
            "196/1001, train_loss: 0.0643, step time: 0.6561\n",
            "197/1001, train_loss: 0.0553, step time: 0.6632\n",
            "198/1001, train_loss: 0.2366, step time: 0.6612\n",
            "199/1001, train_loss: 0.0596, step time: 0.6777\n",
            "200/1001, train_loss: 0.7159, step time: 0.6569\n",
            "201/1001, train_loss: 0.4398, step time: 0.6503\n",
            "202/1001, train_loss: 0.0547, step time: 0.6638\n",
            "203/1001, train_loss: 0.0674, step time: 0.6487\n",
            "204/1001, train_loss: 0.0813, step time: 0.6746\n",
            "205/1001, train_loss: 0.0492, step time: 0.6473\n",
            "206/1001, train_loss: 0.0497, step time: 0.6513\n",
            "207/1001, train_loss: 0.0858, step time: 0.6694\n",
            "208/1001, train_loss: 0.0392, step time: 0.6760\n",
            "209/1001, train_loss: 1.0000, step time: 0.6235\n",
            "210/1001, train_loss: 0.0656, step time: 0.6565\n",
            "211/1001, train_loss: 0.2493, step time: 0.6768\n",
            "212/1001, train_loss: 0.7132, step time: 0.6881\n",
            "213/1001, train_loss: 0.0516, step time: 0.6482\n",
            "214/1001, train_loss: 0.1125, step time: 0.6522\n",
            "215/1001, train_loss: 0.5261, step time: 0.6796\n",
            "216/1001, train_loss: 0.1454, step time: 0.6517\n",
            "217/1001, train_loss: 0.1688, step time: 0.6595\n",
            "218/1001, train_loss: 0.4364, step time: 0.6642\n",
            "219/1001, train_loss: 0.4674, step time: 0.6571\n",
            "220/1001, train_loss: 0.1065, step time: 0.6587\n",
            "221/1001, train_loss: 0.0632, step time: 0.6794\n",
            "222/1001, train_loss: 1.0000, step time: 0.6520\n",
            "223/1001, train_loss: 0.0763, step time: 0.6496\n",
            "224/1001, train_loss: 0.0547, step time: 0.6514\n",
            "225/1001, train_loss: 0.0823, step time: 0.6645\n",
            "226/1001, train_loss: 0.1104, step time: 0.6503\n",
            "227/1001, train_loss: 0.0596, step time: 0.6782\n",
            "228/1001, train_loss: 0.6992, step time: 0.6633\n",
            "229/1001, train_loss: 0.0499, step time: 0.6498\n",
            "230/1001, train_loss: 0.0864, step time: 0.6581\n",
            "231/1001, train_loss: 0.2280, step time: 0.6766\n",
            "232/1001, train_loss: 0.0351, step time: 0.6722\n",
            "233/1001, train_loss: 0.8109, step time: 0.6764\n",
            "234/1001, train_loss: 1.0000, step time: 0.6312\n",
            "235/1001, train_loss: 0.0375, step time: 0.6462\n",
            "236/1001, train_loss: 0.4690, step time: 0.6523\n",
            "237/1001, train_loss: 0.9728, step time: 0.6482\n",
            "238/1001, train_loss: 0.0385, step time: 0.6449\n",
            "239/1001, train_loss: 0.0439, step time: 0.6646\n",
            "240/1001, train_loss: 0.0291, step time: 0.6572\n",
            "241/1001, train_loss: 0.1562, step time: 0.6516\n",
            "242/1001, train_loss: 0.0509, step time: 0.6504\n",
            "243/1001, train_loss: 0.8177, step time: 0.6529\n",
            "244/1001, train_loss: 0.0655, step time: 0.6460\n",
            "245/1001, train_loss: 1.0000, step time: 0.6241\n",
            "246/1001, train_loss: 0.1442, step time: 0.6784\n",
            "247/1001, train_loss: 0.0675, step time: 0.6511\n",
            "248/1001, train_loss: 0.0836, step time: 0.6870\n",
            "249/1001, train_loss: 0.1231, step time: 0.6571\n",
            "250/1001, train_loss: 0.0495, step time: 0.6558\n",
            "251/1001, train_loss: 0.3733, step time: 0.6523\n",
            "252/1001, train_loss: 0.7321, step time: 0.6538\n",
            "253/1001, train_loss: 0.0515, step time: 0.6487\n",
            "254/1001, train_loss: 0.0641, step time: 0.6495\n",
            "255/1001, train_loss: 0.1163, step time: 0.6556\n",
            "256/1001, train_loss: 0.1922, step time: 0.6554\n",
            "257/1001, train_loss: 0.4895, step time: 0.6653\n",
            "258/1001, train_loss: 0.3287, step time: 0.6736\n",
            "259/1001, train_loss: 0.0509, step time: 0.6521\n",
            "260/1001, train_loss: 0.0512, step time: 0.6722\n",
            "261/1001, train_loss: 0.2703, step time: 0.6569\n",
            "262/1001, train_loss: 0.8247, step time: 0.6519\n",
            "263/1001, train_loss: 0.1081, step time: 0.6540\n",
            "264/1001, train_loss: 0.1180, step time: 0.6781\n",
            "265/1001, train_loss: 0.3909, step time: 0.6553\n",
            "266/1001, train_loss: 0.1501, step time: 0.6523\n",
            "267/1001, train_loss: 0.0433, step time: 0.6441\n",
            "268/1001, train_loss: 0.0655, step time: 0.6649\n",
            "269/1001, train_loss: 0.4055, step time: 0.6672\n",
            "270/1001, train_loss: 0.0513, step time: 0.6543\n",
            "271/1001, train_loss: 0.0730, step time: 0.6690\n",
            "272/1001, train_loss: 0.2137, step time: 0.6522\n",
            "273/1001, train_loss: 0.7110, step time: 0.6753\n",
            "274/1001, train_loss: 0.0589, step time: 0.6708\n",
            "275/1001, train_loss: 0.0365, step time: 0.6496\n",
            "276/1001, train_loss: 0.0837, step time: 0.6581\n",
            "277/1001, train_loss: 0.0857, step time: 0.6572\n",
            "278/1001, train_loss: 0.0605, step time: 0.6482\n",
            "279/1001, train_loss: 0.0800, step time: 0.6512\n",
            "280/1001, train_loss: 0.0447, step time: 0.6457\n",
            "281/1001, train_loss: 1.0000, step time: 0.6233\n",
            "282/1001, train_loss: 0.1248, step time: 0.6669\n",
            "283/1001, train_loss: 0.6134, step time: 0.6510\n",
            "284/1001, train_loss: 0.0455, step time: 0.6468\n",
            "285/1001, train_loss: 0.1570, step time: 0.6597\n",
            "286/1001, train_loss: 0.2638, step time: 0.6701\n",
            "287/1001, train_loss: 0.1541, step time: 0.6557\n",
            "288/1001, train_loss: 0.1502, step time: 0.6982\n",
            "289/1001, train_loss: 0.3722, step time: 0.6534\n",
            "290/1001, train_loss: 0.0582, step time: 0.6492\n",
            "291/1001, train_loss: 0.9467, step time: 0.6538\n",
            "292/1001, train_loss: 0.1175, step time: 0.6535\n",
            "293/1001, train_loss: 0.0917, step time: 0.6532\n",
            "294/1001, train_loss: 0.1458, step time: 0.6540\n",
            "295/1001, train_loss: 0.2638, step time: 0.6591\n",
            "296/1001, train_loss: 0.0470, step time: 0.6657\n",
            "297/1001, train_loss: 0.5608, step time: 0.6579\n",
            "298/1001, train_loss: 0.0401, step time: 0.6639\n",
            "299/1001, train_loss: 0.0741, step time: 0.6497\n",
            "300/1001, train_loss: 0.1703, step time: 0.6529\n",
            "301/1001, train_loss: 0.0433, step time: 0.6544\n",
            "302/1001, train_loss: 0.1349, step time: 0.6728\n",
            "303/1001, train_loss: 0.1494, step time: 0.6620\n",
            "304/1001, train_loss: 0.0909, step time: 0.6726\n",
            "305/1001, train_loss: 0.0826, step time: 0.6565\n",
            "306/1001, train_loss: 0.9609, step time: 0.6548\n",
            "307/1001, train_loss: 0.2517, step time: 0.6526\n",
            "308/1001, train_loss: 0.0826, step time: 0.6475\n",
            "309/1001, train_loss: 0.0484, step time: 0.6687\n",
            "310/1001, train_loss: 0.1933, step time: 0.6626\n",
            "311/1001, train_loss: 0.0475, step time: 0.6488\n",
            "312/1001, train_loss: 0.0480, step time: 0.6455\n",
            "313/1001, train_loss: 0.9973, step time: 0.6426\n",
            "314/1001, train_loss: 0.7199, step time: 0.6513\n",
            "315/1001, train_loss: 0.0615, step time: 0.6650\n",
            "316/1001, train_loss: 0.1200, step time: 0.6516\n",
            "317/1001, train_loss: 0.1390, step time: 0.6466\n",
            "318/1001, train_loss: 0.1121, step time: 0.6514\n",
            "319/1001, train_loss: 0.0641, step time: 0.6633\n",
            "320/1001, train_loss: 0.1089, step time: 0.6681\n",
            "321/1001, train_loss: 0.0328, step time: 0.6652\n",
            "322/1001, train_loss: 0.6795, step time: 0.6663\n",
            "323/1001, train_loss: 0.1449, step time: 0.6638\n",
            "324/1001, train_loss: 0.0741, step time: 0.6647\n",
            "325/1001, train_loss: 0.0596, step time: 0.6508\n",
            "326/1001, train_loss: 0.0438, step time: 0.6506\n",
            "327/1001, train_loss: 0.0576, step time: 0.6537\n",
            "328/1001, train_loss: 0.0777, step time: 0.6490\n",
            "329/1001, train_loss: 0.0916, step time: 0.6551\n",
            "330/1001, train_loss: 0.0558, step time: 0.6562\n",
            "331/1001, train_loss: 1.0000, step time: 0.6407\n",
            "332/1001, train_loss: 0.0469, step time: 0.6687\n",
            "333/1001, train_loss: 0.0686, step time: 0.6527\n",
            "334/1001, train_loss: 0.0952, step time: 0.6501\n",
            "335/1001, train_loss: 0.1834, step time: 0.6827\n",
            "336/1001, train_loss: 0.2067, step time: 0.6573\n",
            "337/1001, train_loss: 0.0596, step time: 0.6496\n",
            "338/1001, train_loss: 0.7257, step time: 0.6559\n",
            "339/1001, train_loss: 0.4311, step time: 0.6726\n",
            "340/1001, train_loss: 0.0279, step time: 0.6474\n",
            "341/1001, train_loss: 0.0710, step time: 0.6437\n",
            "342/1001, train_loss: 0.0542, step time: 0.6498\n",
            "343/1001, train_loss: 0.7093, step time: 0.6592\n",
            "344/1001, train_loss: 0.0685, step time: 0.6570\n",
            "345/1001, train_loss: 0.0410, step time: 0.6617\n",
            "346/1001, train_loss: 0.8489, step time: 0.6529\n",
            "347/1001, train_loss: 0.0300, step time: 0.6447\n",
            "348/1001, train_loss: 0.5142, step time: 0.6769\n",
            "349/1001, train_loss: 1.0000, step time: 0.6482\n",
            "350/1001, train_loss: 0.0358, step time: 0.6533\n",
            "351/1001, train_loss: 0.7346, step time: 0.6528\n",
            "352/1001, train_loss: 0.0573, step time: 0.6493\n",
            "353/1001, train_loss: 0.0617, step time: 0.6493\n",
            "354/1001, train_loss: 0.9994, step time: 0.6340\n",
            "355/1001, train_loss: 0.0988, step time: 0.6466\n",
            "356/1001, train_loss: 0.0416, step time: 0.6522\n",
            "357/1001, train_loss: 0.0715, step time: 0.6492\n",
            "358/1001, train_loss: 0.1364, step time: 0.6512\n",
            "359/1001, train_loss: 0.1019, step time: 0.6490\n",
            "360/1001, train_loss: 0.0637, step time: 0.6491\n",
            "361/1001, train_loss: 0.1061, step time: 0.6494\n",
            "362/1001, train_loss: 0.0570, step time: 0.6841\n",
            "363/1001, train_loss: 1.0000, step time: 0.6248\n",
            "364/1001, train_loss: 0.0746, step time: 0.6713\n",
            "365/1001, train_loss: 0.0402, step time: 0.6464\n",
            "366/1001, train_loss: 1.0000, step time: 0.6321\n",
            "367/1001, train_loss: 0.7709, step time: 0.6749\n",
            "368/1001, train_loss: 0.0738, step time: 0.6620\n",
            "369/1001, train_loss: 0.0627, step time: 0.6605\n",
            "370/1001, train_loss: 0.0984, step time: 0.6511\n",
            "371/1001, train_loss: 0.0952, step time: 0.6517\n",
            "372/1001, train_loss: 0.0275, step time: 0.6622\n",
            "373/1001, train_loss: 0.0990, step time: 0.6702\n",
            "374/1001, train_loss: 0.1947, step time: 0.6522\n",
            "375/1001, train_loss: 0.2553, step time: 0.6552\n",
            "376/1001, train_loss: 0.0604, step time: 0.6536\n",
            "377/1001, train_loss: 0.0934, step time: 0.6522\n",
            "378/1001, train_loss: 0.1029, step time: 0.6559\n",
            "379/1001, train_loss: 0.1415, step time: 0.6524\n",
            "380/1001, train_loss: 0.7951, step time: 0.6530\n",
            "381/1001, train_loss: 0.1921, step time: 0.6737\n",
            "382/1001, train_loss: 0.2078, step time: 0.6584\n",
            "383/1001, train_loss: 0.1198, step time: 0.6679\n",
            "384/1001, train_loss: 0.0313, step time: 0.6594\n",
            "385/1001, train_loss: 0.0320, step time: 0.6520\n",
            "386/1001, train_loss: 0.0664, step time: 0.6702\n",
            "387/1001, train_loss: 0.0753, step time: 0.6573\n",
            "388/1001, train_loss: 0.1982, step time: 0.6541\n",
            "389/1001, train_loss: 0.0418, step time: 0.6499\n",
            "390/1001, train_loss: 0.2376, step time: 0.6508\n",
            "391/1001, train_loss: 0.0911, step time: 0.6472\n",
            "392/1001, train_loss: 0.0474, step time: 0.6673\n",
            "393/1001, train_loss: 0.0562, step time: 0.6463\n",
            "394/1001, train_loss: 0.4065, step time: 0.6715\n",
            "395/1001, train_loss: 1.0000, step time: 0.6470\n",
            "396/1001, train_loss: 0.0430, step time: 0.6479\n",
            "397/1001, train_loss: 0.0434, step time: 0.6455\n",
            "398/1001, train_loss: 0.0886, step time: 0.6492\n",
            "399/1001, train_loss: 0.9696, step time: 0.6729\n",
            "400/1001, train_loss: 0.0589, step time: 0.6551\n",
            "401/1001, train_loss: 0.0674, step time: 0.6522\n",
            "402/1001, train_loss: 0.2765, step time: 0.6555\n",
            "403/1001, train_loss: 1.0000, step time: 0.6282\n",
            "404/1001, train_loss: 0.0468, step time: 0.6524\n",
            "405/1001, train_loss: 0.1143, step time: 0.6483\n",
            "406/1001, train_loss: 1.0000, step time: 0.6267\n",
            "407/1001, train_loss: 0.9005, step time: 0.6769\n",
            "408/1001, train_loss: 1.0000, step time: 0.6404\n",
            "409/1001, train_loss: 0.0552, step time: 0.6748\n",
            "410/1001, train_loss: 0.0469, step time: 0.6511\n",
            "411/1001, train_loss: 0.0714, step time: 0.6489\n",
            "412/1001, train_loss: 0.0288, step time: 0.6484\n",
            "413/1001, train_loss: 0.0796, step time: 0.6593\n",
            "414/1001, train_loss: 0.7480, step time: 0.6520\n",
            "415/1001, train_loss: 0.1716, step time: 0.6456\n",
            "416/1001, train_loss: 0.0311, step time: 0.6512\n",
            "417/1001, train_loss: 0.0645, step time: 0.6755\n",
            "418/1001, train_loss: 0.0554, step time: 0.6471\n",
            "419/1001, train_loss: 0.0404, step time: 0.6490\n",
            "420/1001, train_loss: 0.1850, step time: 0.6540\n",
            "421/1001, train_loss: 0.1108, step time: 0.6636\n",
            "422/1001, train_loss: 0.0904, step time: 0.6554\n",
            "423/1001, train_loss: 0.9781, step time: 0.6552\n",
            "424/1001, train_loss: 0.1403, step time: 0.6518\n",
            "425/1001, train_loss: 0.0456, step time: 0.6536\n",
            "426/1001, train_loss: 0.0905, step time: 0.6683\n",
            "427/1001, train_loss: 0.0701, step time: 0.6716\n",
            "428/1001, train_loss: 0.1453, step time: 0.6520\n",
            "429/1001, train_loss: 0.4138, step time: 0.6693\n",
            "430/1001, train_loss: 0.0468, step time: 0.6611\n",
            "431/1001, train_loss: 0.0568, step time: 0.6508\n",
            "432/1001, train_loss: 0.0374, step time: 0.6505\n",
            "433/1001, train_loss: 0.0545, step time: 0.6569\n",
            "434/1001, train_loss: 0.3278, step time: 0.6633\n",
            "435/1001, train_loss: 1.0000, step time: 0.6283\n",
            "436/1001, train_loss: 0.0348, step time: 0.6465\n",
            "437/1001, train_loss: 0.0790, step time: 0.6799\n",
            "438/1001, train_loss: 0.3442, step time: 0.6530\n",
            "439/1001, train_loss: 0.0771, step time: 0.6683\n",
            "440/1001, train_loss: 0.0680, step time: 0.6679\n",
            "441/1001, train_loss: 0.8974, step time: 0.6495\n",
            "442/1001, train_loss: 0.2144, step time: 0.6564\n",
            "443/1001, train_loss: 0.0736, step time: 0.6506\n",
            "444/1001, train_loss: 0.1123, step time: 0.6664\n",
            "445/1001, train_loss: 0.0701, step time: 0.6843\n",
            "446/1001, train_loss: 0.0485, step time: 0.6506\n",
            "447/1001, train_loss: 0.0548, step time: 0.6850\n",
            "448/1001, train_loss: 0.0956, step time: 0.6583\n",
            "449/1001, train_loss: 0.0989, step time: 0.6504\n",
            "450/1001, train_loss: 0.0520, step time: 0.6517\n",
            "451/1001, train_loss: 0.1405, step time: 0.6521\n",
            "452/1001, train_loss: 0.1333, step time: 0.6560\n",
            "453/1001, train_loss: 0.0875, step time: 0.6556\n",
            "454/1001, train_loss: 0.0547, step time: 0.6616\n",
            "455/1001, train_loss: 0.4364, step time: 0.6530\n",
            "456/1001, train_loss: 0.0353, step time: 0.6503\n",
            "457/1001, train_loss: 0.0693, step time: 0.6857\n",
            "458/1001, train_loss: 0.0574, step time: 0.6816\n",
            "459/1001, train_loss: 0.1421, step time: 0.6712\n",
            "460/1001, train_loss: 0.2006, step time: 0.6506\n",
            "461/1001, train_loss: 0.4885, step time: 0.6534\n",
            "462/1001, train_loss: 0.6999, step time: 0.6652\n",
            "463/1001, train_loss: 0.4507, step time: 0.6501\n",
            "464/1001, train_loss: 0.1197, step time: 0.6571\n",
            "465/1001, train_loss: 1.0000, step time: 0.6495\n",
            "466/1001, train_loss: 1.0000, step time: 0.6289\n",
            "467/1001, train_loss: 0.0805, step time: 0.6474\n",
            "468/1001, train_loss: 0.6984, step time: 0.6527\n",
            "469/1001, train_loss: 0.1260, step time: 0.6565\n",
            "470/1001, train_loss: 0.0771, step time: 0.6547\n",
            "471/1001, train_loss: 0.0956, step time: 0.6489\n",
            "472/1001, train_loss: 0.9999, step time: 0.6258\n",
            "473/1001, train_loss: 0.0809, step time: 0.6507\n",
            "474/1001, train_loss: 0.2466, step time: 0.6526\n",
            "475/1001, train_loss: 0.1916, step time: 0.6586\n",
            "476/1001, train_loss: 0.0536, step time: 0.6522\n",
            "477/1001, train_loss: 0.0358, step time: 0.6522\n",
            "478/1001, train_loss: 0.0721, step time: 0.6515\n",
            "479/1001, train_loss: 0.0712, step time: 0.6521\n",
            "480/1001, train_loss: 0.2057, step time: 0.6543\n",
            "481/1001, train_loss: 0.3596, step time: 0.6656\n",
            "482/1001, train_loss: 0.1394, step time: 0.6559\n",
            "483/1001, train_loss: 0.2556, step time: 0.6521\n",
            "484/1001, train_loss: 0.0376, step time: 0.6489\n",
            "485/1001, train_loss: 0.0541, step time: 0.6873\n",
            "486/1001, train_loss: 0.1172, step time: 0.6571\n",
            "487/1001, train_loss: 1.0000, step time: 0.6320\n",
            "488/1001, train_loss: 0.6664, step time: 0.6577\n",
            "489/1001, train_loss: 1.0000, step time: 0.6243\n",
            "490/1001, train_loss: 0.1343, step time: 0.6559\n",
            "491/1001, train_loss: 0.0409, step time: 0.6487\n",
            "492/1001, train_loss: 0.0940, step time: 0.6514\n",
            "493/1001, train_loss: 0.9741, step time: 0.6823\n",
            "494/1001, train_loss: 0.1078, step time: 0.6638\n",
            "495/1001, train_loss: 0.1479, step time: 0.6511\n",
            "496/1001, train_loss: 0.3012, step time: 0.6509\n",
            "497/1001, train_loss: 0.2467, step time: 0.6781\n",
            "498/1001, train_loss: 0.1064, step time: 0.6770\n",
            "499/1001, train_loss: 0.0603, step time: 0.6474\n",
            "500/1001, train_loss: 0.6955, step time: 0.6514\n",
            "501/1001, train_loss: 0.0566, step time: 0.6486\n",
            "502/1001, train_loss: 0.1742, step time: 0.6573\n",
            "503/1001, train_loss: 0.0666, step time: 0.6811\n",
            "504/1001, train_loss: 0.8101, step time: 0.6568\n",
            "505/1001, train_loss: 0.3222, step time: 0.6705\n",
            "506/1001, train_loss: 0.0697, step time: 0.6803\n",
            "507/1001, train_loss: 1.0000, step time: 0.6274\n",
            "508/1001, train_loss: 0.0220, step time: 0.6579\n",
            "509/1001, train_loss: 1.0000, step time: 0.6439\n",
            "510/1001, train_loss: 0.3137, step time: 0.6531\n",
            "511/1001, train_loss: 0.0415, step time: 0.6625\n",
            "512/1001, train_loss: 0.0618, step time: 0.6504\n",
            "513/1001, train_loss: 0.1640, step time: 0.6688\n",
            "514/1001, train_loss: 0.1450, step time: 0.6521\n",
            "515/1001, train_loss: 0.1139, step time: 0.6564\n",
            "516/1001, train_loss: 0.6978, step time: 0.6495\n",
            "517/1001, train_loss: 0.0893, step time: 0.6552\n",
            "518/1001, train_loss: 0.0761, step time: 0.6772\n",
            "519/1001, train_loss: 0.0282, step time: 0.6457\n",
            "520/1001, train_loss: 0.6557, step time: 0.6612\n",
            "521/1001, train_loss: 1.0000, step time: 0.6287\n",
            "522/1001, train_loss: 0.0429, step time: 0.6529\n",
            "523/1001, train_loss: 0.2098, step time: 0.6516\n",
            "524/1001, train_loss: 0.0854, step time: 0.6542\n",
            "525/1001, train_loss: 0.0577, step time: 0.6570\n",
            "526/1001, train_loss: 0.0286, step time: 0.6534\n",
            "527/1001, train_loss: 0.0397, step time: 0.6497\n",
            "528/1001, train_loss: 0.2752, step time: 0.6653\n",
            "529/1001, train_loss: 1.0000, step time: 0.6252\n",
            "530/1001, train_loss: 1.0000, step time: 0.6294\n",
            "531/1001, train_loss: 0.0456, step time: 0.6497\n",
            "532/1001, train_loss: 0.4073, step time: 0.6503\n",
            "533/1001, train_loss: 0.0448, step time: 0.6508\n",
            "534/1001, train_loss: 1.0000, step time: 0.6290\n",
            "535/1001, train_loss: 0.0282, step time: 0.6503\n",
            "536/1001, train_loss: 0.1839, step time: 0.6774\n",
            "537/1001, train_loss: 0.1340, step time: 0.6610\n",
            "538/1001, train_loss: 0.0386, step time: 0.6852\n",
            "539/1001, train_loss: 0.6816, step time: 0.6420\n",
            "540/1001, train_loss: 0.6859, step time: 0.6435\n",
            "541/1001, train_loss: 1.0000, step time: 0.6267\n",
            "542/1001, train_loss: 0.0412, step time: 0.6645\n",
            "543/1001, train_loss: 0.0415, step time: 0.6749\n",
            "544/1001, train_loss: 0.0445, step time: 0.6463\n",
            "545/1001, train_loss: 0.6724, step time: 0.6555\n",
            "546/1001, train_loss: 0.0324, step time: 0.6453\n",
            "547/1001, train_loss: 0.9991, step time: 0.6573\n",
            "548/1001, train_loss: 1.0000, step time: 0.6601\n",
            "549/1001, train_loss: 0.0439, step time: 0.6494\n",
            "550/1001, train_loss: 0.1150, step time: 0.6619\n",
            "551/1001, train_loss: 0.1157, step time: 0.6512\n",
            "552/1001, train_loss: 0.0575, step time: 0.6733\n",
            "553/1001, train_loss: 0.1465, step time: 0.6523\n",
            "554/1001, train_loss: 0.0453, step time: 0.6465\n",
            "555/1001, train_loss: 0.0679, step time: 0.6526\n",
            "556/1001, train_loss: 1.0000, step time: 0.6289\n",
            "557/1001, train_loss: 0.0384, step time: 0.6467\n",
            "558/1001, train_loss: 0.0830, step time: 0.6652\n",
            "559/1001, train_loss: 0.0395, step time: 0.6490\n",
            "560/1001, train_loss: 0.0888, step time: 0.6463\n",
            "561/1001, train_loss: 0.0697, step time: 0.6821\n",
            "562/1001, train_loss: 0.2348, step time: 0.6496\n",
            "563/1001, train_loss: 0.0341, step time: 0.6487\n",
            "564/1001, train_loss: 0.0664, step time: 0.6628\n",
            "565/1001, train_loss: 0.0888, step time: 0.6723\n",
            "566/1001, train_loss: 0.0780, step time: 0.6505\n",
            "567/1001, train_loss: 0.8950, step time: 0.6531\n",
            "568/1001, train_loss: 0.0388, step time: 0.6524\n",
            "569/1001, train_loss: 0.0374, step time: 0.6489\n",
            "570/1001, train_loss: 0.4511, step time: 0.6523\n",
            "571/1001, train_loss: 0.1027, step time: 0.6518\n",
            "572/1001, train_loss: 0.0392, step time: 0.6540\n",
            "573/1001, train_loss: 0.9700, step time: 0.6651\n",
            "574/1001, train_loss: 0.0365, step time: 0.6485\n",
            "575/1001, train_loss: 0.0434, step time: 0.6647\n",
            "576/1001, train_loss: 0.0651, step time: 0.6483\n",
            "577/1001, train_loss: 1.0000, step time: 0.6273\n",
            "578/1001, train_loss: 0.2462, step time: 0.6682\n",
            "579/1001, train_loss: 0.0679, step time: 0.6776\n",
            "580/1001, train_loss: 0.1908, step time: 0.6749\n",
            "581/1001, train_loss: 0.1884, step time: 0.6697\n",
            "582/1001, train_loss: 0.0421, step time: 0.6491\n",
            "583/1001, train_loss: 0.1435, step time: 0.6565\n",
            "584/1001, train_loss: 0.2188, step time: 0.6748\n",
            "585/1001, train_loss: 0.0488, step time: 0.6612\n",
            "586/1001, train_loss: 0.1925, step time: 0.6520\n",
            "587/1001, train_loss: 0.0364, step time: 0.6541\n",
            "588/1001, train_loss: 0.1807, step time: 0.6815\n",
            "589/1001, train_loss: 0.1027, step time: 0.6660\n",
            "590/1001, train_loss: 0.3690, step time: 0.6521\n",
            "591/1001, train_loss: 0.8799, step time: 0.6647\n",
            "592/1001, train_loss: 0.1013, step time: 0.6480\n",
            "593/1001, train_loss: 0.0286, step time: 0.6531\n",
            "594/1001, train_loss: 0.1214, step time: 0.6552\n",
            "595/1001, train_loss: 0.2408, step time: 0.6709\n",
            "596/1001, train_loss: 0.7353, step time: 0.6616\n",
            "597/1001, train_loss: 0.1285, step time: 0.6494\n",
            "598/1001, train_loss: 0.1985, step time: 0.6786\n",
            "599/1001, train_loss: 0.0740, step time: 0.6594\n",
            "600/1001, train_loss: 0.0320, step time: 0.6571\n",
            "601/1001, train_loss: 0.1079, step time: 0.6549\n",
            "602/1001, train_loss: 0.0529, step time: 0.6466\n",
            "603/1001, train_loss: 0.6894, step time: 0.6820\n",
            "604/1001, train_loss: 0.0296, step time: 0.6569\n",
            "605/1001, train_loss: 0.0529, step time: 0.6696\n",
            "606/1001, train_loss: 0.0668, step time: 0.6505\n",
            "607/1001, train_loss: 0.0501, step time: 0.6527\n",
            "608/1001, train_loss: 0.0371, step time: 0.6543\n",
            "609/1001, train_loss: 1.0000, step time: 0.6299\n",
            "610/1001, train_loss: 0.0280, step time: 0.6445\n",
            "611/1001, train_loss: 0.1277, step time: 0.6576\n",
            "612/1001, train_loss: 0.0418, step time: 0.6501\n",
            "613/1001, train_loss: 0.1747, step time: 0.6561\n",
            "614/1001, train_loss: 0.0345, step time: 0.6483\n",
            "615/1001, train_loss: 0.1161, step time: 0.6510\n",
            "616/1001, train_loss: 0.0703, step time: 0.6822\n",
            "617/1001, train_loss: 1.0000, step time: 0.6357\n",
            "618/1001, train_loss: 0.0366, step time: 0.6812\n",
            "619/1001, train_loss: 0.0633, step time: 0.6954\n",
            "620/1001, train_loss: 0.0696, step time: 0.6806\n",
            "621/1001, train_loss: 0.1133, step time: 0.6549\n",
            "622/1001, train_loss: 0.7971, step time: 0.6551\n",
            "623/1001, train_loss: 0.2332, step time: 0.6660\n",
            "624/1001, train_loss: 0.6399, step time: 0.6776\n",
            "625/1001, train_loss: 0.1878, step time: 0.6585\n",
            "626/1001, train_loss: 0.7692, step time: 0.6570\n",
            "627/1001, train_loss: 0.2793, step time: 0.6503\n",
            "628/1001, train_loss: 0.1409, step time: 0.6609\n",
            "629/1001, train_loss: 0.1826, step time: 0.6510\n",
            "630/1001, train_loss: 0.0503, step time: 0.6780\n",
            "631/1001, train_loss: 0.0394, step time: 0.6497\n",
            "632/1001, train_loss: 0.0657, step time: 0.6491\n",
            "633/1001, train_loss: 0.0855, step time: 0.6733\n",
            "634/1001, train_loss: 0.0650, step time: 0.6543\n",
            "635/1001, train_loss: 0.1212, step time: 0.6745\n",
            "636/1001, train_loss: 0.0768, step time: 0.6558\n",
            "637/1001, train_loss: 0.8599, step time: 0.6860\n",
            "638/1001, train_loss: 0.0697, step time: 0.6622\n",
            "639/1001, train_loss: 0.1233, step time: 0.6635\n",
            "640/1001, train_loss: 0.0687, step time: 0.6482\n",
            "641/1001, train_loss: 1.0000, step time: 0.6331\n",
            "642/1001, train_loss: 0.0716, step time: 0.6600\n",
            "643/1001, train_loss: 0.0313, step time: 0.6712\n",
            "644/1001, train_loss: 0.0434, step time: 0.6689\n",
            "645/1001, train_loss: 0.0855, step time: 0.6539\n",
            "646/1001, train_loss: 0.1021, step time: 0.7017\n",
            "647/1001, train_loss: 0.0737, step time: 0.6551\n",
            "648/1001, train_loss: 0.0342, step time: 0.6499\n",
            "649/1001, train_loss: 0.7023, step time: 0.6502\n",
            "650/1001, train_loss: 0.9082, step time: 0.6511\n",
            "651/1001, train_loss: 0.2194, step time: 0.6546\n",
            "652/1001, train_loss: 0.1267, step time: 0.6572\n",
            "653/1001, train_loss: 0.3673, step time: 0.6541\n",
            "654/1001, train_loss: 0.6772, step time: 0.6465\n",
            "655/1001, train_loss: 1.0000, step time: 0.6251\n",
            "656/1001, train_loss: 0.6853, step time: 0.6421\n",
            "657/1001, train_loss: 0.0621, step time: 0.6618\n",
            "658/1001, train_loss: 0.1398, step time: 0.6550\n",
            "659/1001, train_loss: 0.3738, step time: 0.6590\n",
            "660/1001, train_loss: 0.4070, step time: 0.6497\n",
            "661/1001, train_loss: 0.6843, step time: 0.6542\n",
            "662/1001, train_loss: 1.0000, step time: 0.6240\n",
            "663/1001, train_loss: 0.0677, step time: 0.6542\n",
            "664/1001, train_loss: 0.0350, step time: 0.6511\n",
            "665/1001, train_loss: 0.1013, step time: 0.6580\n",
            "666/1001, train_loss: 0.1602, step time: 0.6519\n",
            "667/1001, train_loss: 0.1073, step time: 0.6501\n",
            "668/1001, train_loss: 0.0358, step time: 0.6796\n",
            "669/1001, train_loss: 1.0000, step time: 0.6317\n",
            "670/1001, train_loss: 0.4052, step time: 0.6579\n",
            "671/1001, train_loss: 0.8422, step time: 0.6736\n",
            "672/1001, train_loss: 1.0000, step time: 0.6479\n",
            "673/1001, train_loss: 0.7958, step time: 0.6522\n",
            "674/1001, train_loss: 0.0476, step time: 0.6463\n",
            "675/1001, train_loss: 0.1190, step time: 0.6734\n",
            "676/1001, train_loss: 0.0757, step time: 0.6548\n",
            "677/1001, train_loss: 0.1642, step time: 0.6721\n",
            "678/1001, train_loss: 0.6854, step time: 0.6480\n",
            "679/1001, train_loss: 0.0414, step time: 0.6706\n",
            "680/1001, train_loss: 0.0192, step time: 0.6468\n",
            "681/1001, train_loss: 0.1318, step time: 0.6541\n",
            "682/1001, train_loss: 0.0849, step time: 0.6782\n",
            "683/1001, train_loss: 0.2020, step time: 0.6582\n",
            "684/1001, train_loss: 0.0824, step time: 0.6501\n",
            "685/1001, train_loss: 0.0699, step time: 0.6551\n",
            "686/1001, train_loss: 0.0901, step time: 0.6579\n",
            "687/1001, train_loss: 0.0787, step time: 0.6547\n",
            "688/1001, train_loss: 1.0000, step time: 0.6244\n",
            "689/1001, train_loss: 0.6068, step time: 0.6540\n",
            "690/1001, train_loss: 0.3172, step time: 0.6719\n",
            "691/1001, train_loss: 0.1747, step time: 0.6703\n",
            "692/1001, train_loss: 0.0616, step time: 0.6928\n",
            "693/1001, train_loss: 0.0540, step time: 0.6682\n",
            "694/1001, train_loss: 0.8967, step time: 0.6556\n",
            "695/1001, train_loss: 0.4027, step time: 0.6484\n",
            "696/1001, train_loss: 1.0000, step time: 0.6489\n",
            "697/1001, train_loss: 0.1740, step time: 0.6528\n",
            "698/1001, train_loss: 1.0000, step time: 0.6277\n",
            "699/1001, train_loss: 0.0777, step time: 0.6826\n",
            "700/1001, train_loss: 0.0360, step time: 0.6598\n",
            "701/1001, train_loss: 0.4463, step time: 0.6657\n",
            "702/1001, train_loss: 0.0461, step time: 0.6658\n",
            "703/1001, train_loss: 0.0960, step time: 0.6514\n",
            "704/1001, train_loss: 0.0510, step time: 0.6506\n",
            "705/1001, train_loss: 0.0930, step time: 0.6540\n",
            "706/1001, train_loss: 0.0569, step time: 0.6481\n",
            "707/1001, train_loss: 0.1305, step time: 0.6510\n",
            "708/1001, train_loss: 0.8436, step time: 0.6820\n",
            "709/1001, train_loss: 0.0419, step time: 0.6595\n",
            "710/1001, train_loss: 0.0502, step time: 0.6561\n",
            "711/1001, train_loss: 0.0309, step time: 0.6455\n",
            "712/1001, train_loss: 0.0705, step time: 0.6605\n",
            "713/1001, train_loss: 0.1972, step time: 0.6950\n",
            "714/1001, train_loss: 0.0472, step time: 0.6757\n",
            "715/1001, train_loss: 0.7223, step time: 0.6654\n",
            "716/1001, train_loss: 0.7680, step time: 0.6774\n",
            "717/1001, train_loss: 0.0630, step time: 0.6630\n",
            "718/1001, train_loss: 0.2524, step time: 0.6706\n",
            "719/1001, train_loss: 1.0000, step time: 0.6240\n",
            "720/1001, train_loss: 0.0473, step time: 0.6498\n",
            "721/1001, train_loss: 0.0871, step time: 0.6823\n",
            "722/1001, train_loss: 1.0000, step time: 0.6379\n",
            "723/1001, train_loss: 0.0594, step time: 0.6506\n",
            "724/1001, train_loss: 0.0798, step time: 0.6538\n",
            "725/1001, train_loss: 1.0000, step time: 0.6403\n",
            "726/1001, train_loss: 0.0394, step time: 0.6491\n",
            "727/1001, train_loss: 0.1471, step time: 0.6525\n",
            "728/1001, train_loss: 1.0000, step time: 0.6235\n",
            "729/1001, train_loss: 0.0503, step time: 0.6621\n",
            "730/1001, train_loss: 0.0781, step time: 0.6595\n",
            "731/1001, train_loss: 0.0791, step time: 0.6512\n",
            "732/1001, train_loss: 1.0000, step time: 0.6462\n",
            "733/1001, train_loss: 1.0000, step time: 0.6322\n",
            "734/1001, train_loss: 0.4844, step time: 0.6799\n",
            "735/1001, train_loss: 0.0473, step time: 0.6676\n",
            "736/1001, train_loss: 0.0445, step time: 0.6450\n",
            "737/1001, train_loss: 0.1410, step time: 0.6498\n",
            "738/1001, train_loss: 0.1130, step time: 0.6496\n",
            "739/1001, train_loss: 0.0727, step time: 0.6424\n",
            "740/1001, train_loss: 0.3366, step time: 0.6605\n",
            "741/1001, train_loss: 0.0803, step time: 0.6569\n",
            "742/1001, train_loss: 0.9274, step time: 0.6513\n",
            "743/1001, train_loss: 0.0579, step time: 0.6618\n",
            "744/1001, train_loss: 0.9999, step time: 0.6348\n",
            "745/1001, train_loss: 0.0435, step time: 0.6537\n",
            "746/1001, train_loss: 0.0380, step time: 0.6512\n",
            "747/1001, train_loss: 0.8992, step time: 0.6560\n",
            "748/1001, train_loss: 0.1986, step time: 0.6516\n",
            "749/1001, train_loss: 0.8038, step time: 0.6532\n",
            "750/1001, train_loss: 0.0626, step time: 0.6641\n",
            "751/1001, train_loss: 0.0257, step time: 0.6717\n",
            "752/1001, train_loss: 0.7983, step time: 0.6550\n",
            "753/1001, train_loss: 0.0435, step time: 0.6528\n",
            "754/1001, train_loss: 0.0585, step time: 0.6617\n",
            "755/1001, train_loss: 0.0673, step time: 0.6706\n",
            "756/1001, train_loss: 0.4415, step time: 0.6571\n",
            "757/1001, train_loss: 0.1113, step time: 0.6514\n",
            "758/1001, train_loss: 0.1482, step time: 0.6520\n",
            "759/1001, train_loss: 0.0699, step time: 0.6550\n",
            "760/1001, train_loss: 0.2114, step time: 0.6545\n",
            "761/1001, train_loss: 0.0712, step time: 0.6516\n",
            "762/1001, train_loss: 0.1010, step time: 0.6779\n",
            "763/1001, train_loss: 0.1325, step time: 0.6521\n",
            "764/1001, train_loss: 0.6018, step time: 0.6772\n",
            "765/1001, train_loss: 0.7703, step time: 0.6562\n",
            "766/1001, train_loss: 0.9055, step time: 0.6607\n",
            "767/1001, train_loss: 0.7009, step time: 0.6538\n",
            "768/1001, train_loss: 0.4319, step time: 0.6638\n",
            "769/1001, train_loss: 0.1126, step time: 0.6676\n",
            "770/1001, train_loss: 0.0386, step time: 0.7834\n",
            "771/1001, train_loss: 0.0884, step time: 0.6539\n",
            "772/1001, train_loss: 0.7793, step time: 0.6761\n",
            "773/1001, train_loss: 0.1026, step time: 0.6673\n",
            "774/1001, train_loss: 0.7487, step time: 0.6872\n",
            "775/1001, train_loss: 0.0353, step time: 0.6592\n",
            "776/1001, train_loss: 0.7335, step time: 0.6605\n",
            "777/1001, train_loss: 0.7833, step time: 0.6524\n",
            "778/1001, train_loss: 0.0423, step time: 0.6466\n",
            "779/1001, train_loss: 0.0962, step time: 0.6610\n",
            "780/1001, train_loss: 0.1121, step time: 0.6550\n",
            "781/1001, train_loss: 0.0633, step time: 0.6485\n",
            "782/1001, train_loss: 0.0372, step time: 0.6562\n",
            "783/1001, train_loss: 0.2218, step time: 0.6884\n",
            "784/1001, train_loss: 0.0301, step time: 0.6556\n",
            "785/1001, train_loss: 0.0720, step time: 0.6567\n",
            "786/1001, train_loss: 0.0360, step time: 0.6523\n",
            "787/1001, train_loss: 0.9987, step time: 0.6418\n",
            "788/1001, train_loss: 0.1200, step time: 0.6522\n",
            "789/1001, train_loss: 0.9118, step time: 0.6508\n",
            "790/1001, train_loss: 1.0000, step time: 0.6271\n",
            "791/1001, train_loss: 1.0000, step time: 0.6484\n",
            "792/1001, train_loss: 0.0569, step time: 0.6518\n",
            "793/1001, train_loss: 0.0469, step time: 0.6507\n",
            "794/1001, train_loss: 0.0389, step time: 0.6624\n",
            "795/1001, train_loss: 0.0854, step time: 0.6537\n",
            "796/1001, train_loss: 0.0598, step time: 0.6522\n",
            "797/1001, train_loss: 0.1132, step time: 0.6543\n",
            "798/1001, train_loss: 0.0348, step time: 0.6473\n",
            "799/1001, train_loss: 0.7492, step time: 0.7054\n",
            "800/1001, train_loss: 1.0000, step time: 0.6271\n",
            "801/1001, train_loss: 0.3466, step time: 0.6515\n",
            "802/1001, train_loss: 0.9381, step time: 0.6490\n",
            "803/1001, train_loss: 0.6960, step time: 0.6598\n",
            "804/1001, train_loss: 1.0000, step time: 0.6269\n",
            "805/1001, train_loss: 0.0322, step time: 0.6422\n",
            "806/1001, train_loss: 0.6764, step time: 0.6487\n",
            "807/1001, train_loss: 0.0333, step time: 0.6556\n",
            "808/1001, train_loss: 0.0993, step time: 0.6510\n",
            "809/1001, train_loss: 0.6775, step time: 0.6528\n",
            "810/1001, train_loss: 0.0391, step time: 0.6511\n",
            "811/1001, train_loss: 0.0570, step time: 0.6496\n",
            "812/1001, train_loss: 0.3034, step time: 0.6623\n",
            "813/1001, train_loss: 0.0957, step time: 0.6697\n",
            "814/1001, train_loss: 0.0585, step time: 0.6661\n",
            "815/1001, train_loss: 0.0731, step time: 0.6610\n",
            "816/1001, train_loss: 0.0405, step time: 0.6501\n",
            "817/1001, train_loss: 0.1175, step time: 0.6733\n",
            "818/1001, train_loss: 0.0413, step time: 0.7062\n",
            "819/1001, train_loss: 0.0556, step time: 0.6525\n",
            "820/1001, train_loss: 0.0599, step time: 0.6499\n",
            "821/1001, train_loss: 0.0575, step time: 0.6635\n",
            "822/1001, train_loss: 0.0594, step time: 0.6486\n",
            "823/1001, train_loss: 0.4722, step time: 0.6521\n",
            "824/1001, train_loss: 1.0000, step time: 0.6255\n",
            "825/1001, train_loss: 0.2641, step time: 0.6509\n",
            "826/1001, train_loss: 0.7429, step time: 0.6539\n",
            "827/1001, train_loss: 0.0356, step time: 0.6691\n",
            "828/1001, train_loss: 0.2805, step time: 0.6817\n",
            "829/1001, train_loss: 0.0292, step time: 0.6494\n",
            "830/1001, train_loss: 0.0771, step time: 0.6850\n",
            "831/1001, train_loss: 0.0545, step time: 0.6519\n",
            "832/1001, train_loss: 0.6897, step time: 0.6502\n",
            "833/1001, train_loss: 0.0812, step time: 0.6500\n",
            "834/1001, train_loss: 0.1650, step time: 0.6535\n",
            "835/1001, train_loss: 0.7020, step time: 0.6567\n",
            "836/1001, train_loss: 0.2817, step time: 0.6515\n",
            "837/1001, train_loss: 0.0962, step time: 0.6510\n",
            "838/1001, train_loss: 0.0873, step time: 0.6503\n",
            "839/1001, train_loss: 0.1550, step time: 0.6540\n",
            "840/1001, train_loss: 0.0662, step time: 0.6518\n",
            "841/1001, train_loss: 0.0841, step time: 0.6678\n",
            "842/1001, train_loss: 0.7578, step time: 0.6548\n",
            "843/1001, train_loss: 0.0454, step time: 0.6506\n",
            "844/1001, train_loss: 0.6889, step time: 0.6466\n",
            "845/1001, train_loss: 0.8543, step time: 0.6529\n",
            "846/1001, train_loss: 0.0675, step time: 0.6577\n",
            "847/1001, train_loss: 0.0417, step time: 0.6495\n",
            "848/1001, train_loss: 0.0462, step time: 0.6537\n",
            "849/1001, train_loss: 1.0000, step time: 0.6273\n",
            "850/1001, train_loss: 0.0456, step time: 0.6489\n",
            "851/1001, train_loss: 0.8396, step time: 0.6526\n",
            "852/1001, train_loss: 0.0318, step time: 0.6495\n",
            "853/1001, train_loss: 0.3457, step time: 0.6770\n",
            "854/1001, train_loss: 0.0688, step time: 0.6609\n",
            "855/1001, train_loss: 0.0360, step time: 0.6728\n",
            "856/1001, train_loss: 0.1770, step time: 0.6631\n",
            "857/1001, train_loss: 0.0385, step time: 0.6528\n",
            "858/1001, train_loss: 0.4708, step time: 0.6572\n",
            "859/1001, train_loss: 0.7329, step time: 0.6540\n",
            "860/1001, train_loss: 0.0808, step time: 0.6527\n",
            "861/1001, train_loss: 0.2920, step time: 0.6766\n",
            "862/1001, train_loss: 0.0460, step time: 0.6483\n",
            "863/1001, train_loss: 0.0708, step time: 0.6532\n",
            "864/1001, train_loss: 0.0559, step time: 0.6691\n",
            "865/1001, train_loss: 0.0333, step time: 0.6514\n",
            "866/1001, train_loss: 0.0298, step time: 0.6513\n",
            "867/1001, train_loss: 0.0751, step time: 0.6521\n",
            "868/1001, train_loss: 0.0331, step time: 0.6508\n",
            "869/1001, train_loss: 1.0000, step time: 0.6239\n",
            "870/1001, train_loss: 0.7258, step time: 0.6561\n",
            "871/1001, train_loss: 0.8028, step time: 0.6523\n",
            "872/1001, train_loss: 0.0694, step time: 0.6490\n",
            "873/1001, train_loss: 0.0595, step time: 0.6675\n",
            "874/1001, train_loss: 0.7461, step time: 0.6671\n",
            "875/1001, train_loss: 0.0292, step time: 0.6524\n",
            "876/1001, train_loss: 1.0000, step time: 0.6260\n",
            "877/1001, train_loss: 0.6870, step time: 0.6671\n",
            "878/1001, train_loss: 0.0526, step time: 0.6831\n",
            "879/1001, train_loss: 0.0670, step time: 0.6587\n",
            "880/1001, train_loss: 0.1146, step time: 0.6474\n",
            "881/1001, train_loss: 0.0666, step time: 0.6492\n",
            "882/1001, train_loss: 0.0639, step time: 0.6488\n",
            "883/1001, train_loss: 0.1596, step time: 0.6872\n",
            "884/1001, train_loss: 1.0000, step time: 0.6282\n",
            "885/1001, train_loss: 0.2892, step time: 0.6537\n",
            "886/1001, train_loss: 0.0466, step time: 0.6527\n",
            "887/1001, train_loss: 0.1875, step time: 0.6498\n",
            "888/1001, train_loss: 0.4805, step time: 0.6543\n",
            "889/1001, train_loss: 0.0530, step time: 0.6489\n",
            "890/1001, train_loss: 0.0488, step time: 0.6662\n",
            "891/1001, train_loss: 0.0565, step time: 0.6469\n",
            "892/1001, train_loss: 0.0588, step time: 0.6509\n",
            "893/1001, train_loss: 0.0494, step time: 0.6581\n",
            "894/1001, train_loss: 0.0539, step time: 0.6548\n",
            "895/1001, train_loss: 0.1804, step time: 0.6563\n",
            "896/1001, train_loss: 0.1123, step time: 0.6682\n",
            "897/1001, train_loss: 0.0523, step time: 0.6677\n",
            "898/1001, train_loss: 0.1630, step time: 0.6558\n",
            "899/1001, train_loss: 0.0666, step time: 0.6502\n",
            "900/1001, train_loss: 0.1540, step time: 0.6613\n",
            "901/1001, train_loss: 0.7093, step time: 0.6686\n",
            "902/1001, train_loss: 0.7793, step time: 0.7010\n",
            "903/1001, train_loss: 0.1343, step time: 0.6589\n",
            "904/1001, train_loss: 0.0614, step time: 0.6518\n",
            "905/1001, train_loss: 0.7235, step time: 0.6490\n",
            "906/1001, train_loss: 0.6889, step time: 0.6501\n",
            "907/1001, train_loss: 0.0754, step time: 0.6526\n",
            "908/1001, train_loss: 0.6212, step time: 0.6520\n",
            "909/1001, train_loss: 0.2155, step time: 0.6562\n",
            "910/1001, train_loss: 0.0488, step time: 0.6590\n",
            "911/1001, train_loss: 0.1328, step time: 0.6525\n",
            "912/1001, train_loss: 0.0602, step time: 0.6759\n",
            "913/1001, train_loss: 0.0578, step time: 0.6502\n",
            "914/1001, train_loss: 0.0856, step time: 0.6796\n",
            "915/1001, train_loss: 0.1014, step time: 0.6593\n",
            "916/1001, train_loss: 0.6721, step time: 0.6488\n",
            "917/1001, train_loss: 0.1625, step time: 0.6504\n",
            "918/1001, train_loss: 0.9844, step time: 0.6569\n",
            "919/1001, train_loss: 0.0334, step time: 0.6701\n",
            "920/1001, train_loss: 1.0000, step time: 0.6237\n",
            "921/1001, train_loss: 0.0410, step time: 0.6533\n",
            "922/1001, train_loss: 0.0638, step time: 0.6593\n",
            "923/1001, train_loss: 0.0759, step time: 0.6801\n",
            "924/1001, train_loss: 0.0415, step time: 0.6722\n",
            "925/1001, train_loss: 0.1323, step time: 0.6678\n",
            "926/1001, train_loss: 0.2218, step time: 0.6554\n",
            "927/1001, train_loss: 0.0470, step time: 0.6766\n",
            "928/1001, train_loss: 0.0504, step time: 0.6521\n",
            "929/1001, train_loss: 0.0476, step time: 0.6662\n",
            "930/1001, train_loss: 0.0459, step time: 0.6660\n",
            "931/1001, train_loss: 0.0456, step time: 0.6508\n",
            "932/1001, train_loss: 0.0501, step time: 0.6805\n",
            "933/1001, train_loss: 0.2372, step time: 0.6628\n",
            "934/1001, train_loss: 0.2341, step time: 0.6489\n",
            "935/1001, train_loss: 0.0529, step time: 0.6555\n",
            "936/1001, train_loss: 1.0000, step time: 0.6272\n",
            "937/1001, train_loss: 0.2254, step time: 0.6605\n",
            "938/1001, train_loss: 0.1033, step time: 0.6615\n",
            "939/1001, train_loss: 1.0000, step time: 0.6228\n",
            "940/1001, train_loss: 0.0699, step time: 0.6723\n",
            "941/1001, train_loss: 0.0687, step time: 0.6548\n",
            "942/1001, train_loss: 0.0393, step time: 0.6687\n",
            "943/1001, train_loss: 0.0379, step time: 0.6503\n",
            "944/1001, train_loss: 0.2272, step time: 0.6501\n",
            "945/1001, train_loss: 0.3051, step time: 0.6507\n",
            "946/1001, train_loss: 0.0673, step time: 0.6676\n",
            "947/1001, train_loss: 0.0433, step time: 0.6493\n",
            "948/1001, train_loss: 0.4021, step time: 0.6536\n",
            "949/1001, train_loss: 0.0385, step time: 0.6550\n",
            "950/1001, train_loss: 0.1368, step time: 0.6668\n",
            "951/1001, train_loss: 1.0000, step time: 0.6245\n",
            "952/1001, train_loss: 0.0690, step time: 0.6511\n",
            "953/1001, train_loss: 1.0000, step time: 0.6229\n",
            "954/1001, train_loss: 0.0338, step time: 0.6504\n",
            "955/1001, train_loss: 0.1908, step time: 0.6654\n",
            "956/1001, train_loss: 0.0934, step time: 0.6569\n",
            "957/1001, train_loss: 0.4346, step time: 0.6533\n",
            "958/1001, train_loss: 0.0788, step time: 0.6633\n",
            "959/1001, train_loss: 0.1502, step time: 0.6521\n",
            "960/1001, train_loss: 0.3466, step time: 0.6692\n",
            "961/1001, train_loss: 1.0000, step time: 0.6228\n",
            "962/1001, train_loss: 0.0460, step time: 0.6545\n",
            "963/1001, train_loss: 0.1134, step time: 0.6569\n",
            "964/1001, train_loss: 0.0594, step time: 0.6507\n",
            "965/1001, train_loss: 1.0000, step time: 0.6236\n",
            "966/1001, train_loss: 0.0530, step time: 0.6644\n",
            "967/1001, train_loss: 0.0241, step time: 0.6768\n",
            "968/1001, train_loss: 0.1044, step time: 0.6569\n",
            "969/1001, train_loss: 0.0381, step time: 0.6639\n",
            "970/1001, train_loss: 0.1005, step time: 0.6496\n",
            "971/1001, train_loss: 0.1746, step time: 0.6968\n",
            "972/1001, train_loss: 0.0520, step time: 0.6542\n",
            "973/1001, train_loss: 0.7054, step time: 0.6517\n",
            "974/1001, train_loss: 0.0735, step time: 0.6538\n",
            "975/1001, train_loss: 0.4304, step time: 0.6526\n",
            "976/1001, train_loss: 0.0632, step time: 0.6499\n",
            "977/1001, train_loss: 0.1001, step time: 0.6508\n",
            "978/1001, train_loss: 0.9954, step time: 0.6464\n",
            "979/1001, train_loss: 0.9019, step time: 0.6495\n",
            "980/1001, train_loss: 0.0767, step time: 0.6719\n",
            "981/1001, train_loss: 0.0661, step time: 0.6496\n",
            "982/1001, train_loss: 0.1033, step time: 0.6466\n",
            "983/1001, train_loss: 0.0288, step time: 0.6483\n",
            "984/1001, train_loss: 1.0000, step time: 0.6300\n",
            "985/1001, train_loss: 0.1099, step time: 0.6548\n",
            "986/1001, train_loss: 0.0494, step time: 0.6489\n",
            "987/1001, train_loss: 0.3944, step time: 0.6496\n",
            "988/1001, train_loss: 0.0615, step time: 0.6505\n",
            "989/1001, train_loss: 0.7580, step time: 0.6510\n",
            "990/1001, train_loss: 0.2580, step time: 0.6516\n",
            "991/1001, train_loss: 0.0352, step time: 0.6429\n",
            "992/1001, train_loss: 1.0000, step time: 0.6235\n",
            "993/1001, train_loss: 0.0429, step time: 0.6500\n",
            "994/1001, train_loss: 0.0596, step time: 0.6493\n",
            "995/1001, train_loss: 0.0775, step time: 0.6463\n",
            "996/1001, train_loss: 0.9805, step time: 0.6506\n",
            "997/1001, train_loss: 0.0347, step time: 0.6425\n",
            "998/1001, train_loss: 0.0728, step time: 0.6516\n",
            "999/1001, train_loss: 0.1285, step time: 0.6470\n",
            "1000/1001, train_loss: 0.2078, step time: 0.6505\n",
            "1001/1001, train_loss: 0.9993, step time: 0.6384\n",
            "epoch 20 average loss: 0.2694\n",
            "current epoch: 20 current mean dice: 0.8702 tc: 0.8604 wt: 0.9095 et: 0.8440\n",
            "best mean dice: 0.8719 at epoch: 19\n",
            "time consuming of epoch 20 is: 883.3359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}, total time: {total_time}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL3cOVdNP6py",
        "outputId": "5f4b2e50-d74e-4fec-fcc2-ad0e4129fe13"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train completed, best_metric: 0.8719 at epoch: 19, total time: 16652.683278799057.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(\"train\", (12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Epoch Average Loss\")\n",
        "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
        "y = epoch_loss_values\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y, color=\"red\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Val Mean Dice\")\n",
        "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
        "y = metric_values\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y, color=\"green\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(\"train\", (18, 6))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.title(\"Val Mean Dice TC\")\n",
        "x = [val_interval * (i + 1) for i in range(len(metric_values_tc))]\n",
        "y = metric_values_tc\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y, color=\"blue\")\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.title(\"Val Mean Dice WT\")\n",
        "x = [val_interval * (i + 1) for i in range(len(metric_values_wt))]\n",
        "y = metric_values_wt\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y, color=\"brown\")\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.title(\"Val Mean Dice ET\")\n",
        "x = [val_interval * (i + 1) for i in range(len(metric_values_et))]\n",
        "y = metric_values_et\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y, color=\"purple\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "id": "E8uvk-3fP9xG",
        "outputId": "7b4f0856-d9d0-4756-cd24-ce7fa1b07bca"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1296x432 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "case_num = \"01619\"\n",
        "\n",
        "test_files = [\n",
        "    {\n",
        "        \"image\": [\n",
        "            os.path.join(\n",
        "                data_dir,\n",
        "                \"TrainingData/BraTS2021_\"\n",
        "                + case_num\n",
        "                + \"/BraTS2021_\"\n",
        "                + case_num\n",
        "                + \"_flair.nii.gz\",\n",
        "            ),\n",
        "            os.path.join(\n",
        "                data_dir,\n",
        "                \"TrainingData/BraTS2021_\"\n",
        "                + case_num\n",
        "                + \"/BraTS2021_\"\n",
        "                + case_num\n",
        "                + \"_t1ce.nii.gz\",\n",
        "            ),\n",
        "            os.path.join(\n",
        "                data_dir,\n",
        "                \"TrainingData/BraTS2021_\"\n",
        "                + case_num\n",
        "                + \"/BraTS2021_\"\n",
        "                + case_num\n",
        "                + \"_t1.nii.gz\",\n",
        "            ),\n",
        "            os.path.join(\n",
        "                data_dir,\n",
        "                \"TrainingData/BraTS2021_\"\n",
        "                + case_num\n",
        "                + \"/BraTS2021_\"\n",
        "                + case_num\n",
        "                + \"_t2.nii.gz\",\n",
        "            ),\n",
        "        ],\n",
        "        \"label\": os.path.join(\n",
        "            data_dir,\n",
        "            \"TrainingData/BraTS2021_\"\n",
        "            + case_num\n",
        "            + \"/BraTS2021_\"\n",
        "            + case_num\n",
        "            + \"_seg.nii.gz\",\n",
        "        ),\n",
        "    }\n",
        "]\n",
        "\n",
        "test_transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.LoadImaged(keys=[\"image\", \"label\"]),\n",
        "        transforms.ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
        "        transforms.NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
        "        transforms.ToTensord(keys=[\"image\", \"label\"]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "test_ds = data.Dataset(data=test_files, transform=test_transform)\n",
        "\n",
        "test_loader = data.DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=8,\n",
        "    pin_memory=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xy3ncjy_IKdu",
        "outputId": "72ad4765-7163-43c1-e844-312cf517a7e9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(os.path.join(root_dir, \"best_metric_model.pth\")))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "model_inferer_test = partial(\n",
        "    sliding_window_inference,\n",
        "    roi_size=[roi[0], roi[1], roi[2]],\n",
        "    sw_batch_size=1,\n",
        "    predictor=model,\n",
        "    overlap=0.6,\n",
        ")\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for idx, batch_data in enumerate(test_loader):\n",
        "        image = batch_data[\"image\"].cuda()\n",
        "        prob = torch.sigmoid(model_inferer_test(image))\n",
        "        seg = prob[0].detach().cpu().numpy()\n",
        "        seg = (seg > 0.5).astype(np.int8)\n",
        "        seg_out = np.zeros((seg.shape[1], seg.shape[2], seg.shape[3]))\n",
        "        seg_out[seg[1] == 1] = 2\n",
        "        seg_out[seg[0] == 1] = 1\n",
        "        seg_out[seg[2] == 1] = 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mW4JQUIQCPG",
        "outputId": "42790d70-a26f-47cd-fe4e-bd4da557c740"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "slice_num = 35\n",
        "img_add = os.path.join(data_dir,\"TrainingData/BraTS2021_\" + case_num + \"/BraTS2021_\" + case_num + \"_t1ce.nii.gz\")\n",
        "label_add = os.path.join(data_dir,\"TrainingData/BraTS2021_\" + case_num + \"/BraTS2021_\" + case_num + \"_seg.nii.gz\")\n",
        "\n",
        "img = nib.load(img_add).get_fdata()\n",
        "label = nib.load(label_add).get_fdata()\n",
        "plt.figure(\"image\", (18, 6))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.title(\"image\")\n",
        "plt.imshow(img[:, :, slice_num], cmap=\"gray\")\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.title(\"label\")\n",
        "plt.imshow(label[:, :, slice_num])\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.title(\"segmentation\")\n",
        "plt.imshow(seg_out[:, :, slice_num])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "FayY-qmEQEpg",
        "outputId": "a1ad1e5c-0a71-4fba-f905-903c63246c2b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1296x432 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##if directory is None:\n",
        "    ##shutil.rmtree(root_dir)\n"
      ],
      "metadata": {
        "id": "P8rvhssDQKNR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}